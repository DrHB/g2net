{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e383b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import copy\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from x_transformers import  Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import exists\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fastai.vision.all import BCEWithLogitsLossFlat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import os\n",
    "from timm import create_model\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from secrets import token_hex\n",
    "\n",
    "def get_random_name(len_k=16):\n",
    "    token = token_hex(len_k)\n",
    "    return token\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_torch(fn):\n",
    "    data = torch.load(fn)\n",
    "    data_dict = {\"sft\" : np.stack([data['H1_SFTs_amplitudes'][:, :4096], data['L1_SFTs_amplitudes'][:, :4096]])}\n",
    "    return data_dict\n",
    "                 \n",
    "    \n",
    "def preprocess(sft):\n",
    "    sft = sft * 1e22\n",
    "    sft = sft.real**2 + sft.imag**2\n",
    "    return sft\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data[0] = data[0] / data[0].mean()\n",
    "    data[1] = data[1] / data[1].mean()\n",
    "    data = data.reshape(2, 360, 128, 32).mean(-1)  # compress 4096 -> 128\n",
    "    data = data - data.mean()\n",
    "    data = data / data.std()\n",
    "    return torch.tensor(data)\n",
    "\n",
    "\n",
    "def read_h5(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        k = f[filename]\n",
    "        h1 = k[\"H1\"]\n",
    "        l1 = k[\"L1\"]\n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "\n",
    "        data_dict = {\n",
    "            \"sft\": np.stack([h1_stft[:, :4096], l1_stft[:, :4096]]),\n",
    "            \"timestamps\": {\"H1\": h1_timestamp, \"L1\": l1_timestamp},\n",
    "        }\n",
    "        return data_dict\n",
    "#generating valid\n",
    "#class ValLoader(torch.utils.data.Dataset):\n",
    "#    \"\"\"\n",
    "#    dataset = Dataset(data_type, df)\n",
    "#\n",
    "#    img, y = dataset[i]\n",
    "#      img (np.float32): 2 x 360 x 128\n",
    "#      y (np.float32): label 0 or 1\n",
    "#    \"\"\"\n",
    "#    def __init__(self, df, freq_tfms=False):\n",
    "#        self.df = df\n",
    "#        self.tfms = freq_tfms\n",
    "#        \n",
    "#\n",
    "#    def __len__(self):\n",
    "#        return len(self.df)\n",
    "#\n",
    "#    def __getitem__(self, i):\n",
    "#        \"\"\"\n",
    "#        i (int): get ith data\n",
    "#        \"\"\"\n",
    "#        r = self.df.iloc[i]\n",
    "#        y = np.float32(r.target)\n",
    "#        img = normalize(preprocess(read_h5(r.id)['sft']))\n",
    "#        data = {\"sft\": img, \"target\": y}\n",
    "#        return data, f\"{Path(r.id).stem}.pth\"\n",
    "#\n",
    "#\n",
    "#\n",
    "#val_df = pd.read_csv('../data/SPLITS/V_22/val_df.csv')\n",
    "#comp_train = pd.read_csv('../data/train_labels.csv')\n",
    "#comp_train.columns = ['fn', 'target']\n",
    "#comp_train = comp_train.query('target>=0')\n",
    "#comp_train['fn'] = comp_train['fn'].apply(lambda x: Path('../data/train')/f'{x}.hdf5')\n",
    "#comp_train.columns = ['id', 'target']\n",
    "#comp_train['data_type'] = 'comp_train'\n",
    "#real_noise_fns =  sorted(\n",
    "#            Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "#            key=lambda x: str(x).split(\"_\")[-2])\n",
    "#real_noise_df = pd.DataFrame({\"id\": real_noise_fns[1100:], 'target': 0., 'snr': 0})\n",
    "#real_noise_df['id'] = real_noise_df['id'].apply(lambda x: Path(str(x).replace('.pth', '.h5')))\n",
    "#\n",
    "#val_df = pd.concat([val_df, comp_train, real_noise_df], ignore_index=True)\n",
    "#vld_ds = ValLoader(val_df)\n",
    "#folder_name = Path('cashe_dataset_eval')\n",
    "#os.makedirs(folder_name, exist_ok=True)\n",
    "#for i in tqdm(range(len(vld_ds))):\n",
    "#    data, name = vld_ds[i]\n",
    "#    torch.save(data, folder_name/name)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330b147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf873aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preoprocessed(save_folder, noise_fns, signal_fns):\n",
    "    noise_fn = random.choice(noise_fns)\n",
    "    signal_fn = random.choice(signal_fns)\n",
    "    \n",
    "    if np.random.rand() >= 0.6:\n",
    "        img = normalize(preprocess(read_torch(noise_fn)[\"sft\"])).numpy()\n",
    "        y = 0.0\n",
    "        if np.random.rand() <= 0.5:  # horizontal flip\n",
    "            img = np.flip(img, axis=1).copy()\n",
    "        if np.random.rand() <= 0.5:  # vertical flip\n",
    "            img = np.flip(img, axis=2).copy()\n",
    "        if np.random.rand() <= 0.5:  # vertical shift\n",
    "            img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "        if np.random.rand() <= 0.5:  # channel shuffle\n",
    "            img = img[np.random.permutation([0, 1]), ...]\n",
    "        img = torch.tensor(img)\n",
    "        name = get_random_name() + '.pth'\n",
    "    else:\n",
    "        \n",
    "        img = normalize(\n",
    "            preprocess(read_torch(noise_fn)[\"sft\"] + read_torch(signal_fn)[\"sft\"])\n",
    "        )\n",
    "        y = 1.0\n",
    "        name = noise_fn.stem + '_' + signal_fn.stem + '.pth'\n",
    "    data = {\"sft\": img, \"target\": y}\n",
    "   \n",
    "    return torch.save(data, save_folder/name)\n",
    "\n",
    "signal = list(Path(\"../data/custom_data/SIGNAL_V0/data\").glob(\"*.pth\")) + list(\n",
    "    Path(\"../data/custom_data/SIGNAL_V1/data\").glob(\"*.pth\")\n",
    ")\n",
    "\n",
    "real_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "fake_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V34/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "noise_sim = list(Path(\"../data/custom_data/DATA_V31_V32_NOISE/\").glob(\"*.pth\"))\n",
    "\n",
    "\n",
    "noise = real_noise_fns[:1100] + fake_noise_fns + list(np.random.choice(noise_sim, 2000))\n",
    "\n",
    "\n",
    "len(signal), len(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = Path('cashe_dataset')\n",
    "n_samples = 15000\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "#for i in tqdm(range(1000)):\n",
    "#    save_preoprocessed(folder_name, noise, signal)\n",
    "#\n",
    "Parallel(n_jobs=32)(\n",
    "    delayed(save_preoprocessed)(save_folder=folder_name, noise_fns=noise, signal_fns=signal)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb0469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edac2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal = list(Path(\"../data/custom_data/SIGNAL_V0/data\").glob(\"*.pth\"))\n",
    "#\n",
    "#real_noise_fns = sorted(\n",
    "#    Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "#    key=lambda x: str(x).split(\"_\")[-2],\n",
    "#)\n",
    "#\n",
    "#fake_noise_fns = sorted(\n",
    "#    Path(\"../data/custom_data/DATA_V34/data/\").glob(\"*.pth\"),\n",
    "#    key=lambda x: str(x).split(\"_\")[-2],\n",
    "#)\n",
    "#\n",
    "#noise = list(Path('../data/custom_data/DATA_V31_V32_NOISE').glob('*.pth'))\n",
    "#\n",
    "#\n",
    "#len(signal), len(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa87baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_name = Path('cashe_dataset')\n",
    "#n_samples = 20000\n",
    "#os.makedirs(folder_name, exist_ok=True)\n",
    "#Parallel(n_jobs=16)(\n",
    "#    delayed(save_preoprocessed)(save_folder=folder_name, noise_fns=noise, signal_fns=signal)\n",
    "#    for i in tqdm(range(n_samples))\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preoprocessed(save_folder, noise_fns, signal_fns):\n",
    "    noise_fn = random.choice(noise_fns)\n",
    "    signal_fn = random.choice(signal_fns)\n",
    "    prob = np.random.beta(0.5, 0.5)\n",
    "    \n",
    "    if np.random.rand() >= 0.5:\n",
    "        noise_2 = prob * torch.load(random.choice(noise_fns))['sft']\n",
    "        noise_1 = (1- prob) * torch.load(noise_fn)[\"sft\"]\n",
    "        img = normalize(preprocess(noise_2 + noise_1))\n",
    "        y = 0.0\n",
    "        name = f'mix_{prob}_{1-prob}_' + noise_fn.stem + '.pth'\n",
    "    else:\n",
    "        \n",
    "        img = normalize(\n",
    "            preprocess(prob * torch.load(noise_fn)[\"sft\"] +  (1-prob)*torch.load(signal_fn)[\"sft\"])\n",
    "        )\n",
    "        y = 1.0\n",
    "        name =  f'mix_{prob}_{1-prob}_' + noise_fn.stem + '_' + signal_fn.stem + '.pth'\n",
    "    data = {\"sft\": img, \"target\": y}\n",
    "   \n",
    "    return torch.save(data, save_folder/name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b961f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list(Path('cashe_dataset').glob('*.pth'))\n",
    "len(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = list(Path(\"../data/custom_data/SIGNAL_V0/data\").glob(\"*.pth\"))\n",
    "\n",
    "real_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "fake_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V34/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "noise = real_noise_fns[:1100] + fake_noise_fns + list(Path('../data/custom_data/DATA_V31_V32_NOISE').glob('*.pth'))\n",
    "len(signal), len(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12389720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_name = Path('cashe_dataset')\n",
    "n_samples = 25000\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "Parallel(n_jobs=16)(\n",
    "    delayed(save_preoprocessed)(save_folder=folder_name, noise_fns=noise, signal_fns=signal)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3723d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████▏                                          | 32118/74981 [00:43<00:57, 740.03it/s]"
     ]
    }
   ],
   "source": [
    "fns = list(Path('cashe_dataset').glob('*.pth'))\n",
    "for i in tqdm(fns):\n",
    "    try: torch.load(i)\n",
    "    except: \n",
    "        print(i)\n",
    "        os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10301f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
