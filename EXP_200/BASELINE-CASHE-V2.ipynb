{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e383b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import copy\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from x_transformers import  Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import exists\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fastai.vision.all import BCEWithLogitsLossFlat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import os\n",
    "from timm import create_model\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab37361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 64\n",
    "    nw = 4\n",
    "    model_name = \"convnext_large_in22k\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 20\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 1\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_200_BASELINE_CASHE_V2\"\n",
    "    mixup=False\n",
    "    exp_name = f\"{folder}_{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a785480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "\n",
    "def generate_report(df, p, fn):\n",
    "    pred = torch.sigmoid(p).cpu().numpy().reshape(-1)\n",
    "    val_df_eval = df.copy()\n",
    "    val_df_eval[\"pred\"] = pred\n",
    "    val_df_eval.to_csv(f\"{fn}_oof.csv\")\n",
    "\n",
    "    roc_100 = roc_auc_score(val_df_eval[\"target\"], val_df_eval[\"pred\"])\n",
    "    \n",
    "    tr_comp = val_df_eval.query('data_type==\"comp_train\"')\n",
    "    roc_comp_train = roc_auc_score(tr_comp['target'], tr_comp['pred'])\n",
    "    roc_0_50 = roc_auc_score(\n",
    "        get_snr(0, 50, val_df_eval)[\"target\"], get_snr(0, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_15_50 = roc_auc_score(\n",
    "        get_snr(15, 50, val_df_eval)[\"target\"], get_snr(15, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_25_50 = roc_auc_score(\n",
    "        get_snr(25, 50, val_df_eval)[\"target\"], get_snr(25, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_0_40 = roc_auc_score(\n",
    "        get_snr(0, 40, val_df_eval)[\"target\"], get_snr(0, 40, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    roc_0_30 = roc_auc_score(\n",
    "        get_snr(0, 30, val_df_eval)[\"target\"], get_snr(0, 30, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"roc_all\": roc_100,\n",
    "        \"roc_0_50\": roc_0_50,\n",
    "        \"roc_15_50\": roc_15_50,\n",
    "        \"roc_25_50\": roc_25_50,\n",
    "        \"roc_0_40\": roc_0_40,\n",
    "        \"roc_0_30\": roc_0_30,\n",
    "        \"roc_comp_train\": roc_comp_train\n",
    "    }\n",
    "\n",
    "class SaveModel:\n",
    "    def __init__(self, folder, exp_name, best=np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score < self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelMetric:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelEpoch:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder)\n",
    "        self.exp_name = exp_name\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        self.best = score\n",
    "        print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "        torch.save(model.state_dict(), f\"{self.folder/self.exp_name}_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def custom_auc_score(p, gt):\n",
    "    return roc_auc_score(gt.cpu().numpy(),  torch.sigmoid(p).cpu().numpy().reshape(-1))\n",
    "\n",
    "\n",
    "def fit_mixup(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    loss_fn,\n",
    "    opt,\n",
    "    metric,\n",
    "    val_df,\n",
    "    folder=\"models\",\n",
    "    exp_name=\"exp_00\",\n",
    "    device=None,\n",
    "    sched=None,\n",
    "    mixup_=False,\n",
    "    save_md=SaveModelEpoch,\n",
    "):\n",
    "    if device is None:\n",
    "        device = (\n",
    "            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    loss_fn_trn = loss_fn\n",
    "    if mixup_:\n",
    "        mixup = Mixup(num_classes=2, mixup_alpha=0.4, prob=0.8)\n",
    "        loss_fn_trn = BinaryCrossEntropy()\n",
    "    mb = master_bar(range(epochs))\n",
    "\n",
    "    mb.write(\n",
    "        [\n",
    "            \"epoch\",\n",
    "            \"train_loss\",\n",
    "            \"valid_loss\",\n",
    "            \"val_metric\",\n",
    "            \"roc_all\",\n",
    "            \"roc_0_50\",\n",
    "            \"roc_15_50\",\n",
    "            \"roc_25_50\",\n",
    "            \"roc_0_40\",\n",
    "            \"roc_0_30\",\n",
    "            \"roc_comp_train\",\n",
    "        ],\n",
    "        table=True,\n",
    "    )\n",
    "    model.to(device)  # we have to put our model on gpu\n",
    "    #scaler = torch.cuda.amp.GradScaler()  # this for half precision training\n",
    "    save_md = save_md(folder, exp_name)\n",
    "\n",
    "    for i in mb:  # iterating  epoch\n",
    "        trn_loss, val_loss = 0.0, 0.0\n",
    "        trn_n, val_n = len(train_dl.dataset), len(valid_dl.dataset)\n",
    "        model.train()  # set model for training\n",
    "        for (xb, yb) in progress_bar(train_dl, parent=mb):\n",
    "            xb, yb = xb.to(device), yb.to(device)  # putting batches to device\n",
    "            if mixup_:\n",
    "                xb, yb = mixup(xb, yb)\n",
    "           \n",
    "            out = model(xb)  # forward pass\n",
    "            loss = loss_fn_trn(out, yb)  # calulation loss\n",
    "\n",
    "            trn_loss += loss.item()\n",
    "            #print(loss.item())\n",
    "            opt.zero_grad()  # zeroing optimizer\n",
    "            loss.backward()  # backward\n",
    "            opt.step()  # optimzers step\n",
    "            if sched is not None:\n",
    "                sched.step()  # scuedular step\n",
    "\n",
    "        trn_loss /= mb.child.total\n",
    "\n",
    "        # putting model in eval mode\n",
    "        model.eval()\n",
    "        gt = []\n",
    "        pred = []\n",
    "        # after epooch is done we can run a validation dataloder and see how are doing\n",
    "        with torch.no_grad():\n",
    "            for (xb, yb) in progress_bar(valid_dl, parent=mb):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(out, yb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                gt.append(yb.detach())\n",
    "                pred.append(out.detach())\n",
    "        # calculating metric\n",
    "        metric_ = metric(torch.cat(pred), torch.cat(gt))\n",
    "        # saving model if necessary\n",
    "        save_md(metric_, model, i)\n",
    "        val_loss /= mb.child.total\n",
    "        dict_res = generate_report(val_df, torch.cat(pred), f\"{folder}/{exp_name}_{i}\")\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"trn_loss\": [trn_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"metric\": [metric_],\n",
    "                \"roc_all\": [dict_res[\"roc_all\"]],\n",
    "                \"roc_0_50\": [dict_res[\"roc_0_50\"]],\n",
    "                \"roc_15_50\": [dict_res[\"roc_15_50\"]],\n",
    "                \"roc_25_50\": [dict_res[\"roc_25_50\"]],\n",
    "                \"roc_0_40\": [dict_res[\"roc_0_40\"]],\n",
    "                \"roc_0_30\": [dict_res[\"roc_0_30\"]],\n",
    "                \"roc_comp_train\": [dict_res[\"roc_comp_train\"]]\n",
    "            }\n",
    "        ).to_csv(f\"{folder}/{exp_name}_{i}.csv\", index=False)\n",
    "        mb.write(\n",
    "            [\n",
    "                i,\n",
    "                f\"{trn_loss:.6f}\",\n",
    "                f\"{val_loss:.6f}\",\n",
    "                f\"{metric_:.6f}\",\n",
    "                f\"{dict_res['roc_all']:.6f}\",\n",
    "                f\"{dict_res['roc_0_50']:.6f}\",\n",
    "                f\"{dict_res['roc_15_50']:.6f}\",\n",
    "                f\"{dict_res['roc_25_50']:.6f}\",\n",
    "                f\"{dict_res['roc_0_40']:.6f}\",\n",
    "                f\"{dict_res['roc_0_30']:.6f}\",\n",
    "                f\"{dict_res['roc_comp_train']:.6f}\",\n",
    "            ],\n",
    "            table=True,\n",
    "        )\n",
    "    print(\"Training done\")\n",
    "    # loading the best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3eed83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mask(spec, T=10):\n",
    "    cloned = spec.clone().detach()\n",
    "    len_spectro = cloned.shape[2]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):\n",
    "        t = random.randrange(0, T)\n",
    "        t_zero = random.randrange(0, len_spectro - t)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (t_zero == t_zero + t): return cloned\n",
    "\n",
    "        mask_end = random.randrange(t_zero, t_zero + t)\n",
    "        cloned[:, :,t_zero:mask_end] = 0\n",
    "    return cloned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def freq_mask(spec, F=30):\n",
    "    cloned = spec.clone().detach()\n",
    "    num_mel_channels = cloned.shape[1]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):        \n",
    "        f = random.randrange(0, F)\n",
    "        f_zero = random.randrange(0, num_mel_channels - f)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "        mask_end = random.randrange(f_zero, f_zero + f) \n",
    "        cloned[:, f_zero:mask_end, :] = 0\n",
    "    \n",
    "    return cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d80e7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sft):\n",
    "    sft = sft * 1e22\n",
    "    sft = sft.real**2 + sft.imag**2\n",
    "    return sft\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data[0] = data[0] / data[0].mean()\n",
    "    data[1] = data[1] / data[1].mean()\n",
    "    data = data.reshape(2, 360, 128, 32).mean(-1)  # compress 4096 -> 128\n",
    "    data = data - data.mean()\n",
    "    data = data / data.std()\n",
    "    return torch.tensor(data)\n",
    "\n",
    "\n",
    "def read_h5(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        k = f[filename]\n",
    "        h1 = k[\"H1\"]\n",
    "        l1 = k[\"L1\"]\n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "        \n",
    "        data_dict = {\"sft\" : np.stack([h1_stft[:, :4096], l1_stft[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp}}\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "class TrainDatasetCashe(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, signal_fns, noise_fns, cashe_fns, freq_tfms=False, iteration=50000):\n",
    "        self.signal_fns = signal_fns\n",
    "        self.noise_fns = noise_fns\n",
    "        self.cashe_fns = cashe_fns\n",
    "        self.tfms = freq_tfms\n",
    "        self.iteration = iteration\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.iteration\n",
    "    \n",
    "    \n",
    "    def generate_random_file(self):\n",
    "        noise_fn = random.choice(self.noise_fns)\n",
    "        signal_fn = random.choice(self.signal_fns)\n",
    "        if np.random.rand() >= 0.5:\n",
    "            img = normalize(preprocess(torch.load(noise_fn)[\"sft\"]))\n",
    "            y = 0.\n",
    "        else:\n",
    "            img = normalize(\n",
    "                preprocess(torch.load(noise_fn)[\"sft\"] + torch.load(signal_fn)[\"sft\"])\n",
    "            )\n",
    "            y = 1.\n",
    "        return img, y\n",
    "    \n",
    "    def get_cashe(self):\n",
    "        fn = random.choice(self.cashe_fns)\n",
    "        data = torch.load(fn)\n",
    "        img, y = data['sft'], data['target']\n",
    "        return img, y\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if np.random.rand()>0.2:\n",
    "            img, y = self.generate_random_file()\n",
    "        else:\n",
    "            img, y = self.get_cashe()\n",
    "\n",
    "        if self.tfms:\n",
    "            if np.random.rand() <= 0.7:\n",
    "                img = freq_mask(img)\n",
    "            if np.random.rand() <= 0.7:\n",
    "                img = time_mask(img)\n",
    "            img = img.numpy()\n",
    "            if np.random.rand() <= 0.6:  # horizontal flip\n",
    "                img = np.flip(img, axis=1).copy()\n",
    "            if np.random.rand() <= 0.6:  # vertical flip\n",
    "                img = np.flip(img, axis=2).copy()\n",
    "            if np.random.rand() <= 0.6:  # vertical shift\n",
    "                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "            if np.random.rand() <= 0.5:  # channel shuffle\n",
    "                img = img[np.random.permutation([0, 1]), ...]\n",
    "        return img, y\n",
    "    \n",
    "class ValLoader(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        img = normalize(preprocess(read_h5(r.id)['sft']))\n",
    "        return img, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b5a5a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8155, 10369, 96853)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = list(Path('../data/custom_data/SIGNAL_V0/data').glob('*.pth')) + list(Path('../data/custom_data/SIGNAL_V1/data').glob('*.pth'))\n",
    "\n",
    "real_noise_fns =  sorted(\n",
    "            Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "            key=lambda x: str(x).split(\"_\")[-2])\n",
    "\n",
    "fake_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V34/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "\n",
    "noise = list(Path('../data/custom_data/DATA_V31_V32_NOISE').glob('*.pth')) + real_noise_fns[:1100] + fake_noise_fns\n",
    "cashe_fns = list(Path('cashe_dataset').glob('*.pth'))\n",
    "\n",
    "val_df = pd.read_csv('../data/SPLITS/V_22/val_df.csv')\n",
    "comp_train = pd.read_csv('../data/train_labels.csv')\n",
    "comp_train.columns = ['fn', 'target']\n",
    "comp_train = comp_train.query('target>=0')\n",
    "comp_train['fn'] = comp_train['fn'].apply(lambda x: Path('../data/train')/f'{x}.hdf5')\n",
    "comp_train.columns = ['id', 'target']\n",
    "comp_train['data_type'] = 'comp_train'\n",
    "real_noise_df = pd.DataFrame({\"id\": real_noise_fns[1100:], 'target': 0., 'snr': 0})\n",
    "real_noise_df['id'] = real_noise_df['id'].apply(lambda x: Path(str(x).replace('.pth', '.h5')))\n",
    "\n",
    "val_df = pd.concat([val_df, comp_train, real_noise_df], ignore_index=True)\n",
    "\n",
    "\n",
    "len(signal), len(noise), len(cashe_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "975a2564",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>roc_all</th>\n",
       "      <th>roc_0_50</th>\n",
       "      <th>roc_15_50</th>\n",
       "      <th>roc_25_50</th>\n",
       "      <th>roc_0_40</th>\n",
       "      <th>roc_0_30</th>\n",
       "      <th>roc_comp_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.411675</td>\n",
       "      <td>0.381713</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.690043</td>\n",
       "      <td>0.690043</td>\n",
       "      <td>0.694498</td>\n",
       "      <td>0.585235</td>\n",
       "      <td>0.548213</td>\n",
       "      <td>0.819725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.409109</td>\n",
       "      <td>0.383615</td>\n",
       "      <td>0.870498</td>\n",
       "      <td>0.870498</td>\n",
       "      <td>0.716987</td>\n",
       "      <td>0.716987</td>\n",
       "      <td>0.730141</td>\n",
       "      <td>0.618912</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.815375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.403133</td>\n",
       "      <td>0.388211</td>\n",
       "      <td>0.878658</td>\n",
       "      <td>0.878658</td>\n",
       "      <td>0.724989</td>\n",
       "      <td>0.724989</td>\n",
       "      <td>0.734296</td>\n",
       "      <td>0.610928</td>\n",
       "      <td>0.547418</td>\n",
       "      <td>0.809812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.392582</td>\n",
       "      <td>0.341972</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>0.748949</td>\n",
       "      <td>0.748949</td>\n",
       "      <td>0.757581</td>\n",
       "      <td>0.641817</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.821150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.387215</td>\n",
       "      <td>0.355375</td>\n",
       "      <td>0.890557</td>\n",
       "      <td>0.890557</td>\n",
       "      <td>0.746383</td>\n",
       "      <td>0.746383</td>\n",
       "      <td>0.756122</td>\n",
       "      <td>0.641095</td>\n",
       "      <td>0.563249</td>\n",
       "      <td>0.829263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.378186</td>\n",
       "      <td>0.386975</td>\n",
       "      <td>0.896273</td>\n",
       "      <td>0.896273</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.768536</td>\n",
       "      <td>0.652205</td>\n",
       "      <td>0.573025</td>\n",
       "      <td>0.825087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.376009</td>\n",
       "      <td>0.354354</td>\n",
       "      <td>0.899717</td>\n",
       "      <td>0.899717</td>\n",
       "      <td>0.766228</td>\n",
       "      <td>0.766228</td>\n",
       "      <td>0.776573</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.826450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.372276</td>\n",
       "      <td>0.381930</td>\n",
       "      <td>0.899178</td>\n",
       "      <td>0.899178</td>\n",
       "      <td>0.772366</td>\n",
       "      <td>0.772366</td>\n",
       "      <td>0.781193</td>\n",
       "      <td>0.666587</td>\n",
       "      <td>0.590109</td>\n",
       "      <td>0.828837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.372503</td>\n",
       "      <td>0.333841</td>\n",
       "      <td>0.900172</td>\n",
       "      <td>0.900172</td>\n",
       "      <td>0.762561</td>\n",
       "      <td>0.762561</td>\n",
       "      <td>0.774206</td>\n",
       "      <td>0.651188</td>\n",
       "      <td>0.570409</td>\n",
       "      <td>0.827475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.368537</td>\n",
       "      <td>0.349249</td>\n",
       "      <td>0.902978</td>\n",
       "      <td>0.902978</td>\n",
       "      <td>0.778882</td>\n",
       "      <td>0.778882</td>\n",
       "      <td>0.789159</td>\n",
       "      <td>0.678095</td>\n",
       "      <td>0.593533</td>\n",
       "      <td>0.826850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.366991</td>\n",
       "      <td>0.342813</td>\n",
       "      <td>0.904795</td>\n",
       "      <td>0.904795</td>\n",
       "      <td>0.779273</td>\n",
       "      <td>0.779273</td>\n",
       "      <td>0.793498</td>\n",
       "      <td>0.676614</td>\n",
       "      <td>0.578217</td>\n",
       "      <td>0.828762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.358866</td>\n",
       "      <td>0.327795</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.770892</td>\n",
       "      <td>0.770892</td>\n",
       "      <td>0.782226</td>\n",
       "      <td>0.665922</td>\n",
       "      <td>0.573418</td>\n",
       "      <td>0.827525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.356966</td>\n",
       "      <td>0.335308</td>\n",
       "      <td>0.907066</td>\n",
       "      <td>0.907066</td>\n",
       "      <td>0.776201</td>\n",
       "      <td>0.776201</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.673131</td>\n",
       "      <td>0.570787</td>\n",
       "      <td>0.830950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.357219</td>\n",
       "      <td>0.334183</td>\n",
       "      <td>0.909714</td>\n",
       "      <td>0.909714</td>\n",
       "      <td>0.784015</td>\n",
       "      <td>0.784015</td>\n",
       "      <td>0.797064</td>\n",
       "      <td>0.683092</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.833738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.355972</td>\n",
       "      <td>0.329609</td>\n",
       "      <td>0.910179</td>\n",
       "      <td>0.910179</td>\n",
       "      <td>0.788663</td>\n",
       "      <td>0.788663</td>\n",
       "      <td>0.800206</td>\n",
       "      <td>0.686870</td>\n",
       "      <td>0.586464</td>\n",
       "      <td>0.836350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.354608</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.910703</td>\n",
       "      <td>0.910703</td>\n",
       "      <td>0.788102</td>\n",
       "      <td>0.788102</td>\n",
       "      <td>0.800445</td>\n",
       "      <td>0.686178</td>\n",
       "      <td>0.589529</td>\n",
       "      <td>0.835450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.346965</td>\n",
       "      <td>0.330453</td>\n",
       "      <td>0.908022</td>\n",
       "      <td>0.908022</td>\n",
       "      <td>0.779450</td>\n",
       "      <td>0.779450</td>\n",
       "      <td>0.791244</td>\n",
       "      <td>0.674476</td>\n",
       "      <td>0.576509</td>\n",
       "      <td>0.834237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.349547</td>\n",
       "      <td>0.338917</td>\n",
       "      <td>0.912023</td>\n",
       "      <td>0.912023</td>\n",
       "      <td>0.792127</td>\n",
       "      <td>0.792127</td>\n",
       "      <td>0.805143</td>\n",
       "      <td>0.692679</td>\n",
       "      <td>0.596808</td>\n",
       "      <td>0.833075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.344533</td>\n",
       "      <td>0.332841</td>\n",
       "      <td>0.913313</td>\n",
       "      <td>0.913313</td>\n",
       "      <td>0.792260</td>\n",
       "      <td>0.792260</td>\n",
       "      <td>0.804566</td>\n",
       "      <td>0.691454</td>\n",
       "      <td>0.599445</td>\n",
       "      <td>0.836337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.344310</td>\n",
       "      <td>0.328631</td>\n",
       "      <td>0.914432</td>\n",
       "      <td>0.914432</td>\n",
       "      <td>0.794164</td>\n",
       "      <td>0.794164</td>\n",
       "      <td>0.806841</td>\n",
       "      <td>0.694565</td>\n",
       "      <td>0.603351</td>\n",
       "      <td>0.835475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with value: 0.86153799626086.\n",
      "Better model found at epoch 1 with value: 0.8704983687085304.\n",
      "Better model found at epoch 2 with value: 0.8786576670699072.\n",
      "Better model found at epoch 3 with value: 0.8915999486784705.\n",
      "Better model found at epoch 4 with value: 0.8905573884673192.\n",
      "Better model found at epoch 5 with value: 0.8962727739286631.\n",
      "Better model found at epoch 6 with value: 0.8997168151325196.\n",
      "Better model found at epoch 7 with value: 0.8991775724916603.\n",
      "Better model found at epoch 8 with value: 0.9001724769969572.\n",
      "Better model found at epoch 9 with value: 0.9029777484511897.\n",
      "Better model found at epoch 10 with value: 0.9047947138824737.\n",
      "Better model found at epoch 11 with value: 0.9004631768026687.\n",
      "Better model found at epoch 12 with value: 0.9070656915576085.\n",
      "Better model found at epoch 13 with value: 0.9097141574104622.\n",
      "Better model found at epoch 14 with value: 0.91017889218813.\n",
      "Better model found at epoch 15 with value: 0.9107025550789986.\n",
      "Better model found at epoch 16 with value: 0.9080221965614574.\n",
      "Better model found at epoch 17 with value: 0.9120233512958686.\n",
      "Better model found at epoch 18 with value: 0.9133128047215807.\n",
      "Better model found at epoch 19 with value: 0.914431614062099.\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Train - val split\n",
    "fold =0\n",
    "trn_ds = TrainDatasetCashe(signal, noise, cashe_fns, True)\n",
    "vld_ds = ValLoader(val_df)\n",
    "\n",
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "custom_model = create_model(\n",
    "                    CFG.model_name,\n",
    "                    pretrained=True,\n",
    "                    num_classes=1,\n",
    "                    in_chans=2,\n",
    "                )\n",
    "\n",
    "custom_model.load_state_dict(torch.load('EXP_200_BASELINE/EXP_200_BASELINE_convnext_large_in22k_0.pth'))\n",
    "\n",
    "opt = torch.optim.AdamW(custom_model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "loss_func = BCEWithLogitsLossFlat()\n",
    "warmup_steps = int(len(trn_dl) * int(CFG.warmup_pct * CFG.epoch))\n",
    "total_steps = int(len(trn_dl) * CFG.epoch)\n",
    "sched = get_linear_schedule_with_warmup(\n",
    "    opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "fit_mixup(\n",
    "    epochs=CFG.epoch,\n",
    "    model=custom_model,\n",
    "    train_dl=trn_dl,\n",
    "    valid_dl=vld_dl,\n",
    "    loss_fn=loss_func,\n",
    "    opt=opt,\n",
    "    val_df=val_df,\n",
    "    metric=custom_auc_score,\n",
    "    folder=CFG.folder,\n",
    "    exp_name=f\"{CFG.exp_name}_{fold}\",\n",
    "    device=\"cuda:0\",\n",
    "    sched=sched,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096bfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
