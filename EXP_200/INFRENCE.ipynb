{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e383b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import copy\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from x_transformers import  Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import exists\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fastai.vision.all import BCEWithLogitsLossFlat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import os\n",
    "from timm import create_model\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab37361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 32\n",
    "    nw = 4\n",
    "    model_name = \"convnext_large_in22k\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 12\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 1\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_200_BASELINE_CASHE_V3\"\n",
    "    mixup=False\n",
    "    exp_name = f\"{folder}_{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a785480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "\n",
    "def generate_report(df):\n",
    "    val_df_eval = df.copy()\n",
    "\n",
    "    roc_100 = roc_auc_score(val_df_eval[\"target\"], val_df_eval[\"pred\"])\n",
    "\n",
    "    roc_25_50 = roc_auc_score(\n",
    "        get_snr(30, 50, val_df_eval)[\"target\"], get_snr(30, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"roc_all\": roc_100,\n",
    "        \"roc_30_50\": roc_25_50,\n",
    "\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3eed83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mask(spec, T=10):\n",
    "    cloned = spec.clone().detach()\n",
    "    len_spectro = cloned.shape[2]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):\n",
    "        t = random.randrange(0, T)\n",
    "        t_zero = random.randrange(0, len_spectro - t)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (t_zero == t_zero + t): return cloned\n",
    "\n",
    "        mask_end = random.randrange(t_zero, t_zero + t)\n",
    "        cloned[:, :,t_zero:mask_end] = 0\n",
    "    return cloned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def freq_mask(spec, F=30):\n",
    "    cloned = spec.clone().detach()\n",
    "    num_mel_channels = cloned.shape[1]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):        \n",
    "        f = random.randrange(0, F)\n",
    "        f_zero = random.randrange(0, num_mel_channels - f)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "        mask_end = random.randrange(f_zero, f_zero + f) \n",
    "        cloned[:, f_zero:mask_end, :] = 0\n",
    "    \n",
    "    return cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e79a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pkl(filename):   \n",
    "    with open(filename, 'rb') as file1: \n",
    "        k = pickle.load(file1)\n",
    "        h1 = k[\"H1\"]['spectrogram']\n",
    "        l1 = k[\"L1\"]['spectrogram']\n",
    "        h1_timestamp = k[\"H1\"]['timestamps']\n",
    "        l1_timestamp = k[\"L1\"]['timestamps']\n",
    "        freq = k['frequency']\n",
    "        \n",
    "    data_dict = {\"sft\" : np.stack([h1[:, :4096], l1[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp}}\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d80e7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sft):\n",
    "    sft = sft * 1e22\n",
    "    sft = sft.real**2 + sft.imag**2\n",
    "    return sft\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data[0] = data[0] / data[0].mean()\n",
    "    data[1] = data[1] / data[1].mean()\n",
    "    data = data.reshape(2, 360, 128, 32).mean(-1)  # compress 4096 -> 128\n",
    "    data = data - data.mean()\n",
    "    data = data / data.std()\n",
    "    return torch.tensor(data)\n",
    "\n",
    "\n",
    "def read_h5(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        k = f[filename]\n",
    "        h1 = k[\"H1\"]\n",
    "        l1 = k[\"L1\"]\n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "        \n",
    "        data_dict = {\"sft\" : np.stack([h1_stft[:, :4096], l1_stft[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp}}\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "\n",
    "    \n",
    "class ValLoader(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        img = normalize(preprocess(read_h5(r.id)['sft']))\n",
    "        return img, y\n",
    "    \n",
    "    \n",
    "class ValLoaderPickle(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        img = normalize(read_pkl(str(r.id))['sft'])\n",
    "        return img.float(), y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7faec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_rot90_cw(x):\n",
    "    return x.rot90(k=-1, dims=(2, 3))\n",
    "\n",
    "\n",
    "def torch_fliplr(x: Tensor):\n",
    "    \"\"\"\n",
    "    Flip 4D image tensor horizontally\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return x.flip(3)\n",
    "\n",
    "\n",
    "def torch_flipud(x: Tensor):\n",
    "    \"\"\"\n",
    "    Flip 4D image tensor vertically\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return x.flip(2)\n",
    "\n",
    "\n",
    "def tencrop_image2label(model: nn.Module, image: Tensor) -> Tensor:\n",
    "    \"\"\"Test-time augmentation for image classification that takes five crops out of input tensor (4 on corners and central)\n",
    "    and averages predictions from them and from their horisontally-flipped versions (10-Crop TTA).\n",
    "    :param model: Classification model\n",
    "    :param image: Input image tensor\n",
    "    :param crop_size: Crop size. Must be smaller than image size\n",
    "    :return: Averaged logits\n",
    "    \"\"\"\n",
    "\n",
    "    output = (\n",
    "        torch.sigmoid(model(image))\n",
    "        + torch.sigmoid(model(torch_flipud(image)))\n",
    "        #+ torch.sigmoid(model(torch_fliplr(image)))\n",
    "       # + torch.sigmoid(model(torch_flipud(torch_fliplr(image))))\n",
    "    ) / 2.\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7005f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tta(dl, model):\n",
    "    res = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(vld_dl):\n",
    "            out = tencrop_image2label(model, x.cuda()).detach().cpu()\n",
    "            #out = torch.sigmoid(model(x.cuda())).detach().cpu()\n",
    "            res.append(out)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "fake_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V34/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "\n",
    "noise = (\n",
    "    list(Path(\"../data/custom_data/DATA_V31_V32_NOISE\").glob(\"*.pth\"))\n",
    "    + real_noise_fns[:1100]\n",
    "    + fake_noise_fns\n",
    ")\n",
    "cashe_fns = list(Path(\"cashe_dataset\").glob(\"*.pth\"))\n",
    "\n",
    "val_df = pd.read_csv(\"../data/SPLITS/V_22/val_df.csv\")\n",
    "comp_train = pd.read_csv(\"../data/train_labels.csv\")\n",
    "comp_train.columns = [\"fn\", \"target\"]\n",
    "comp_train = comp_train.query(\"target>=0\")\n",
    "comp_train[\"fn\"] = comp_train[\"fn\"].apply(lambda x: Path(\"../data/train\") / f\"{x}.hdf5\")\n",
    "comp_train.columns = [\"id\", \"target\"]\n",
    "comp_train[\"data_type\"] = \"comp_train\"\n",
    "real_noise_df = pd.DataFrame({\"id\": real_noise_fns[1100:], \"target\": 0.0, \"snr\": 0})\n",
    "real_noise_df[\"id\"] = real_noise_df[\"id\"].apply(\n",
    "    lambda x: Path(str(x).replace(\".pth\", \".h5\"))\n",
    ")\n",
    "\n",
    "val_df = pd.concat([val_df, comp_train, real_noise_df], ignore_index=True)\n",
    "val_df['id']= val_df['id'].apply(lambda x: Path(x))\n",
    "                             \n",
    "fns = [\"EXP_200_BASELINE_CASHE_V4/EXP_200_BASELINE_CASHE_V4_convnext_large_in22k_0_8.pth\"]\n",
    "\n",
    "custom_model = create_model(\n",
    "                    CFG.model_name,\n",
    "                    pretrained=True,\n",
    "                    num_classes=1,\n",
    "                    in_chans=2,\n",
    "                )\n",
    "\n",
    "custom_model.load_state_dict(torch.load(fns[0]))\n",
    "custom_model.cuda();\n",
    "custom_model.eval();\n",
    "sub_ds = ValLoader(val_df)\n",
    "vld_dl = DataLoader(\n",
    "    sub_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "res = predict_tta(vld_dl, custom_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3a459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416929a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['pred'] = torch.cat(res).view(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ac135",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(val_df['target'], val_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(val_df.query('data_type == \"comp_train\"')['target'], \n",
    "              val_df.query('data_type == \"comp_train\"')['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = [\"EXP_200_BASELINE_CASHE_V4/EXP_200_BASELINE_CASHE_V4_convnext_large_in22k_0_8.pth\"]\n",
    "\n",
    "custom_model = create_model(\n",
    "                    CFG.model_name,\n",
    "                    pretrained=True,\n",
    "                    num_classes=1,\n",
    "                    in_chans=2,\n",
    "                )\n",
    "\n",
    "custom_model.load_state_dict(torch.load(fns[0]))\n",
    "custom_model.cuda();\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "sub['id'] = sub['id'].apply(lambda x: Path(f'../data/test/{x}.hdf5'))\n",
    "sub_ds = ValLoader(sub)\n",
    "vld_dl = DataLoader(\n",
    "    sub_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    sub_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "res = predict_tta(vld_dl, custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target'] = torch.cat(res).view(-1).numpy()\n",
    "sub['id'] = sub['id'].apply(lambda x: x.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c986c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('EXP_200_BASELINE_CASHE_V4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b848b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36732d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afe8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80698dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9ff0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = [\"EXP_200_BASELINE_CASHE_V4/EXP_200_BASELINE_CASHE_V4_convnext_large_in22k_0_8.pth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a055ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6832ec7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______\n",
      "EXP_200_BASELINE_CASHE_V4/EXP_200_BASELINE_CASHE_V4_convnext_large_in22k_0_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▉                                                                    | 40/250 [00:27<01:29,  2.35it/s]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 18%|██████████████▎                                                                  | 44/250 [00:30<01:31,  2.25it/s]/tmp/ipykernel_1902750/2093617167.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data[1] = data[1] / data[1].mean()\n",
      " 40%|████████████████████████████████                                                | 100/250 [01:07<01:10,  2.12it/s]/tmp/ipykernel_1902750/2093617167.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data[0] = data[0] / data[0].mean()\n",
      " 49%|███████████████████████████████████████                                         | 122/250 [01:23<01:35,  1.35it/s]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 61%|████████████████████████████████████████████████▉                               | 153/250 [01:44<01:16,  1.26it/s]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 67%|█████████████████████████████████████████████████████▊                          | 168/250 [01:53<00:37,  2.18it/s]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:235: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      " 86%|█████████████████████████████████████████████████████████████████████           | 216/250 [02:24<00:14,  2.27it/s]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▉      | 231/250 [02:32<00:08,  2.28it/s]/tmp/ipykernel_1902750/2093617167.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data[1] = data[1] / data[1].mean()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [02:39<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "#predict train\n",
    "\n",
    "for mw in fns:\n",
    "    print('_______')\n",
    "    print(mw)\n",
    "    df_eval = pd.read_csv('../../val_v23/v23v.csv')\n",
    "    df_eval.id = df_eval.id.apply(lambda x: Path(f\"../../val_v23/v23_val/{x}.pickle\"))\n",
    "    sub_ds = ValLoaderPickle(df_eval)\n",
    "    vld_dl = DataLoader(\n",
    "        sub_ds,\n",
    "        batch_size=CFG.bs,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.nw,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    custom_model = create_model(\n",
    "                        CFG.model_name,\n",
    "                        pretrained=True,\n",
    "                        num_classes=1,\n",
    "                        in_chans=2,\n",
    "                    )\n",
    "\n",
    "    custom_model.load_state_dict(torch.load(mw, map_location=torch.device('cpu')))\n",
    "    custom_model.cuda();\n",
    "    custom_model.eval();\n",
    "\n",
    "    res = predict_tta(vld_dl, custom_model)\n",
    "    df_eval['pred'] = torch.cat(res).view(-1).numpy()\n",
    "    break\n",
    "    #df_eval['snr'] = df_eval['snr'].replace(np.nan, 0)\n",
    "    #df_eval = df_eval.dropna(subset='pred')\n",
    "    #dict_res = generate_report(df_eval)\n",
    "    #dict_res_400_500 = generate_report(df_eval.query('freq>400 and freq<500'))\n",
    "    #dict_res_300_400 = generate_report(df_eval.query('freq>300 and freq<400'))\n",
    "    #dict_res_200_300 = generate_report(df_eval.query('freq>200 and freq<300'))\n",
    "    #dict_res_50_200 = generate_report(df_eval.query('freq>50 and freq<200'))\n",
    "    print('___all___')\n",
    "    print(dict_res)\n",
    "    #print('freq_400_500:')\n",
    "    #print(dict_res_400_500)\n",
    "    #print('freq_300_400:')\n",
    "    #print(dict_res_300_400)\n",
    "    #print('freq_200_300:')\n",
    "    #print(dict_res_200_300)\n",
    "    #print('freq_50_200:')\n",
    "    #print(dict_res_50_200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57be0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_eval = df_eval.dropna(subset='pred')\n",
    "#roc_auc_score(df_eval['target'], df_eval['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91dd2bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "7970    1\n",
       "7971    0\n",
       "7972    1\n",
       "7973    1\n",
       "7974    0\n",
       "Name: target, Length: 7975, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d942929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.265349\n",
       "1       0.297388\n",
       "2       0.421611\n",
       "3       0.999995\n",
       "4       0.244278\n",
       "          ...   \n",
       "7970    0.999996\n",
       "7971    0.300561\n",
       "7972    0.246879\n",
       "7973    0.999998\n",
       "7974    0.324846\n",
       "Name: pred, Length: 7975, dtype: float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c8cc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.id = df_eval.id.apply(lambda x: x.stem)\n",
    "df_eval.to_csv('EXP_200_BASELINE_CASHE_V4_EVAL_V23_CORRECT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1fd5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
