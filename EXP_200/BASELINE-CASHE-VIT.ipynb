{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e383b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import copy\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from x_transformers import  Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import exists\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fastai.vision.all import BCEWithLogitsLossFlat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "from timm import create_model\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e59546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c909b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.vit_with_patch_merger import ViT\n",
    "from vit_pytorch.crossformer import CrossFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab37361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 128\n",
    "    nw = 4\n",
    "    model_name = \"VIT\"\n",
    "    lr = 1e-3\n",
    "    wd = 1e-4\n",
    "    epoch = 100\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 1\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_200_BASELINE_CASHE_VIT\"\n",
    "    mixup=False\n",
    "    exp_name = f\"{folder}_{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a785480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "\n",
    "def generate_report(df, p, fn):\n",
    "    pred = torch.sigmoid(p).cpu().numpy().reshape(-1)\n",
    "    val_df_eval = df.copy()\n",
    "    val_df_eval[\"pred\"] = pred\n",
    "    val_df_eval.to_csv(f\"{fn}_oof.csv\")\n",
    "\n",
    "    roc_100 = roc_auc_score(val_df_eval[\"target\"], val_df_eval[\"pred\"])\n",
    "    \n",
    "    tr_comp = val_df_eval.query('data_type==\"comp_train\"')\n",
    "    roc_comp_train = roc_auc_score(tr_comp['target'], tr_comp['pred'])\n",
    "    roc_0_50 = roc_auc_score(\n",
    "        get_snr(0, 50, val_df_eval)[\"target\"], get_snr(0, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_15_50 = roc_auc_score(\n",
    "        get_snr(15, 50, val_df_eval)[\"target\"], get_snr(15, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_25_50 = roc_auc_score(\n",
    "        get_snr(25, 50, val_df_eval)[\"target\"], get_snr(25, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_0_40 = roc_auc_score(\n",
    "        get_snr(0, 40, val_df_eval)[\"target\"], get_snr(0, 40, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    roc_0_30 = roc_auc_score(\n",
    "        get_snr(0, 30, val_df_eval)[\"target\"], get_snr(0, 30, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"roc_all\": roc_100,\n",
    "        \"roc_0_50\": roc_0_50,\n",
    "        \"roc_15_50\": roc_15_50,\n",
    "        \"roc_25_50\": roc_25_50,\n",
    "        \"roc_0_40\": roc_0_40,\n",
    "        \"roc_0_30\": roc_0_30,\n",
    "        \"roc_comp_train\": roc_comp_train\n",
    "    }\n",
    "\n",
    "class SaveModel:\n",
    "    def __init__(self, folder, exp_name, best=np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score < self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelMetric:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelEpoch:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder)\n",
    "        self.exp_name = exp_name\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        self.best = score\n",
    "        print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "        torch.save(model.state_dict(), f\"{self.folder/self.exp_name}_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def custom_auc_score(p, gt):\n",
    "    return roc_auc_score(gt.cpu().numpy(),  torch.sigmoid(p).cpu().numpy().reshape(-1))\n",
    "\n",
    "\n",
    "def fit_mixup(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    loss_fn,\n",
    "    opt,\n",
    "    metric,\n",
    "    val_df,\n",
    "    folder=\"models\",\n",
    "    exp_name=\"exp_00\",\n",
    "    device=None,\n",
    "    sched=None,\n",
    "    mixup_=False,\n",
    "    save_md=SaveModel,\n",
    "):\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    loss_fn_trn = loss_fn\n",
    "    if mixup_:\n",
    "        mixup = Mixup(num_classes=2, mixup_alpha=0.4, prob=0.8)\n",
    "        loss_fn_trn = BinaryCrossEntropy()\n",
    "    mb = master_bar(range(epochs))\n",
    "\n",
    "    mb.write(\n",
    "        [\n",
    "            \"epoch\",\n",
    "            \"train_loss\",\n",
    "            \"valid_loss\",\n",
    "            \"val_metric\",\n",
    "            \"roc_all\",\n",
    "            \"roc_0_50\",\n",
    "            \"roc_15_50\",\n",
    "            \"roc_25_50\",\n",
    "            \"roc_0_40\",\n",
    "            \"roc_0_30\",\n",
    "            \"roc_comp_train\",\n",
    "        ],\n",
    "        table=True,\n",
    "    )\n",
    "    model.to(device)  # we have to put our model on gpu\n",
    "    #scaler = torch.cuda.amp.GradScaler()  # this for half precision training\n",
    "    save_md = save_md(folder, exp_name)\n",
    "\n",
    "    for i in mb:  # iterating  epoch\n",
    "        trn_loss, val_loss = 0.0, 0.0\n",
    "        trn_n, val_n = len(train_dl.dataset), len(valid_dl.dataset)\n",
    "        model.train()  # set model for training\n",
    "        for (xb, yb) in progress_bar(train_dl, parent=mb):\n",
    "            xb, yb = xb.to(device), yb.to(device)  # putting batches to device\n",
    "            if mixup_:\n",
    "                xb, yb = mixup(xb, yb)\n",
    "           \n",
    "            out = model(xb)  # forward pass\n",
    "            loss = loss_fn_trn(out, yb)  # calulation loss\n",
    "\n",
    "            trn_loss += loss.item()\n",
    "            #print(loss.item())\n",
    "            opt.zero_grad()  # zeroing optimizer\n",
    "            loss.backward()  # backward\n",
    "            opt.step()  # optimzers step\n",
    "            if sched is not None:\n",
    "                sched.step()  # scuedular step\n",
    "\n",
    "        trn_loss /= mb.child.total\n",
    "\n",
    "        # putting model in eval mode\n",
    "        model.eval()\n",
    "        gt = []\n",
    "        pred = []\n",
    "        # after epooch is done we can run a validation dataloder and see how are doing\n",
    "        with torch.no_grad():\n",
    "            for (xb, yb) in progress_bar(valid_dl, parent=mb):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(out, yb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                gt.append(yb.detach())\n",
    "                pred.append(out.detach())\n",
    "        # calculating metric\n",
    "        metric_ = metric(torch.cat(pred), torch.cat(gt))\n",
    "        # saving model if necessary\n",
    "        save_md(metric_, model, i)\n",
    "        val_loss /= mb.child.total\n",
    "        dict_res = generate_report(val_df, torch.cat(pred), f\"{folder}/{exp_name}_{i}\")\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"trn_loss\": [trn_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"metric\": [metric_],\n",
    "                \"roc_all\": [dict_res[\"roc_all\"]],\n",
    "                \"roc_0_50\": [dict_res[\"roc_0_50\"]],\n",
    "                \"roc_15_50\": [dict_res[\"roc_15_50\"]],\n",
    "                \"roc_25_50\": [dict_res[\"roc_25_50\"]],\n",
    "                \"roc_0_40\": [dict_res[\"roc_0_40\"]],\n",
    "                \"roc_0_30\": [dict_res[\"roc_0_30\"]],\n",
    "                \"roc_comp_train\": [dict_res[\"roc_comp_train\"]]\n",
    "            }\n",
    "        ).to_csv(f\"{folder}/{exp_name}_{i}.csv\", index=False)\n",
    "        mb.write(\n",
    "            [\n",
    "                i,\n",
    "                f\"{trn_loss:.6f}\",\n",
    "                f\"{val_loss:.6f}\",\n",
    "                f\"{metric_:.6f}\",\n",
    "                f\"{dict_res['roc_all']:.6f}\",\n",
    "                f\"{dict_res['roc_0_50']:.6f}\",\n",
    "                f\"{dict_res['roc_15_50']:.6f}\",\n",
    "                f\"{dict_res['roc_25_50']:.6f}\",\n",
    "                f\"{dict_res['roc_0_40']:.6f}\",\n",
    "                f\"{dict_res['roc_0_30']:.6f}\",\n",
    "                f\"{dict_res['roc_comp_train']:.6f}\",\n",
    "            ],\n",
    "            table=True,\n",
    "        )\n",
    "    print(\"Training done\")\n",
    "    # loading the best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3eed83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mask(spec, T=10):\n",
    "    cloned = spec.clone().detach()\n",
    "    len_spectro = cloned.shape[2]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):\n",
    "        t = random.randrange(0, T)\n",
    "        t_zero = random.randrange(0, len_spectro - t)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (t_zero == t_zero + t): return cloned\n",
    "\n",
    "        mask_end = random.randrange(t_zero, t_zero + t)\n",
    "        cloned[:, :,t_zero:mask_end] = 0\n",
    "    return cloned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def freq_mask(spec, F=30):\n",
    "    cloned = spec.clone().detach()\n",
    "    num_mel_channels = cloned.shape[1]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):        \n",
    "        f = random.randrange(0, F)\n",
    "        f_zero = random.randrange(0, num_mel_channels - f)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "        mask_end = random.randrange(f_zero, f_zero + f) \n",
    "        cloned[:, f_zero:mask_end, :] = 0\n",
    "    \n",
    "    return cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80e7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sft):\n",
    "    sft = sft * 1e22\n",
    "    sft = sft.real**2 + sft.imag**2\n",
    "    return sft\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data[0] = data[0] / data[0].mean()\n",
    "    data[1] = data[1] / data[1].mean()\n",
    "    data = data.reshape(2, 360, 128, 32).mean(-1)  # compress 4096 -> 128\n",
    "    data = data - data.mean()\n",
    "    data = data / data.std()\n",
    "    return torch.tensor(data)\n",
    "\n",
    "\n",
    "def read_h5(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        k = f[filename]\n",
    "        h1 = k[\"H1\"]\n",
    "        l1 = k[\"L1\"]\n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "        \n",
    "        data_dict = {\"sft\" : np.stack([h1_stft[:, :4096], l1_stft[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp}}\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "class TrainDatasetCashe(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, signal_fns, noise_fns, cashe_fns, freq_tfms=False, iteration=75000):\n",
    "        self.signal_fns = signal_fns\n",
    "        self.noise_fns = noise_fns\n",
    "        self.cashe_fns = cashe_fns\n",
    "        self.tfms = freq_tfms\n",
    "        self.iteration = iteration\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cashe_fns)\n",
    "    \n",
    "    \n",
    "    def generate_random_file(self):\n",
    "        noise_fn = random.choice(self.noise_fns)\n",
    "        signal_fn = random.choice(self.signal_fns)\n",
    "        if np.random.rand() >= 0.5:\n",
    "            img = normalize(preprocess(torch.load(noise_fn)[\"sft\"]))\n",
    "            y = 0.\n",
    "        else:\n",
    "            img = normalize(\n",
    "                preprocess(torch.load(noise_fn)[\"sft\"] + torch.load(signal_fn)[\"sft\"])\n",
    "            )\n",
    "            y = 1.\n",
    "        return img, y\n",
    "    \n",
    "    def get_cashe(self, i):\n",
    "        #fn = random.choice(self.cashe_fns)\n",
    "        fn = self.cashe_fns[i]\n",
    "        data = torch.load(fn)\n",
    "        img, y = data['sft'], data['target']\n",
    "        return img, y\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img, y = self.get_cashe(i)\n",
    "\n",
    "        if self.tfms:\n",
    "            if np.random.rand() <= 0.5:\n",
    "                img = freq_mask(img)\n",
    "            if np.random.rand() <= 0.5:\n",
    "                img = time_mask(img)\n",
    "            img = img.numpy()\n",
    "            if np.random.rand() <= 0.6:  # horizontal flip\n",
    "                img = np.flip(img, axis=1).copy()\n",
    "            if np.random.rand() <= 0.6:  # vertical flip\n",
    "                img = np.flip(img, axis=2).copy()\n",
    "            if np.random.rand() <= 0.6:  # vertical shift\n",
    "                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "            if np.random.rand() <= 0.5:  # channel shuffle\n",
    "                img = img[np.random.permutation([0, 1]), ...]\n",
    "        return img, y\n",
    "    \n",
    "class ValLoader(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        img = torch.load(r.id)['sft']\n",
    "        return img, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b5a5a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 10671, 91086)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = list(Path('../data/custom_data/SIGNAL_V0/data').glob('*.pth'))\n",
    "\n",
    "real_noise_fns =  sorted(\n",
    "            Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "            key=lambda x: str(x).split(\"_\")[-2])\n",
    "\n",
    "fake_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V34/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "\n",
    "noise = list(Path('../data/custom_data/DATA_V31_V32_NOISE').glob('*.pth')) + real_noise_fns[:1100] + fake_noise_fns\n",
    "cashe_fns = list(Path('cashe_dataset').glob('*.pth'))\n",
    "\n",
    "val_df = pd.read_csv('../data/SPLITS/V_22/val_df.csv')\n",
    "comp_train = pd.read_csv('../data/train_labels.csv')\n",
    "comp_train.columns = ['fn', 'target']\n",
    "comp_train = comp_train.query('target>=0')\n",
    "comp_train['fn'] = comp_train['fn'].apply(lambda x: Path('../data/train')/f'{x}.hdf5')\n",
    "comp_train.columns = ['id', 'target']\n",
    "comp_train['data_type'] = 'comp_train'\n",
    "real_noise_df = pd.DataFrame({\"id\": real_noise_fns[1100:], 'target': 0., 'snr': 0})\n",
    "real_noise_df['id'] = real_noise_df['id'].apply(lambda x: Path(str(x).replace('.pth', '.h5')))\n",
    "\n",
    "val_df = pd.concat([val_df, comp_train, real_noise_df], ignore_index=True)\n",
    "#val_df = comp_train #pd.concat([val_df, comp_train, real_noise_df], ignore_index=True)\n",
    "val_df['id'] = val_df['id'].apply(lambda x: Path('cashe_dataset_eval')/f\"{Path(x).stem}.pth\")\n",
    "\n",
    "len(signal), len(noise), len(cashe_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ad8c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 cashe_dataset_eval/hb_2a1259daf9307954b6fc3f4596948072_noise.pth\n",
       "1                       cashe_dataset_eval/hb_fe2911c3fe2591b30fb9b81774055a70.pth\n",
       "2                 cashe_dataset_eval/hb_3e8aa29dffdd5deeeee1ede4663b8ff4_noise.pth\n",
       "3                 cashe_dataset_eval/hb_b25dfec297f7816e5c18694507262d04_noise.pth\n",
       "4                 cashe_dataset_eval/hb_91b24f77852228f71680e994ff31a349_noise.pth\n",
       "                                           ...                                    \n",
       "4693    cashe_dataset_eval/hb_ac6b569d6acc698cfa64f65d0d61cdaa_fe6f5a121_noise.pth\n",
       "4694    cashe_dataset_eval/hb_9d5b620c48841a419555bfa00af1bc29_fecaed870_noise.pth\n",
       "4695    cashe_dataset_eval/hb_9e35fc491b49468dc9f3a9176c50a04c_ff771a983_noise.pth\n",
       "4696    cashe_dataset_eval/hb_fba04b04ad6b588b75bcc52ec6c40b2f_ff7f1c8ba_noise.pth\n",
       "4697    cashe_dataset_eval/hb_454dfb63aaa2ee07dbe36c5328b37930_fffa17f67_noise.pth\n",
       "Name: id, Length: 4698, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975a2564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>roc_all</th>\n",
       "      <th>roc_0_50</th>\n",
       "      <th>roc_15_50</th>\n",
       "      <th>roc_25_50</th>\n",
       "      <th>roc_0_40</th>\n",
       "      <th>roc_0_30</th>\n",
       "      <th>roc_comp_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.676365</td>\n",
       "      <td>0.848184</td>\n",
       "      <td>0.552666</td>\n",
       "      <td>0.552666</td>\n",
       "      <td>0.549777</td>\n",
       "      <td>0.549777</td>\n",
       "      <td>0.548070</td>\n",
       "      <td>0.554396</td>\n",
       "      <td>0.582160</td>\n",
       "      <td>0.478625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.660071</td>\n",
       "      <td>0.680695</td>\n",
       "      <td>0.636342</td>\n",
       "      <td>0.636342</td>\n",
       "      <td>0.512941</td>\n",
       "      <td>0.512941</td>\n",
       "      <td>0.512486</td>\n",
       "      <td>0.508467</td>\n",
       "      <td>0.520183</td>\n",
       "      <td>0.677488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614383</td>\n",
       "      <td>0.648725</td>\n",
       "      <td>0.647968</td>\n",
       "      <td>0.647968</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>0.509733</td>\n",
       "      <td>0.490859</td>\n",
       "      <td>0.495809</td>\n",
       "      <td>0.710038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.603797</td>\n",
       "      <td>0.640319</td>\n",
       "      <td>0.670117</td>\n",
       "      <td>0.670117</td>\n",
       "      <td>0.527019</td>\n",
       "      <td>0.527019</td>\n",
       "      <td>0.526423</td>\n",
       "      <td>0.506798</td>\n",
       "      <td>0.518956</td>\n",
       "      <td>0.698862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.609033</td>\n",
       "      <td>0.656899</td>\n",
       "      <td>0.648289</td>\n",
       "      <td>0.648289</td>\n",
       "      <td>0.523507</td>\n",
       "      <td>0.523507</td>\n",
       "      <td>0.525281</td>\n",
       "      <td>0.503218</td>\n",
       "      <td>0.493457</td>\n",
       "      <td>0.674012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.607841</td>\n",
       "      <td>0.650965</td>\n",
       "      <td>0.655623</td>\n",
       "      <td>0.655623</td>\n",
       "      <td>0.516901</td>\n",
       "      <td>0.516901</td>\n",
       "      <td>0.525629</td>\n",
       "      <td>0.492881</td>\n",
       "      <td>0.469574</td>\n",
       "      <td>0.682937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.617954</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.616897</td>\n",
       "      <td>0.616897</td>\n",
       "      <td>0.494690</td>\n",
       "      <td>0.494690</td>\n",
       "      <td>0.493466</td>\n",
       "      <td>0.503021</td>\n",
       "      <td>0.542326</td>\n",
       "      <td>0.690613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.615944</td>\n",
       "      <td>0.659311</td>\n",
       "      <td>0.629917</td>\n",
       "      <td>0.629917</td>\n",
       "      <td>0.504809</td>\n",
       "      <td>0.504809</td>\n",
       "      <td>0.504413</td>\n",
       "      <td>0.508478</td>\n",
       "      <td>0.534129</td>\n",
       "      <td>0.682625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.611062</td>\n",
       "      <td>0.651937</td>\n",
       "      <td>0.655325</td>\n",
       "      <td>0.655325</td>\n",
       "      <td>0.523103</td>\n",
       "      <td>0.523103</td>\n",
       "      <td>0.524577</td>\n",
       "      <td>0.519965</td>\n",
       "      <td>0.533514</td>\n",
       "      <td>0.710600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.611126</td>\n",
       "      <td>0.671469</td>\n",
       "      <td>0.648771</td>\n",
       "      <td>0.648771</td>\n",
       "      <td>0.522005</td>\n",
       "      <td>0.522005</td>\n",
       "      <td>0.515834</td>\n",
       "      <td>0.507154</td>\n",
       "      <td>0.538906</td>\n",
       "      <td>0.705225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.614931</td>\n",
       "      <td>0.686105</td>\n",
       "      <td>0.643620</td>\n",
       "      <td>0.643620</td>\n",
       "      <td>0.531782</td>\n",
       "      <td>0.531782</td>\n",
       "      <td>0.531669</td>\n",
       "      <td>0.515606</td>\n",
       "      <td>0.527428</td>\n",
       "      <td>0.716200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.621889</td>\n",
       "      <td>0.666947</td>\n",
       "      <td>0.631094</td>\n",
       "      <td>0.631094</td>\n",
       "      <td>0.521798</td>\n",
       "      <td>0.521798</td>\n",
       "      <td>0.522435</td>\n",
       "      <td>0.505843</td>\n",
       "      <td>0.505785</td>\n",
       "      <td>0.686637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.624728</td>\n",
       "      <td>0.685139</td>\n",
       "      <td>0.622868</td>\n",
       "      <td>0.622868</td>\n",
       "      <td>0.520852</td>\n",
       "      <td>0.520852</td>\n",
       "      <td>0.522018</td>\n",
       "      <td>0.509032</td>\n",
       "      <td>0.506429</td>\n",
       "      <td>0.653562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.618742</td>\n",
       "      <td>0.687977</td>\n",
       "      <td>0.609898</td>\n",
       "      <td>0.609898</td>\n",
       "      <td>0.509008</td>\n",
       "      <td>0.509008</td>\n",
       "      <td>0.509133</td>\n",
       "      <td>0.495351</td>\n",
       "      <td>0.509053</td>\n",
       "      <td>0.680163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.618943</td>\n",
       "      <td>0.685349</td>\n",
       "      <td>0.644260</td>\n",
       "      <td>0.644260</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.538929</td>\n",
       "      <td>0.531065</td>\n",
       "      <td>0.551467</td>\n",
       "      <td>0.672662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.620258</td>\n",
       "      <td>0.684741</td>\n",
       "      <td>0.616004</td>\n",
       "      <td>0.616004</td>\n",
       "      <td>0.519127</td>\n",
       "      <td>0.519127</td>\n",
       "      <td>0.516997</td>\n",
       "      <td>0.523524</td>\n",
       "      <td>0.519893</td>\n",
       "      <td>0.659112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.621861</td>\n",
       "      <td>0.684288</td>\n",
       "      <td>0.637667</td>\n",
       "      <td>0.637667</td>\n",
       "      <td>0.535938</td>\n",
       "      <td>0.535938</td>\n",
       "      <td>0.539284</td>\n",
       "      <td>0.527524</td>\n",
       "      <td>0.507468</td>\n",
       "      <td>0.669037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.636680</td>\n",
       "      <td>0.700326</td>\n",
       "      <td>0.593748</td>\n",
       "      <td>0.593748</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>0.506025</td>\n",
       "      <td>0.504491</td>\n",
       "      <td>0.529175</td>\n",
       "      <td>0.654137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.634519</td>\n",
       "      <td>0.697315</td>\n",
       "      <td>0.608782</td>\n",
       "      <td>0.608782</td>\n",
       "      <td>0.516169</td>\n",
       "      <td>0.516169</td>\n",
       "      <td>0.518309</td>\n",
       "      <td>0.511566</td>\n",
       "      <td>0.496849</td>\n",
       "      <td>0.676900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.635796</td>\n",
       "      <td>0.704527</td>\n",
       "      <td>0.578971</td>\n",
       "      <td>0.578971</td>\n",
       "      <td>0.485400</td>\n",
       "      <td>0.485400</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.497691</td>\n",
       "      <td>0.674012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.632727</td>\n",
       "      <td>0.690645</td>\n",
       "      <td>0.606206</td>\n",
       "      <td>0.606206</td>\n",
       "      <td>0.510107</td>\n",
       "      <td>0.510107</td>\n",
       "      <td>0.509313</td>\n",
       "      <td>0.493580</td>\n",
       "      <td>0.478798</td>\n",
       "      <td>0.676462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.631867</td>\n",
       "      <td>0.692125</td>\n",
       "      <td>0.602020</td>\n",
       "      <td>0.602020</td>\n",
       "      <td>0.512127</td>\n",
       "      <td>0.512127</td>\n",
       "      <td>0.509273</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>0.645162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.628857</td>\n",
       "      <td>0.692958</td>\n",
       "      <td>0.605396</td>\n",
       "      <td>0.605396</td>\n",
       "      <td>0.510599</td>\n",
       "      <td>0.510599</td>\n",
       "      <td>0.507965</td>\n",
       "      <td>0.505146</td>\n",
       "      <td>0.500665</td>\n",
       "      <td>0.636350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.629169</td>\n",
       "      <td>0.676277</td>\n",
       "      <td>0.581894</td>\n",
       "      <td>0.581894</td>\n",
       "      <td>0.493772</td>\n",
       "      <td>0.493772</td>\n",
       "      <td>0.489121</td>\n",
       "      <td>0.486048</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.635950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.627951</td>\n",
       "      <td>0.679363</td>\n",
       "      <td>0.594915</td>\n",
       "      <td>0.594915</td>\n",
       "      <td>0.503499</td>\n",
       "      <td>0.503499</td>\n",
       "      <td>0.498714</td>\n",
       "      <td>0.495037</td>\n",
       "      <td>0.491864</td>\n",
       "      <td>0.652687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.629247</td>\n",
       "      <td>0.671355</td>\n",
       "      <td>0.599066</td>\n",
       "      <td>0.599066</td>\n",
       "      <td>0.503047</td>\n",
       "      <td>0.503047</td>\n",
       "      <td>0.496360</td>\n",
       "      <td>0.495832</td>\n",
       "      <td>0.514346</td>\n",
       "      <td>0.649188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.628173</td>\n",
       "      <td>0.671514</td>\n",
       "      <td>0.594674</td>\n",
       "      <td>0.594674</td>\n",
       "      <td>0.491123</td>\n",
       "      <td>0.491123</td>\n",
       "      <td>0.483574</td>\n",
       "      <td>0.471495</td>\n",
       "      <td>0.502459</td>\n",
       "      <td>0.662025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.675041</td>\n",
       "      <td>0.589750</td>\n",
       "      <td>0.589750</td>\n",
       "      <td>0.486196</td>\n",
       "      <td>0.486196</td>\n",
       "      <td>0.476143</td>\n",
       "      <td>0.466826</td>\n",
       "      <td>0.516319</td>\n",
       "      <td>0.664425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.626916</td>\n",
       "      <td>0.687520</td>\n",
       "      <td>0.579760</td>\n",
       "      <td>0.579760</td>\n",
       "      <td>0.495215</td>\n",
       "      <td>0.495215</td>\n",
       "      <td>0.487332</td>\n",
       "      <td>0.479796</td>\n",
       "      <td>0.499041</td>\n",
       "      <td>0.627587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.629190</td>\n",
       "      <td>0.689436</td>\n",
       "      <td>0.584016</td>\n",
       "      <td>0.584016</td>\n",
       "      <td>0.493302</td>\n",
       "      <td>0.493302</td>\n",
       "      <td>0.486459</td>\n",
       "      <td>0.478845</td>\n",
       "      <td>0.502934</td>\n",
       "      <td>0.631200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.628339</td>\n",
       "      <td>0.686398</td>\n",
       "      <td>0.591955</td>\n",
       "      <td>0.591955</td>\n",
       "      <td>0.511152</td>\n",
       "      <td>0.511152</td>\n",
       "      <td>0.508563</td>\n",
       "      <td>0.492138</td>\n",
       "      <td>0.501085</td>\n",
       "      <td>0.629487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.635218</td>\n",
       "      <td>0.695959</td>\n",
       "      <td>0.576625</td>\n",
       "      <td>0.576625</td>\n",
       "      <td>0.510683</td>\n",
       "      <td>0.510683</td>\n",
       "      <td>0.506433</td>\n",
       "      <td>0.504884</td>\n",
       "      <td>0.535744</td>\n",
       "      <td>0.629150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.637935</td>\n",
       "      <td>0.699824</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>0.495151</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.627537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.634831</td>\n",
       "      <td>0.703332</td>\n",
       "      <td>0.583166</td>\n",
       "      <td>0.583166</td>\n",
       "      <td>0.520623</td>\n",
       "      <td>0.520623</td>\n",
       "      <td>0.516981</td>\n",
       "      <td>0.504650</td>\n",
       "      <td>0.524585</td>\n",
       "      <td>0.641463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.641171</td>\n",
       "      <td>0.701816</td>\n",
       "      <td>0.569803</td>\n",
       "      <td>0.569803</td>\n",
       "      <td>0.516240</td>\n",
       "      <td>0.516240</td>\n",
       "      <td>0.510984</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.544048</td>\n",
       "      <td>0.626862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.642995</td>\n",
       "      <td>0.742621</td>\n",
       "      <td>0.569470</td>\n",
       "      <td>0.569470</td>\n",
       "      <td>0.520735</td>\n",
       "      <td>0.520735</td>\n",
       "      <td>0.517344</td>\n",
       "      <td>0.513752</td>\n",
       "      <td>0.530381</td>\n",
       "      <td>0.590425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.641062</td>\n",
       "      <td>0.698516</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>0.495344</td>\n",
       "      <td>0.495344</td>\n",
       "      <td>0.490378</td>\n",
       "      <td>0.498914</td>\n",
       "      <td>0.521138</td>\n",
       "      <td>0.608025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.641681</td>\n",
       "      <td>0.695040</td>\n",
       "      <td>0.552975</td>\n",
       "      <td>0.552975</td>\n",
       "      <td>0.497035</td>\n",
       "      <td>0.497035</td>\n",
       "      <td>0.492632</td>\n",
       "      <td>0.497336</td>\n",
       "      <td>0.510342</td>\n",
       "      <td>0.638850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.643515</td>\n",
       "      <td>0.698755</td>\n",
       "      <td>0.565932</td>\n",
       "      <td>0.565932</td>\n",
       "      <td>0.510448</td>\n",
       "      <td>0.510448</td>\n",
       "      <td>0.511017</td>\n",
       "      <td>0.500898</td>\n",
       "      <td>0.489891</td>\n",
       "      <td>0.625725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.643281</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.552491</td>\n",
       "      <td>0.552491</td>\n",
       "      <td>0.491004</td>\n",
       "      <td>0.491004</td>\n",
       "      <td>0.489398</td>\n",
       "      <td>0.490473</td>\n",
       "      <td>0.498823</td>\n",
       "      <td>0.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.641926</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>0.556131</td>\n",
       "      <td>0.556131</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0.496750</td>\n",
       "      <td>0.485276</td>\n",
       "      <td>0.472382</td>\n",
       "      <td>0.627488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.642050</td>\n",
       "      <td>0.702278</td>\n",
       "      <td>0.547520</td>\n",
       "      <td>0.547520</td>\n",
       "      <td>0.488514</td>\n",
       "      <td>0.488514</td>\n",
       "      <td>0.488891</td>\n",
       "      <td>0.475704</td>\n",
       "      <td>0.483496</td>\n",
       "      <td>0.622869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.641470</td>\n",
       "      <td>0.694338</td>\n",
       "      <td>0.548013</td>\n",
       "      <td>0.548013</td>\n",
       "      <td>0.480034</td>\n",
       "      <td>0.480034</td>\n",
       "      <td>0.476363</td>\n",
       "      <td>0.472991</td>\n",
       "      <td>0.481892</td>\n",
       "      <td>0.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.641478</td>\n",
       "      <td>0.696962</td>\n",
       "      <td>0.548962</td>\n",
       "      <td>0.548962</td>\n",
       "      <td>0.472726</td>\n",
       "      <td>0.472726</td>\n",
       "      <td>0.472533</td>\n",
       "      <td>0.459237</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.630812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.638631</td>\n",
       "      <td>0.700656</td>\n",
       "      <td>0.556794</td>\n",
       "      <td>0.556794</td>\n",
       "      <td>0.483501</td>\n",
       "      <td>0.483501</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.474509</td>\n",
       "      <td>0.474124</td>\n",
       "      <td>0.654062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.636771</td>\n",
       "      <td>0.691070</td>\n",
       "      <td>0.563206</td>\n",
       "      <td>0.563206</td>\n",
       "      <td>0.490341</td>\n",
       "      <td>0.490341</td>\n",
       "      <td>0.486788</td>\n",
       "      <td>0.478985</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.653487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.636835</td>\n",
       "      <td>0.698073</td>\n",
       "      <td>0.553674</td>\n",
       "      <td>0.553674</td>\n",
       "      <td>0.489415</td>\n",
       "      <td>0.489415</td>\n",
       "      <td>0.484903</td>\n",
       "      <td>0.486810</td>\n",
       "      <td>0.495043</td>\n",
       "      <td>0.641163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.637262</td>\n",
       "      <td>0.715852</td>\n",
       "      <td>0.567405</td>\n",
       "      <td>0.567405</td>\n",
       "      <td>0.490308</td>\n",
       "      <td>0.490308</td>\n",
       "      <td>0.484321</td>\n",
       "      <td>0.489728</td>\n",
       "      <td>0.498560</td>\n",
       "      <td>0.666850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.637455</td>\n",
       "      <td>0.695050</td>\n",
       "      <td>0.558619</td>\n",
       "      <td>0.558619</td>\n",
       "      <td>0.486246</td>\n",
       "      <td>0.486246</td>\n",
       "      <td>0.479810</td>\n",
       "      <td>0.484060</td>\n",
       "      <td>0.495949</td>\n",
       "      <td>0.657169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.635076</td>\n",
       "      <td>0.693455</td>\n",
       "      <td>0.561121</td>\n",
       "      <td>0.561121</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.482211</td>\n",
       "      <td>0.481882</td>\n",
       "      <td>0.494002</td>\n",
       "      <td>0.674488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.632503</td>\n",
       "      <td>0.703247</td>\n",
       "      <td>0.573753</td>\n",
       "      <td>0.573753</td>\n",
       "      <td>0.491669</td>\n",
       "      <td>0.491669</td>\n",
       "      <td>0.485262</td>\n",
       "      <td>0.483691</td>\n",
       "      <td>0.493705</td>\n",
       "      <td>0.664775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.631539</td>\n",
       "      <td>0.680704</td>\n",
       "      <td>0.557604</td>\n",
       "      <td>0.557604</td>\n",
       "      <td>0.487539</td>\n",
       "      <td>0.487539</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.483536</td>\n",
       "      <td>0.511952</td>\n",
       "      <td>0.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.629595</td>\n",
       "      <td>0.699913</td>\n",
       "      <td>0.581230</td>\n",
       "      <td>0.581230</td>\n",
       "      <td>0.498349</td>\n",
       "      <td>0.498349</td>\n",
       "      <td>0.493399</td>\n",
       "      <td>0.487411</td>\n",
       "      <td>0.491652</td>\n",
       "      <td>0.662650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.630020</td>\n",
       "      <td>0.681026</td>\n",
       "      <td>0.573534</td>\n",
       "      <td>0.573534</td>\n",
       "      <td>0.490930</td>\n",
       "      <td>0.490930</td>\n",
       "      <td>0.485627</td>\n",
       "      <td>0.487882</td>\n",
       "      <td>0.506341</td>\n",
       "      <td>0.665687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.627469</td>\n",
       "      <td>0.685840</td>\n",
       "      <td>0.586687</td>\n",
       "      <td>0.586687</td>\n",
       "      <td>0.503115</td>\n",
       "      <td>0.503115</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.503081</td>\n",
       "      <td>0.517216</td>\n",
       "      <td>0.674737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.628666</td>\n",
       "      <td>0.686829</td>\n",
       "      <td>0.576836</td>\n",
       "      <td>0.576836</td>\n",
       "      <td>0.499323</td>\n",
       "      <td>0.499323</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>0.503754</td>\n",
       "      <td>0.522389</td>\n",
       "      <td>0.671225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.626766</td>\n",
       "      <td>0.682673</td>\n",
       "      <td>0.576952</td>\n",
       "      <td>0.576952</td>\n",
       "      <td>0.497170</td>\n",
       "      <td>0.497170</td>\n",
       "      <td>0.490021</td>\n",
       "      <td>0.503616</td>\n",
       "      <td>0.531160</td>\n",
       "      <td>0.673288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.624187</td>\n",
       "      <td>0.673960</td>\n",
       "      <td>0.576777</td>\n",
       "      <td>0.576777</td>\n",
       "      <td>0.497651</td>\n",
       "      <td>0.497651</td>\n",
       "      <td>0.491613</td>\n",
       "      <td>0.501488</td>\n",
       "      <td>0.530058</td>\n",
       "      <td>0.679963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.623830</td>\n",
       "      <td>0.677672</td>\n",
       "      <td>0.587315</td>\n",
       "      <td>0.587315</td>\n",
       "      <td>0.496953</td>\n",
       "      <td>0.496953</td>\n",
       "      <td>0.491310</td>\n",
       "      <td>0.498822</td>\n",
       "      <td>0.527281</td>\n",
       "      <td>0.683987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.621425</td>\n",
       "      <td>0.670120</td>\n",
       "      <td>0.585571</td>\n",
       "      <td>0.585571</td>\n",
       "      <td>0.499317</td>\n",
       "      <td>0.499317</td>\n",
       "      <td>0.494174</td>\n",
       "      <td>0.499736</td>\n",
       "      <td>0.518898</td>\n",
       "      <td>0.674275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.621216</td>\n",
       "      <td>0.677054</td>\n",
       "      <td>0.596884</td>\n",
       "      <td>0.596884</td>\n",
       "      <td>0.498105</td>\n",
       "      <td>0.498105</td>\n",
       "      <td>0.493158</td>\n",
       "      <td>0.501957</td>\n",
       "      <td>0.513738</td>\n",
       "      <td>0.679450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.620554</td>\n",
       "      <td>0.667245</td>\n",
       "      <td>0.587386</td>\n",
       "      <td>0.587386</td>\n",
       "      <td>0.499962</td>\n",
       "      <td>0.499962</td>\n",
       "      <td>0.496489</td>\n",
       "      <td>0.506086</td>\n",
       "      <td>0.506949</td>\n",
       "      <td>0.653738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.620175</td>\n",
       "      <td>0.668588</td>\n",
       "      <td>0.591575</td>\n",
       "      <td>0.591575</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.488381</td>\n",
       "      <td>0.495218</td>\n",
       "      <td>0.492235</td>\n",
       "      <td>0.664562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.618556</td>\n",
       "      <td>0.673297</td>\n",
       "      <td>0.603073</td>\n",
       "      <td>0.603073</td>\n",
       "      <td>0.497530</td>\n",
       "      <td>0.497530</td>\n",
       "      <td>0.493023</td>\n",
       "      <td>0.500714</td>\n",
       "      <td>0.502655</td>\n",
       "      <td>0.684212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.619422</td>\n",
       "      <td>0.664529</td>\n",
       "      <td>0.596350</td>\n",
       "      <td>0.596350</td>\n",
       "      <td>0.499571</td>\n",
       "      <td>0.499571</td>\n",
       "      <td>0.495123</td>\n",
       "      <td>0.502315</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>0.679656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.616230</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.600794</td>\n",
       "      <td>0.600794</td>\n",
       "      <td>0.497469</td>\n",
       "      <td>0.497469</td>\n",
       "      <td>0.492591</td>\n",
       "      <td>0.500182</td>\n",
       "      <td>0.509575</td>\n",
       "      <td>0.683388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.617469</td>\n",
       "      <td>0.668472</td>\n",
       "      <td>0.599794</td>\n",
       "      <td>0.599794</td>\n",
       "      <td>0.491674</td>\n",
       "      <td>0.491674</td>\n",
       "      <td>0.486538</td>\n",
       "      <td>0.488077</td>\n",
       "      <td>0.492291</td>\n",
       "      <td>0.691625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.618052</td>\n",
       "      <td>0.668795</td>\n",
       "      <td>0.597763</td>\n",
       "      <td>0.597763</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>0.487359</td>\n",
       "      <td>0.488541</td>\n",
       "      <td>0.490609</td>\n",
       "      <td>0.699925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.617845</td>\n",
       "      <td>0.669303</td>\n",
       "      <td>0.600109</td>\n",
       "      <td>0.600109</td>\n",
       "      <td>0.490047</td>\n",
       "      <td>0.490047</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>0.487936</td>\n",
       "      <td>0.491047</td>\n",
       "      <td>0.692087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.617360</td>\n",
       "      <td>0.660267</td>\n",
       "      <td>0.603297</td>\n",
       "      <td>0.603297</td>\n",
       "      <td>0.489948</td>\n",
       "      <td>0.489948</td>\n",
       "      <td>0.485618</td>\n",
       "      <td>0.486420</td>\n",
       "      <td>0.489817</td>\n",
       "      <td>0.691463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.617690</td>\n",
       "      <td>0.669344</td>\n",
       "      <td>0.606640</td>\n",
       "      <td>0.606640</td>\n",
       "      <td>0.492437</td>\n",
       "      <td>0.492437</td>\n",
       "      <td>0.487951</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.491039</td>\n",
       "      <td>0.693188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.616389</td>\n",
       "      <td>0.664114</td>\n",
       "      <td>0.607847</td>\n",
       "      <td>0.607847</td>\n",
       "      <td>0.495382</td>\n",
       "      <td>0.495382</td>\n",
       "      <td>0.491395</td>\n",
       "      <td>0.490799</td>\n",
       "      <td>0.492766</td>\n",
       "      <td>0.692163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.615919</td>\n",
       "      <td>0.668327</td>\n",
       "      <td>0.607898</td>\n",
       "      <td>0.607898</td>\n",
       "      <td>0.495690</td>\n",
       "      <td>0.495690</td>\n",
       "      <td>0.491363</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.502064</td>\n",
       "      <td>0.706050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.615015</td>\n",
       "      <td>0.666837</td>\n",
       "      <td>0.601057</td>\n",
       "      <td>0.601057</td>\n",
       "      <td>0.491217</td>\n",
       "      <td>0.491217</td>\n",
       "      <td>0.487530</td>\n",
       "      <td>0.484588</td>\n",
       "      <td>0.491140</td>\n",
       "      <td>0.699763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.614642</td>\n",
       "      <td>0.668441</td>\n",
       "      <td>0.601390</td>\n",
       "      <td>0.601390</td>\n",
       "      <td>0.492999</td>\n",
       "      <td>0.492999</td>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.490850</td>\n",
       "      <td>0.497788</td>\n",
       "      <td>0.688387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.615310</td>\n",
       "      <td>0.662803</td>\n",
       "      <td>0.600693</td>\n",
       "      <td>0.600693</td>\n",
       "      <td>0.491560</td>\n",
       "      <td>0.491560</td>\n",
       "      <td>0.486504</td>\n",
       "      <td>0.486518</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>0.689887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.614071</td>\n",
       "      <td>0.660838</td>\n",
       "      <td>0.600720</td>\n",
       "      <td>0.600720</td>\n",
       "      <td>0.491073</td>\n",
       "      <td>0.491073</td>\n",
       "      <td>0.485916</td>\n",
       "      <td>0.486316</td>\n",
       "      <td>0.494168</td>\n",
       "      <td>0.684075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.614255</td>\n",
       "      <td>0.665054</td>\n",
       "      <td>0.604488</td>\n",
       "      <td>0.604488</td>\n",
       "      <td>0.490851</td>\n",
       "      <td>0.490851</td>\n",
       "      <td>0.486746</td>\n",
       "      <td>0.483929</td>\n",
       "      <td>0.480432</td>\n",
       "      <td>0.685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.615899</td>\n",
       "      <td>0.664916</td>\n",
       "      <td>0.605508</td>\n",
       "      <td>0.605508</td>\n",
       "      <td>0.493129</td>\n",
       "      <td>0.493129</td>\n",
       "      <td>0.489170</td>\n",
       "      <td>0.486103</td>\n",
       "      <td>0.490129</td>\n",
       "      <td>0.689312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.615225</td>\n",
       "      <td>0.665845</td>\n",
       "      <td>0.609638</td>\n",
       "      <td>0.609638</td>\n",
       "      <td>0.492969</td>\n",
       "      <td>0.492969</td>\n",
       "      <td>0.489505</td>\n",
       "      <td>0.486865</td>\n",
       "      <td>0.486107</td>\n",
       "      <td>0.690500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.614687</td>\n",
       "      <td>0.666708</td>\n",
       "      <td>0.606850</td>\n",
       "      <td>0.606850</td>\n",
       "      <td>0.496920</td>\n",
       "      <td>0.496920</td>\n",
       "      <td>0.492824</td>\n",
       "      <td>0.488269</td>\n",
       "      <td>0.492082</td>\n",
       "      <td>0.687825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.614999</td>\n",
       "      <td>0.667926</td>\n",
       "      <td>0.604890</td>\n",
       "      <td>0.604890</td>\n",
       "      <td>0.497517</td>\n",
       "      <td>0.497517</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.487905</td>\n",
       "      <td>0.493465</td>\n",
       "      <td>0.683425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.615490</td>\n",
       "      <td>0.668750</td>\n",
       "      <td>0.601717</td>\n",
       "      <td>0.601717</td>\n",
       "      <td>0.497037</td>\n",
       "      <td>0.497037</td>\n",
       "      <td>0.492740</td>\n",
       "      <td>0.491862</td>\n",
       "      <td>0.496498</td>\n",
       "      <td>0.683462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.615383</td>\n",
       "      <td>0.665869</td>\n",
       "      <td>0.601698</td>\n",
       "      <td>0.601698</td>\n",
       "      <td>0.493050</td>\n",
       "      <td>0.493050</td>\n",
       "      <td>0.489410</td>\n",
       "      <td>0.488688</td>\n",
       "      <td>0.490878</td>\n",
       "      <td>0.689125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.660710</td>\n",
       "      <td>0.607065</td>\n",
       "      <td>0.607065</td>\n",
       "      <td>0.495445</td>\n",
       "      <td>0.495445</td>\n",
       "      <td>0.491610</td>\n",
       "      <td>0.490701</td>\n",
       "      <td>0.494980</td>\n",
       "      <td>0.690725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.613406</td>\n",
       "      <td>0.660046</td>\n",
       "      <td>0.612282</td>\n",
       "      <td>0.612282</td>\n",
       "      <td>0.494568</td>\n",
       "      <td>0.494568</td>\n",
       "      <td>0.491325</td>\n",
       "      <td>0.488104</td>\n",
       "      <td>0.493259</td>\n",
       "      <td>0.696963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.612572</td>\n",
       "      <td>0.659235</td>\n",
       "      <td>0.615301</td>\n",
       "      <td>0.615301</td>\n",
       "      <td>0.492994</td>\n",
       "      <td>0.492994</td>\n",
       "      <td>0.489965</td>\n",
       "      <td>0.487983</td>\n",
       "      <td>0.491668</td>\n",
       "      <td>0.694275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.611385</td>\n",
       "      <td>0.661219</td>\n",
       "      <td>0.615771</td>\n",
       "      <td>0.615771</td>\n",
       "      <td>0.494604</td>\n",
       "      <td>0.494604</td>\n",
       "      <td>0.491621</td>\n",
       "      <td>0.489039</td>\n",
       "      <td>0.495028</td>\n",
       "      <td>0.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.612787</td>\n",
       "      <td>0.661254</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.493183</td>\n",
       "      <td>0.493183</td>\n",
       "      <td>0.489377</td>\n",
       "      <td>0.487506</td>\n",
       "      <td>0.494925</td>\n",
       "      <td>0.697137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.611461</td>\n",
       "      <td>0.662443</td>\n",
       "      <td>0.611809</td>\n",
       "      <td>0.611809</td>\n",
       "      <td>0.494831</td>\n",
       "      <td>0.494831</td>\n",
       "      <td>0.491002</td>\n",
       "      <td>0.488981</td>\n",
       "      <td>0.496160</td>\n",
       "      <td>0.694250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.612181</td>\n",
       "      <td>0.659191</td>\n",
       "      <td>0.622864</td>\n",
       "      <td>0.622864</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>0.496184</td>\n",
       "      <td>0.493686</td>\n",
       "      <td>0.497788</td>\n",
       "      <td>0.698238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.612803</td>\n",
       "      <td>0.665394</td>\n",
       "      <td>0.604247</td>\n",
       "      <td>0.604247</td>\n",
       "      <td>0.491940</td>\n",
       "      <td>0.491940</td>\n",
       "      <td>0.487559</td>\n",
       "      <td>0.487654</td>\n",
       "      <td>0.499440</td>\n",
       "      <td>0.695987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.611682</td>\n",
       "      <td>0.660794</td>\n",
       "      <td>0.612989</td>\n",
       "      <td>0.612989</td>\n",
       "      <td>0.492694</td>\n",
       "      <td>0.492694</td>\n",
       "      <td>0.489363</td>\n",
       "      <td>0.488711</td>\n",
       "      <td>0.499047</td>\n",
       "      <td>0.695162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.611354</td>\n",
       "      <td>0.660135</td>\n",
       "      <td>0.620836</td>\n",
       "      <td>0.620836</td>\n",
       "      <td>0.497878</td>\n",
       "      <td>0.497878</td>\n",
       "      <td>0.495068</td>\n",
       "      <td>0.491976</td>\n",
       "      <td>0.496746</td>\n",
       "      <td>0.698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.610819</td>\n",
       "      <td>0.660848</td>\n",
       "      <td>0.610737</td>\n",
       "      <td>0.610737</td>\n",
       "      <td>0.496463</td>\n",
       "      <td>0.496463</td>\n",
       "      <td>0.492157</td>\n",
       "      <td>0.492075</td>\n",
       "      <td>0.505244</td>\n",
       "      <td>0.694925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.611448</td>\n",
       "      <td>0.660527</td>\n",
       "      <td>0.615905</td>\n",
       "      <td>0.615905</td>\n",
       "      <td>0.495234</td>\n",
       "      <td>0.495234</td>\n",
       "      <td>0.492286</td>\n",
       "      <td>0.489611</td>\n",
       "      <td>0.496426</td>\n",
       "      <td>0.698713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.611670</td>\n",
       "      <td>0.661692</td>\n",
       "      <td>0.614589</td>\n",
       "      <td>0.614589</td>\n",
       "      <td>0.494820</td>\n",
       "      <td>0.494820</td>\n",
       "      <td>0.491879</td>\n",
       "      <td>0.489509</td>\n",
       "      <td>0.494088</td>\n",
       "      <td>0.698738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.611362</td>\n",
       "      <td>0.660729</td>\n",
       "      <td>0.610405</td>\n",
       "      <td>0.610405</td>\n",
       "      <td>0.492370</td>\n",
       "      <td>0.492370</td>\n",
       "      <td>0.489185</td>\n",
       "      <td>0.488027</td>\n",
       "      <td>0.493639</td>\n",
       "      <td>0.697262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.610876</td>\n",
       "      <td>0.659858</td>\n",
       "      <td>0.616409</td>\n",
       "      <td>0.616409</td>\n",
       "      <td>0.495224</td>\n",
       "      <td>0.495224</td>\n",
       "      <td>0.492411</td>\n",
       "      <td>0.490173</td>\n",
       "      <td>0.493090</td>\n",
       "      <td>0.699550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.610337</td>\n",
       "      <td>0.660090</td>\n",
       "      <td>0.614113</td>\n",
       "      <td>0.614113</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.494512</td>\n",
       "      <td>0.491467</td>\n",
       "      <td>0.489841</td>\n",
       "      <td>0.494188</td>\n",
       "      <td>0.699137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with value: 0.5526663367425493.\n",
      "Better model found at epoch 36 with value: 0.5315411122108582.\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Train - val split\n",
    "fold = 0\n",
    "trn_ds = TrainDatasetCashe(signal, noise, cashe_fns, True)\n",
    "vld_ds = ValLoader(val_df)\n",
    "\n",
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "custom_model = ViT(\n",
    "    num_classes=1,\n",
    "    image_size=(360, 128),  # image size is a tuple of (height, width)\n",
    "    patch_size=(10, 16),  # patch size is a tuple of (height, width)\n",
    "    dim=1024,\n",
    "    depth=6,\n",
    "    heads=12,\n",
    "    mlp_dim=2048,\n",
    "    dropout=0.1,\n",
    "    emb_dropout=0.1,\n",
    "    channels=2,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt = torch.optim.AdamW(custom_model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "loss_func = BCEWithLogitsLossFlat()\n",
    "warmup_steps = int(len(trn_dl) * int(CFG.warmup_pct * CFG.epoch))\n",
    "total_steps = int(len(trn_dl) * CFG.epoch)\n",
    "sched = get_linear_schedule_with_warmup(\n",
    "    opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "fit_mixup(\n",
    "    epochs=CFG.epoch,\n",
    "    model=custom_model,\n",
    "    train_dl=trn_dl,\n",
    "    valid_dl=vld_dl,\n",
    "    loss_fn=loss_func,\n",
    "    opt=opt,\n",
    "    val_df=val_df,\n",
    "    metric=custom_auc_score,\n",
    "    folder=CFG.folder,\n",
    "    exp_name=f\"{CFG.exp_name}_{fold}\",\n",
    "    device=\"cuda:1\",\n",
    "    sched=sched,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db319a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../EXP_200/EXP_200_BASELINE_CASHE_V2/EXP_200_BASELINE_CASHE_V2_convnext_large_in22k_0_9_oof.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def get_score(df):\n",
    "    return roc_auc_score(df['target'], df['pred'])\n",
    "\n",
    "def get_freq(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"f0>{left} & f0<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da300db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(get_freq(50, 100, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(get_freq(100, 200, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(get_freq(200, 300, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(get_freq(300, 400, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594834",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(get_freq(400, 500, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rho_10_40, freq  50 100:\", get_score(get_snr(10, 40, (get_freq(50, 100, df)))))\n",
    "print(\"rho_10_40, freq 100, 200:\", get_score(get_snr(10, 40, (get_freq(100, 200, df)))))\n",
    "print(\"rho_10_40, freq 200, 300:\", get_score(get_snr(10, 40, (get_freq(200, 300, df)))))\n",
    "print(\"rho_10_40, freq 300, 400:\", get_score(get_snr(10, 40, (get_freq(300, 400, df)))))\n",
    "print(\"rho_10_40, freq 400, 500:\", get_score(get_snr(10, 40, (get_freq(400, 500, df)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = get_snr(10, 40, (get_freq(400, 500, df))).query('target==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94098f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        k = f[filename]\n",
    "        h1 = k[\"H1\"]\n",
    "        l1 = k[\"L1\"]\n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "        freq = f[\"frequency_Hz\"][:]\n",
    "        \n",
    "        data_dict = {\"sft\" : np.stack([h1_stft[:, :4096], l1_stft[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp} , \n",
    "                 \"frequency\": freq}\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "\n",
    "def preprocess(sft):\n",
    "    sft = sft * 1e22\n",
    "    sft = sft.real**2 + sft.imag**2\n",
    "    return sft\n",
    "\n",
    "def h5_to_torch(fn):\n",
    "    fn = Path(fn)\n",
    "    data = read_data(fn)\n",
    "    torch.save(data, str(fn).replace(fn.suffix, '.pth'))\n",
    "    \n",
    "#noise_fns = list(Path('../data/custom_data/DATA_V34/data/').glob('*.h5'))\n",
    "#Parallel(n_jobs=16)(\n",
    "#    delayed(h5_to_torch)(fn=i)\n",
    "#    for i in tqdm(noise_fns)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee783c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384c0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
