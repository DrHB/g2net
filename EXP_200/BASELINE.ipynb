{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e383b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import copy\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from x_transformers import  Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import exists\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fastai.vision.all import BCEWithLogitsLossFlat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import os\n",
    "from timm import create_model\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab37361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 32\n",
    "    nw = 4\n",
    "    model_name = \"convnext_large_in22k\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 10\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 1\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_200_BASELINE\"\n",
    "    mixup=False\n",
    "    exp_name = f\"{folder}_{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a785480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "\n",
    "def generate_report(df, p, fn):\n",
    "    pred = torch.sigmoid(p).cpu().numpy().reshape(-1)\n",
    "    val_df_eval = df.copy()\n",
    "    val_df_eval[\"pred\"] = pred\n",
    "    val_df_eval.to_csv(f\"{fn}_oof.csv\")\n",
    "\n",
    "    roc_100 = roc_auc_score(val_df_eval[\"target\"], val_df_eval[\"pred\"])\n",
    "    \n",
    "    tr_comp = val_df_eval.query('data_type==\"comp_train\"')\n",
    "    roc_comp_train = roc_auc_score(tr_comp['target'], tr_comp['pred'])\n",
    "    roc_0_50 = roc_auc_score(\n",
    "        get_snr(0, 50, val_df_eval)[\"target\"], get_snr(0, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_15_50 = roc_auc_score(\n",
    "        get_snr(15, 50, val_df_eval)[\"target\"], get_snr(15, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_25_50 = roc_auc_score(\n",
    "        get_snr(25, 50, val_df_eval)[\"target\"], get_snr(25, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_0_40 = roc_auc_score(\n",
    "        get_snr(0, 40, val_df_eval)[\"target\"], get_snr(0, 40, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    roc_0_30 = roc_auc_score(\n",
    "        get_snr(0, 30, val_df_eval)[\"target\"], get_snr(0, 30, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"roc_all\": roc_100,\n",
    "        \"roc_0_50\": roc_0_50,\n",
    "        \"roc_15_50\": roc_15_50,\n",
    "        \"roc_25_50\": roc_25_50,\n",
    "        \"roc_0_40\": roc_0_40,\n",
    "        \"roc_0_30\": roc_0_30,\n",
    "        \"roc_comp_train\": roc_comp_train\n",
    "    }\n",
    "\n",
    "class SaveModel:\n",
    "    def __init__(self, folder, exp_name, best=np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score < self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelMetric:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelEpoch:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder)\n",
    "        self.exp_name = exp_name\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        self.best = score\n",
    "        print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "        torch.save(model.state_dict(), f\"{self.folder/self.exp_name}_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def custom_auc_score(p, gt):\n",
    "    return roc_auc_score(gt.cpu().numpy(),  torch.sigmoid(p).cpu().numpy().reshape(-1))\n",
    "\n",
    "\n",
    "def fit_mixup(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    loss_fn,\n",
    "    opt,\n",
    "    metric,\n",
    "    val_df,\n",
    "    folder=\"models\",\n",
    "    exp_name=\"exp_00\",\n",
    "    device=None,\n",
    "    sched=None,\n",
    "    mixup_=False,\n",
    "    save_md=SaveModel,\n",
    "):\n",
    "    if device is None:\n",
    "        device = (\n",
    "            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    loss_fn_trn = loss_fn\n",
    "    if mixup_:\n",
    "        mixup = Mixup(num_classes=2, mixup_alpha=0.4, prob=0.8)\n",
    "        loss_fn_trn = BinaryCrossEntropy()\n",
    "    mb = master_bar(range(epochs))\n",
    "\n",
    "    mb.write(\n",
    "        [\n",
    "            \"epoch\",\n",
    "            \"train_loss\",\n",
    "            \"valid_loss\",\n",
    "            \"val_metric\",\n",
    "            \"roc_all\",\n",
    "            \"roc_0_50\",\n",
    "            \"roc_15_50\",\n",
    "            \"roc_25_50\",\n",
    "            \"roc_0_40\",\n",
    "            \"roc_0_30\",\n",
    "            \"roc_comp_train\",\n",
    "        ],\n",
    "        table=True,\n",
    "    )\n",
    "    model.to(device)  # we have to put our model on gpu\n",
    "    #scaler = torch.cuda.amp.GradScaler()  # this for half precision training\n",
    "    save_md = save_md(folder, exp_name)\n",
    "\n",
    "    for i in mb:  # iterating  epoch\n",
    "        trn_loss, val_loss = 0.0, 0.0\n",
    "        trn_n, val_n = len(train_dl.dataset), len(valid_dl.dataset)\n",
    "        model.train()  # set model for training\n",
    "        for (xb, yb) in progress_bar(train_dl, parent=mb):\n",
    "            xb, yb = xb.to(device), yb.to(device)  # putting batches to device\n",
    "            if mixup_:\n",
    "                xb, yb = mixup(xb, yb)\n",
    "           \n",
    "            out = model(xb)  # forward pass\n",
    "            loss = loss_fn_trn(out, yb)  # calulation loss\n",
    "\n",
    "            trn_loss += loss.item()\n",
    "            #print(loss.item())\n",
    "            opt.zero_grad()  # zeroing optimizer\n",
    "            loss.backward()  # backward\n",
    "            opt.step()  # optimzers step\n",
    "            if sched is not None:\n",
    "                sched.step()  # scuedular step\n",
    "\n",
    "        trn_loss /= mb.child.total\n",
    "\n",
    "        # putting model in eval mode\n",
    "        model.eval()\n",
    "        gt = []\n",
    "        pred = []\n",
    "        # after epooch is done we can run a validation dataloder and see how are doing\n",
    "        with torch.no_grad():\n",
    "            for (xb, yb) in progress_bar(valid_dl, parent=mb):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(out, yb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                gt.append(yb.detach())\n",
    "                pred.append(out.detach())\n",
    "        # calculating metric\n",
    "        metric_ = metric(torch.cat(pred), torch.cat(gt))\n",
    "        # saving model if necessary\n",
    "        save_md(metric_, model, i)\n",
    "        val_loss /= mb.child.total\n",
    "        dict_res = generate_report(val_df, torch.cat(pred), f\"{folder}/{exp_name}_{i}\")\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"trn_loss\": [trn_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"metric\": [metric_],\n",
    "                \"roc_all\": [dict_res[\"roc_all\"]],\n",
    "                \"roc_0_50\": [dict_res[\"roc_0_50\"]],\n",
    "                \"roc_15_50\": [dict_res[\"roc_15_50\"]],\n",
    "                \"roc_25_50\": [dict_res[\"roc_25_50\"]],\n",
    "                \"roc_0_40\": [dict_res[\"roc_0_40\"]],\n",
    "                \"roc_0_30\": [dict_res[\"roc_0_30\"]],\n",
    "                \"roc_comp_train\": [dict_res[\"roc_comp_train\"]]\n",
    "            }\n",
    "        ).to_csv(f\"{folder}/{exp_name}_{i}.csv\", index=False)\n",
    "        mb.write(\n",
    "            [\n",
    "                i,\n",
    "                f\"{trn_loss:.6f}\",\n",
    "                f\"{val_loss:.6f}\",\n",
    "                f\"{metric_:.6f}\",\n",
    "                f\"{dict_res['roc_all']:.6f}\",\n",
    "                f\"{dict_res['roc_0_50']:.6f}\",\n",
    "                f\"{dict_res['roc_15_50']:.6f}\",\n",
    "                f\"{dict_res['roc_25_50']:.6f}\",\n",
    "                f\"{dict_res['roc_0_40']:.6f}\",\n",
    "                f\"{dict_res['roc_0_30']:.6f}\",\n",
    "                f\"{dict_res['roc_comp_train']:.6f}\",\n",
    "            ],\n",
    "            table=True,\n",
    "        )\n",
    "    print(\"Training done\")\n",
    "    # loading the best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3eed83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mask(spec, T=10):\n",
    "    cloned = spec.clone().detach()\n",
    "    len_spectro = cloned.shape[2]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):\n",
    "        t = random.randrange(0, T)\n",
    "        t_zero = random.randrange(0, len_spectro - t)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (t_zero == t_zero + t): return cloned\n",
    "\n",
    "        mask_end = random.randrange(t_zero, t_zero + t)\n",
    "        cloned[:, :,t_zero:mask_end] = 0\n",
    "    return cloned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def freq_mask(spec, F=30):\n",
    "    cloned = spec.clone().detach()\n",
    "    num_mel_channels = cloned.shape[1]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):        \n",
    "        f = random.randrange(0, F)\n",
    "        f_zero = random.randrange(0, num_mel_channels - f)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "        mask_end = random.randrange(f_zero, f_zero + f) \n",
    "        cloned[:, f_zero:mask_end, :] = 0\n",
    "    \n",
    "    return cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80e7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sft):\n",
    "    sft = sft * 1e22\n",
    "    sft = sft.real**2 + sft.imag**2\n",
    "    return sft\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data[0] = data[0] / data[0].mean()\n",
    "    data[1] = data[1] / data[1].mean()\n",
    "    data = data.reshape(2, 360, 128, 32).mean(-1)  # compress 4096 -> 128\n",
    "    data = data - data.mean()\n",
    "    data = data / data.std()\n",
    "    return torch.tensor(data)\n",
    "\n",
    "\n",
    "def read_h5(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        k = f[filename]\n",
    "        h1 = k[\"H1\"]\n",
    "        l1 = k[\"L1\"]\n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "        \n",
    "        data_dict = {\"sft\" : np.stack([h1_stft[:, :4096], l1_stft[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp}}\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, signal_fns, noise_fns, freq_tfms=False, iteration=50000):\n",
    "        self.signal_fns = signal_fns\n",
    "        self.noise_fns = noise_fns\n",
    "        self.tfms = freq_tfms\n",
    "        self.iteration = iteration\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.iteration\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        noise_fn = random.choice(self.noise_fns)\n",
    "        signal_fn = random.choice(self.signal_fns)\n",
    "        if np.random.rand() >= 0.5:\n",
    "            img = normalize(preprocess(torch.load(noise_fn)[\"sft\"]))\n",
    "            y = 0.\n",
    "        else:\n",
    "            img = normalize(\n",
    "                preprocess(torch.load(noise_fn)[\"sft\"] + torch.load(signal_fn)[\"sft\"])\n",
    "            )\n",
    "            y = 1.\n",
    "        if self.tfms:\n",
    "            if np.random.rand() <= 0.7:\n",
    "                img = freq_mask(img)\n",
    "            if np.random.rand() <= 0.7:\n",
    "                img = time_mask(img)\n",
    "            img = img.numpy()\n",
    "            if np.random.rand() <= 0.6:  # horizontal flip\n",
    "                img = np.flip(img, axis=1).copy()\n",
    "            if np.random.rand() <= 0.6:  # vertical flip\n",
    "                img = np.flip(img, axis=2).copy()\n",
    "            if np.random.rand() <= 0.6:  # vertical shift\n",
    "                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "            if np.random.rand() <= 0.5:  # channel shuffle\n",
    "                img = img[np.random.permutation([0, 1]), ...]\n",
    "        return img, y\n",
    "    \n",
    "class ValLoader(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        img = normalize(preprocess(read_h5(r.id)['sft']))\n",
    "        return img, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5a5a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 10116)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = list(Path('../data/custom_data/SIGNAL_V0/data').glob('*.pth'))\n",
    "\n",
    "real_noise_fns =  sorted(\n",
    "            Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "            key=lambda x: str(x).split(\"_\")[-2])\n",
    "\n",
    "noise = list(Path('../data/custom_data/DATA_V31_V32_NOISE').glob('*.pth')) + real_noise_fns[:1100]\n",
    "\n",
    "val_df = pd.read_csv('../data/SPLITS/V_22/val_df.csv')\n",
    "comp_train = pd.read_csv('../data/train_labels.csv')\n",
    "comp_train.columns = ['fn', 'target']\n",
    "comp_train = comp_train.query('target>=0')\n",
    "comp_train['fn'] = comp_train['fn'].apply(lambda x: Path('../data/train')/f'{x}.hdf5')\n",
    "comp_train.columns = ['id', 'target']\n",
    "comp_train['data_type'] = 'comp_train'\n",
    "real_noise_df = pd.DataFrame({\"id\": real_noise_fns[1100:], 'target': 0., 'snr': 0})\n",
    "real_noise_df['id'] = real_noise_df['id'].apply(lambda x: Path(str(x).replace('.pth', '.h5')))\n",
    "\n",
    "val_df = pd.concat([val_df, comp_train, real_noise_df], ignore_index=True)\n",
    "\n",
    "len(signal), len(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "975a2564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='9' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 11:50:18&lt;1:18:55]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>roc_all</th>\n",
       "      <th>roc_0_50</th>\n",
       "      <th>roc_15_50</th>\n",
       "      <th>roc_25_50</th>\n",
       "      <th>roc_0_40</th>\n",
       "      <th>roc_0_30</th>\n",
       "      <th>roc_comp_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.449942</td>\n",
       "      <td>0.381588</td>\n",
       "      <td>0.869562</td>\n",
       "      <td>0.869562</td>\n",
       "      <td>0.699740</td>\n",
       "      <td>0.699740</td>\n",
       "      <td>0.709824</td>\n",
       "      <td>0.599861</td>\n",
       "      <td>0.573614</td>\n",
       "      <td>0.828738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.398843</td>\n",
       "      <td>0.358199</td>\n",
       "      <td>0.885208</td>\n",
       "      <td>0.885208</td>\n",
       "      <td>0.752279</td>\n",
       "      <td>0.752279</td>\n",
       "      <td>0.766713</td>\n",
       "      <td>0.655433</td>\n",
       "      <td>0.573738</td>\n",
       "      <td>0.819450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.375684</td>\n",
       "      <td>0.345149</td>\n",
       "      <td>0.886052</td>\n",
       "      <td>0.886052</td>\n",
       "      <td>0.766287</td>\n",
       "      <td>0.766287</td>\n",
       "      <td>0.775569</td>\n",
       "      <td>0.675190</td>\n",
       "      <td>0.589758</td>\n",
       "      <td>0.815275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.365972</td>\n",
       "      <td>0.335297</td>\n",
       "      <td>0.899387</td>\n",
       "      <td>0.899387</td>\n",
       "      <td>0.775688</td>\n",
       "      <td>0.775688</td>\n",
       "      <td>0.783987</td>\n",
       "      <td>0.678119</td>\n",
       "      <td>0.597141</td>\n",
       "      <td>0.820750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.357763</td>\n",
       "      <td>0.343163</td>\n",
       "      <td>0.904578</td>\n",
       "      <td>0.904578</td>\n",
       "      <td>0.779974</td>\n",
       "      <td>0.779974</td>\n",
       "      <td>0.790060</td>\n",
       "      <td>0.682418</td>\n",
       "      <td>0.583627</td>\n",
       "      <td>0.819037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.351475</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>0.903239</td>\n",
       "      <td>0.903239</td>\n",
       "      <td>0.772767</td>\n",
       "      <td>0.772767</td>\n",
       "      <td>0.782538</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.581661</td>\n",
       "      <td>0.824300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.343516</td>\n",
       "      <td>0.376680</td>\n",
       "      <td>0.908308</td>\n",
       "      <td>0.908308</td>\n",
       "      <td>0.786650</td>\n",
       "      <td>0.786650</td>\n",
       "      <td>0.794120</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.610730</td>\n",
       "      <td>0.815769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.334966</td>\n",
       "      <td>0.333001</td>\n",
       "      <td>0.906905</td>\n",
       "      <td>0.906905</td>\n",
       "      <td>0.781704</td>\n",
       "      <td>0.781704</td>\n",
       "      <td>0.791203</td>\n",
       "      <td>0.677409</td>\n",
       "      <td>0.587197</td>\n",
       "      <td>0.816937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.330260</td>\n",
       "      <td>0.352204</td>\n",
       "      <td>0.911513</td>\n",
       "      <td>0.911513</td>\n",
       "      <td>0.794988</td>\n",
       "      <td>0.794988</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.696164</td>\n",
       "      <td>0.609543</td>\n",
       "      <td>0.815550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='458' class='' max='1562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      29.32% [458/1562 22:36&lt;54:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with value: 0.8695617507973166.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trn_dl) \u001b[38;5;241m*\u001b[39m CFG\u001b[38;5;241m.\u001b[39mepoch)\n\u001b[1;32m     33\u001b[0m sched \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(\n\u001b[1;32m     34\u001b[0m     opt, num_warmup_steps\u001b[38;5;241m=\u001b[39mwarmup_steps, num_training_steps\u001b[38;5;241m=\u001b[39mtotal_steps\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m \u001b[43mfit_mixup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrn_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvld_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_auc_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43msched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mfit_mixup\u001b[0;34m(epochs, model, train_dl, valid_dl, loss_fn, opt, metric, val_df, folder, exp_name, device, sched, mixup_, save_md)\u001b[0m\n\u001b[1;32m    133\u001b[0m trn_n, val_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl\u001b[38;5;241m.\u001b[39mdataset), \u001b[38;5;28mlen\u001b[39m(valid_dl\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    134\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# set model for training\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (xb, yb) \u001b[38;5;129;01min\u001b[39;00m progress_bar(train_dl, parent\u001b[38;5;241m=\u001b[39mmb):\n\u001b[1;32m    136\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# putting batches to device\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mixup_:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fastprogress/fastprogress.py:41\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1286\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1286\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train - val split\n",
    "fold =0\n",
    "trn_ds = TrainDataset(signal, noise, True)\n",
    "vld_ds = ValLoader(val_df)\n",
    "\n",
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "custom_model = create_model(\n",
    "                    CFG.model_name,\n",
    "                    pretrained=True,\n",
    "                    num_classes=1,\n",
    "                    in_chans=2,\n",
    "                )\n",
    "\n",
    "opt = torch.optim.AdamW(custom_model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "loss_func = BCEWithLogitsLossFlat()\n",
    "warmup_steps = int(len(trn_dl) * int(CFG.warmup_pct * CFG.epoch))\n",
    "total_steps = int(len(trn_dl) * CFG.epoch)\n",
    "sched = get_linear_schedule_with_warmup(\n",
    "    opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "fit_mixup(\n",
    "    epochs=CFG.epoch,\n",
    "    model=custom_model,\n",
    "    train_dl=trn_dl,\n",
    "    valid_dl=vld_dl,\n",
    "    loss_fn=loss_func,\n",
    "    opt=opt,\n",
    "    val_df=val_df,\n",
    "    metric=custom_auc_score,\n",
    "    folder=CFG.folder,\n",
    "    exp_name=f\"{CFG.exp_name}_{fold}\",\n",
    "    device=\"cuda:0\",\n",
    "    sched=sched,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bea981",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701f5d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([292.,  68.,  48.,  47.,  48.,  48.,  54.,  46.,  74., 275.]),\n",
       " array([3.56900837e-13, 9.99999998e-02, 2.00000000e-01, 2.99999999e-01,\n",
       "        3.99999999e-01, 4.99999999e-01, 5.99999999e-01, 6.99999998e-01,\n",
       "        7.99999998e-01, 8.99999998e-01, 9.99999998e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([np.random.beta(0.3, 0.3) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfd3427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([178.,  98.,  88.,  62.,  73.,  71.,  71.,  61., 110., 188.]),\n",
       " array([2.59786131e-05, 1.00020752e-01, 2.00015525e-01, 3.00010299e-01,\n",
       "        4.00005072e-01, 4.99999845e-01, 5.99994619e-01, 6.99989392e-01,\n",
       "        7.99984165e-01, 8.99978939e-01, 9.99973712e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([np.random.beta(0.6, 0.6) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da626333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([236.,  94.,  61.,  57.,  50.,  58.,  59.,  69.,  73., 243.]),\n",
       " array([1.76241307e-08, 1.00000012e-01, 2.00000007e-01, 3.00000002e-01,\n",
       "        3.99999997e-01, 4.99999991e-01, 5.99999986e-01, 6.99999981e-01,\n",
       "        7.99999976e-01, 8.99999971e-01, 9.99999965e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([np.random.beta(0.4, 0.4) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d77fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([195.,  80.,  78.,  64.,  70.,  73.,  62.,  67.,  87., 224.]),\n",
       " array([3.64874349e-06, 1.00002877e-01, 2.00002105e-01, 3.00001333e-01,\n",
       "        4.00000562e-01, 4.99999790e-01, 5.99999018e-01, 6.99998246e-01,\n",
       "        7.99997474e-01, 8.99996703e-01, 9.99995931e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([np.random.beta(0.5, 0.5) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc3610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
