{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-11-07 16:52:25.863 pyfstat INFO    : Running PyFstat version 1.18.1\n",
      "22-11-07 16:52:25.946 pyfstat.utils.importing INFO    : No $DISPLAY environment variable found, so importing matplotlib.pyplot with non-interactive 'Agg' backend.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from secrets import token_hex\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import pyfstat\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return 'pass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def read_file(filename):\n",
    "    file_id = Path(filename).stem\n",
    "    img = np.empty((2, 360, 128), dtype=np.float32)\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        g = f[file_id]\n",
    "\n",
    "        for ch, s in enumerate([\"H1\", \"L1\"]):\n",
    "            a = g[s][\"SFTs\"][:, :4096] * 1e22  # Fourier coefficient complex64\n",
    "            p = a.real**2 + a.imag**2  # power\n",
    "            p /= np.mean(p)  # normalize\n",
    "            p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n",
    "            img[ch] = p\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_timestemp(filename):\n",
    "    file_id = Path(filename).stem\n",
    "    img = dict()\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        img[\"L1\"] = np.copy(f[file_id][\"L1\"][\"timestamps_GPS\"])\n",
    "        img[\"H1\"] = np.copy(f[file_id][\"H1\"][\"timestamps_GPS\"])\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_random_name(len_k=16):\n",
    "    token = token_hex(len_k)\n",
    "    return token\n",
    "\n",
    "\n",
    "def save_hdf(\n",
    "    name: str,\n",
    "    sft_h1: np.array,\n",
    "    sft_l1: np.array,\n",
    "    timestamps: Dict,\n",
    "    frequency: np.array,\n",
    "    meta_: dict,\n",
    "):\n",
    "    hf = h5py.File(f\"{name}.h5\", \"w\")\n",
    "    g1 = hf.create_group(name.stem)\n",
    "    h1 = g1.create_group(\"H1\")\n",
    "    h1.create_dataset(\"SFTs\", data=sft_h1)\n",
    "    h1.create_dataset(\"timestamps_GPS\", data=timestamps[\"H1\"])\n",
    "\n",
    "    l1 = g1.create_group(\"L1\")\n",
    "    l1.create_dataset(\"SFTs\", data=sft_l1)\n",
    "    l1.create_dataset(\"timestamps_GPS\", data=timestamps[\"L1\"])\n",
    "\n",
    "    hf.create_dataset(\"frequency_Hz\", data=frequency)\n",
    "    pd.DataFrame(meta_).to_csv(f\"{name}.csv\", index=False)\n",
    "\n",
    "\n",
    "def constrained_sum_sample_pos(n, total):\n",
    "    \"\"\"Return a randomly chosen list of n positive integers summing to total.\n",
    "    Each such list is equally likely to occur.\"\"\"\n",
    "\n",
    "    dividers = sorted(random.sample(range(1, total), n - 1))\n",
    "    return [a - b for a, b in zip(dividers + [total], [0] + dividers)]\n",
    "\n",
    "def get_random_sqrtx_noise():\n",
    "    sqrtx_choice = [\n",
    "        (2e-23, 2.5e-23),\n",
    "        (1e-23, 1.5e-23),\n",
    "        (3e-23, 3.5e-23),\n",
    "        (4e-23, 4.5e-23),\n",
    "        (5e-23, 5.5e-23),\n",
    "        (6e-23, 7e-23),\n",
    "    ]\n",
    "    ch = random.choice(sqrtx_choice)\n",
    "    return ch[0], ch[1]\n",
    "    #return np.random.uniform(1e-23, 5e-23)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_data_v10(fn, save_folder, neg=False):\n",
    "    \"\"\"\n",
    "    this function generates random data using uniform values of sqrtSX sampled randomly (1e-23, 5e-23)\n",
    "    and random timesteps from test data. \n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate signals with parameters drawn from a specific population\n",
    "\n",
    "        # These parameters describe background noise and data format\n",
    "        sq_h1 = np.random.uniform(1e-23, 5e-23)\n",
    "        random_test_timestemp = read_timestemp(random.choice(list(Path('../data/test').glob('*.hdf5'))))\n",
    "        writer_kwargs = {\n",
    "            \"detectors\": \"H1,L1\",\n",
    "            \"timestamps\": random_test_timestemp, \n",
    "            \"sqrtSX\": sq_h1,\n",
    "            \"Tsft\": 1800,\n",
    "            \"SFTWindowType\": \"tukey\",\n",
    "            \"SFTWindowBeta\": random.choice([0.01, 0.001]),\n",
    "            \"Band\": 0.2,\n",
    "        }\n",
    "\n",
    "        #writer_kwargs = {\n",
    "        #    \"tstart\": 1238166018,\n",
    "        #    \"duration\": 86 * 86400,\n",
    "        #    \"detectors\": \"H1,L1\",\n",
    "        #    \"sqrtSX\": sq_h1,\n",
    "        #    \"Tsft\": 1800,\n",
    "        #    \"SFTWindowType\": \"tukey\",\n",
    "        #    \"SFTWindowBeta\": random.choice([0.01, 0.001]),\n",
    "        #    \"Band\": 0.2,\n",
    "        #}\n",
    "\n",
    "        h_0 = lambda: writer_kwargs[\"sqrtSX\"] / stats.uniform(1, 50).rvs()\n",
    "        if neg:\n",
    "            h_0 = 0\n",
    "        signal_parameters_generator = pyfstat.AllSkyInjectionParametersGenerator(\n",
    "            priors={\n",
    "    #            \"tref\": writer_kwargs[\"tstart\"],\n",
    "                \"F0\": {\"uniform\": {\"low\": 50, \"high\": 500}},\n",
    "                \"F1\": lambda: 10 ** stats.uniform(-12, 4).rvs(),\n",
    "                \"F2\": 0,\n",
    "                \"h0\": h_0,\n",
    "                **pyfstat.injection_parameters.isotropic_amplitude_priors,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Draw signal parameters.\n",
    "        # Noise can be drawn by setting `params[\"h0\"] = 0\n",
    "        name = save_folder / f\"hb_{fn}\"\n",
    "        params = signal_parameters_generator.draw()\n",
    "        # same timestemps as in test data\n",
    "        # writer_kwargs['timestamps'] = get_random_timesteps(random.choice(t_fns))\n",
    "        writer_kwargs[\"outdir\"] = f\"PyFstat_example_data_ensemble/Signal_{fn}\"\n",
    "        writer_kwargs[\"label\"] = f\"Signal_{fn}\"\n",
    "\n",
    "        writer = pyfstat.Writer(**writer_kwargs, **params)\n",
    "        writer.make_data()\n",
    "\n",
    "        # SNR can be compute from a set of SFTs for a specific set\n",
    "        # of parameters as follows:\n",
    "        snr = pyfstat.SignalToNoiseRatio.from_sfts(\n",
    "            F0=writer.F0, sftfilepath=writer.sftfilepath\n",
    "        )\n",
    "        squared_snr = snr.compute_snr2(\n",
    "            Alpha=writer.Alpha,\n",
    "            Delta=writer.Delta,\n",
    "            psi=writer.psi,\n",
    "            phi=writer.phi,\n",
    "            h0=writer.h0,\n",
    "            cosi=writer.cosi,\n",
    "        )\n",
    "\n",
    "        meta_ = {\n",
    "            \"alpha\": [writer.Alpha],\n",
    "            \"daelta\": [writer.Delta],\n",
    "            \"cosi\": [writer.cosi],\n",
    "            \"psi\": [writer.psi],\n",
    "            \"phi\": [writer.phi],\n",
    "            \"h0\": [writer.h0],\n",
    "            \"f0\": [writer.F0],\n",
    "            \"f1\": [writer.F1],\n",
    "            \"snr\": [np.sqrt(squared_snr)],\n",
    "        }\n",
    "        # Data can be read as a numpy array using PyFstat\n",
    "        frequency, timestamps, amplitudes = pyfstat.utils.get_sft_as_arrays(\n",
    "            writer.sftfilepath\n",
    "        )\n",
    "\n",
    "        sft_h1 = amplitudes[\"H1\"][1:, :]\n",
    "        sft_l1 = amplitudes[\"L1\"][1:, :]\n",
    "        save_hdf(Path(name), sft_h1, sft_l1, timestamps, frequency, meta_)\n",
    "\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA_V10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_samples = 4000\n",
    "name = 'DATA_V10'\n",
    "save_pos_path =  Path(f'../data/custom_data/{name}/pos')\n",
    "os.makedirs(save_pos_path, exist_ok=True)\n",
    "Parallel(n_jobs=16)(\n",
    "    delayed(generate_data_v10)(get_random_name(),save_folder=save_pos_path, neg=False)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")\n",
    "\n",
    "save_neg_path =  Path(f'../data/custom_data/{name}/neg')\n",
    "os.makedirs(save_neg_path, exist_ok=True)\n",
    "Parallel(n_jobs=16)(\n",
    "    delayed(generate_data_v10)(get_random_name(),save_folder=save_neg_path, neg=True)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")\n",
    "\n",
    "df_pos = pd.DataFrame({\"id\": list(save_pos_path.glob('*.h5')), \n",
    "                       \"target\": 1})\n",
    "df_neg = pd.DataFrame({\"id\": list(save_neg_path.glob('*.h5')), \n",
    "                       \"target\": 0})\n",
    "df_comb = pd.concat([df_pos, df_neg], ignore_index=True).sample(frac=1.)\n",
    "df_comb.to_csv(save_pos_path.parent/'train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA_V11"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_data_v11(fn, save_folder, neg=False):\n",
    "    \"\"\"\n",
    "    this function generates random data fragments using uniform values of sqrtSX for each segment\n",
    "    currently it usses narrow noise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate signals with parameters drawn from a specific population\n",
    "        sft_path = []\n",
    "        # These parameters describe background noise and data format\n",
    "        m = np.random.randint(20, 70)\n",
    "        segment_lengths = list(np.array(constrained_sum_sample_pos(m, 86 * 2)) * 43200)\n",
    "        ch_0, ch_1 = get_random_sqrtx_noise()\n",
    "        segment_sqrtSX = [np.random.uniform(ch_0, ch_1) for i in range(m)]\n",
    "\n",
    "        writer_kwargs = {\n",
    "            \"tstart\": 1238166018,\n",
    "            \"detectors\": \"H1,L1\",\n",
    "            \"Tsft\": 1800,\n",
    "            \"SFTWindowType\": \"tukey\",\n",
    "            \"SFTWindowBeta\": random.choice([0.01, 0.001]),\n",
    "            \"Band\": 0.2,\n",
    "        }\n",
    "\n",
    "        h_0 = lambda: random.choice(segment_sqrtSX) / stats.uniform(1, 50).rvs()\n",
    "        if neg:\n",
    "            h_0 = 0\n",
    "        signal_parameters_generator = pyfstat.AllSkyInjectionParametersGenerator(\n",
    "            priors={\n",
    "                \"tref\": writer_kwargs[\"tstart\"],\n",
    "                \"F0\": {\"uniform\": {\"low\": 50, \"high\": 500}},\n",
    "                \"F1\": lambda: 10 ** stats.uniform(-12, 4).rvs(),\n",
    "                \"F2\": 0,\n",
    "                \"h0\": h_0,\n",
    "                **pyfstat.injection_parameters.isotropic_amplitude_priors,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Draw signal parameters.\n",
    "        # Noise can be drawn by setting `params[\"h0\"] = 0\n",
    "        name = save_folder / f\"hb_{fn}\"\n",
    "        params = signal_parameters_generator.draw()\n",
    "        # same timestemps as in test data\n",
    "        # writer_kwargs['timestamps'] = get_random_timesteps(random.choice(t_fns))\n",
    "        for segment in range(len(segment_lengths)):\n",
    "            writer_kwargs[\"outdir\"] = f\"PyFstat_example_data_ensemble/Signal_{fn}\"\n",
    "            writer_kwargs[\"label\"] = f\"Signal_{fn}\"\n",
    "            writer_kwargs[\"duration\"] = segment_lengths[segment]\n",
    "            writer_kwargs[\"sqrtSX\"] = segment_sqrtSX[segment]\n",
    "\n",
    "            if segment > 0:\n",
    "                writer_kwargs[\"tstart\"] += (\n",
    "                    writer_kwargs[\"Tsft\"] + segment_lengths[segment - 1]\n",
    "                )\n",
    "\n",
    "            writer = pyfstat.Writer(**writer_kwargs, **params)\n",
    "            writer.make_data()\n",
    "            sft_path.append(writer.sftfilepath)\n",
    "\n",
    "        # SNR can be compute from a set of SFTs for a specific set\n",
    "        # of parameters as follows:\n",
    "        sft_path = \";\".join(sft_path)\n",
    "        snr = pyfstat.SignalToNoiseRatio.from_sfts(F0=writer.F0, sftfilepath=sft_path)\n",
    "        squared_snr = snr.compute_snr2(\n",
    "            Alpha=writer.Alpha,\n",
    "            Delta=writer.Delta,\n",
    "            psi=writer.psi,\n",
    "            phi=writer.phi,\n",
    "            h0=writer.h0,\n",
    "            cosi=writer.cosi,\n",
    "        )\n",
    "\n",
    "        meta_ = {\n",
    "            \"alpha\": [writer.Alpha],\n",
    "            \"daelta\": [writer.Delta],\n",
    "            \"cosi\": [writer.cosi],\n",
    "            \"psi\": [writer.psi],\n",
    "            \"phi\": [writer.phi],\n",
    "            \"h0\": [writer.h0],\n",
    "            \"f0\": [writer.F0],\n",
    "            \"f1\": [writer.F1],\n",
    "            \"snr\": [np.sqrt(squared_snr)],\n",
    "        }\n",
    "        # Data can be read as a numpy array using PyFstat\n",
    "        frequency, timestamps, amplitudes = pyfstat.utils.get_sft_as_arrays(sft_path)\n",
    "\n",
    "        sft_h1 = amplitudes[\"H1\"][1:, :]\n",
    "        sft_l1 = amplitudes[\"L1\"][1:, :]\n",
    "        save_hdf(Path(name), sft_h1, sft_l1, timestamps, frequency, meta_)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_samples = 4000\n",
    "name = 'DATA_V11'\n",
    "save_pos_path =  Path(f'../data/custom_data/{name}/pos')\n",
    "os.makedirs(save_pos_path, exist_ok=True)\n",
    "Parallel(n_jobs=16)(\n",
    "    delayed(generate_data_v11)(get_random_name(),save_folder=save_pos_path, neg=False)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")\n",
    "\n",
    "save_neg_path =  Path(f'../data/custom_data/{name}/neg')\n",
    "os.makedirs(save_neg_path, exist_ok=True)\n",
    "Parallel(n_jobs=16)(\n",
    "    delayed(generate_data_v11)(get_random_name(),save_folder=save_neg_path, neg=True)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")\n",
    "\n",
    "df_pos = pd.DataFrame({\"id\": list(save_pos_path.glob('*.h5')), \n",
    "                       \"target\": 1})\n",
    "df_neg = pd.DataFrame({\"id\": list(save_neg_path.glob('*.h5')), \n",
    "                       \"target\": 0})\n",
    "df_comb = pd.concat([df_pos, df_neg], ignore_index=True).sample(frac=1.)\n",
    "df_comb.to_csv(save_pos_path.parent/'train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA_V12"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_data_v12(fn, save_folder, neg=False):\n",
    "    \"\"\"\n",
    "    this function generates random data using uniform values of sqrtSX sampled randomly (1e-23, 5e-23)\n",
    "    and random timesteps from test data. Here we apply Horizontal Instrument Malfunction to L1 and H1\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Generate signals with parameters drawn from a specific population\n",
    "\n",
    "        # These parameters describe background noise and data format\n",
    "        sq_h1 = np.random.uniform(1e-23, 5e-23)\n",
    "        random_test_timestemp = read_timestemp(\n",
    "            random.choice(list(Path(\"../data/test\").glob(\"*.hdf5\")))\n",
    "        )\n",
    "        writer_kwargs = {\n",
    "            \"detectors\": \"H1\",\n",
    "            \"timestamps\": random_test_timestemp[\"H1\"],\n",
    "            \"sqrtSX\": sq_h1,\n",
    "            \"Tsft\": 1800,\n",
    "            \"SFTWindowType\": \"tukey\",\n",
    "            \"SFTWindowBeta\": random.choice([0.01, 0.001]),\n",
    "            \"Band\": 0.2,\n",
    "        }\n",
    "\n",
    "        # writer_kwargs = {\n",
    "        #    \"tstart\": 1238166018,\n",
    "        #    \"duration\": 86 * 86400,\n",
    "        #    \"detectors\": \"H1,L1\",\n",
    "        #    \"sqrtSX\": sq_h1,\n",
    "        #    \"Tsft\": 1800,\n",
    "        #    \"SFTWindowType\": \"tukey\",\n",
    "        #    \"SFTWindowBeta\": random.choice([0.01, 0.001]),\n",
    "        #    \"Band\": 0.2,\n",
    "        # }\n",
    "\n",
    "        h_0 = lambda: writer_kwargs[\"sqrtSX\"] / stats.uniform(1, 50).rvs()\n",
    "        if neg:\n",
    "            h_0 = 0\n",
    "        signal_parameters_generator = pyfstat.AllSkyInjectionParametersGenerator(\n",
    "            priors={\n",
    "                #      \"tref\": writer_kwargs[\"tstart\"],\n",
    "                \"F0\": {\"uniform\": {\"low\": 50, \"high\": 500}},\n",
    "                \"F1\": lambda: 10 ** stats.uniform(-12, 4).rvs(),\n",
    "                \"F2\": 0,\n",
    "                \"h0\": h_0,\n",
    "                **pyfstat.injection_parameters.isotropic_amplitude_priors,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Draw signal parameters.\n",
    "        # Noise can be drawn by setting `params[\"h0\"] = 0\n",
    "        name = save_folder / f\"hb_{fn}\"\n",
    "        params = signal_parameters_generator.draw()\n",
    "        # same timestemps as in test data\n",
    "        # writer_kwargs['timestamps'] = get_random_timesteps(random.choice(t_fns))\n",
    "        writer_kwargs[\"outdir\"] = f\"PyFstat_example_data_ensemble/Signal_{fn}\"\n",
    "        writer_kwargs[\"label\"] = f\"Signal_{fn}\"\n",
    "\n",
    "        writer = pyfstat.LineWriter(**writer_kwargs, **params)\n",
    "        writer.make_data()\n",
    "\n",
    "        # SNR can be compute from a set of SFTs for a specific set\n",
    "        # of parameters as follows:\n",
    "        snr = pyfstat.SignalToNoiseRatio.from_sfts(\n",
    "            F0=writer.F0, sftfilepath=writer.sftfilepath\n",
    "        )\n",
    "        squared_snr = snr.compute_snr2(\n",
    "            Alpha=writer.Alpha,\n",
    "            Delta=writer.Delta,\n",
    "            psi=writer.psi,\n",
    "            phi=writer.phi,\n",
    "            h0=writer.h0,\n",
    "            cosi=writer.cosi,\n",
    "        )\n",
    "\n",
    "        meta_ = {\n",
    "            \"alpha\": [writer.Alpha],\n",
    "            \"daelta\": [writer.Delta],\n",
    "            \"cosi\": [writer.cosi],\n",
    "            \"psi\": [writer.psi],\n",
    "            \"phi\": [writer.phi],\n",
    "            \"h0\": [writer.h0],\n",
    "            \"f0\": [writer.F0],\n",
    "            \"f1\": [writer.F1],\n",
    "            \"snr\": [np.sqrt(squared_snr)],\n",
    "        }\n",
    "        print(meta_)\n",
    "        # Data can be read as a numpy array using PyFstat\n",
    "        frequency_h1, timestamps_h1, amplitudes_h1 = pyfstat.utils.get_sft_as_arrays(\n",
    "            writer.sftfilepath\n",
    "        )\n",
    "\n",
    "        # ______________L1_________\n",
    "        writer_kwargs[\"timestamps\"] = (random_test_timestemp[\"L1\"],)\n",
    "        writer_kwargs[\"detectors\"] = \"L1\"\n",
    "        writer = pyfstat.LineWriter(**writer_kwargs, **params)\n",
    "        writer.make_data()\n",
    "\n",
    "        # SNR can be compute from a set of SFTs for a specific set\n",
    "        # of parameters as follows:\n",
    "        snr = pyfstat.SignalToNoiseRatio.from_sfts(\n",
    "            F0=writer.F0, sftfilepath=writer.sftfilepath\n",
    "        )\n",
    "        squared_snr = snr.compute_snr2(\n",
    "            Alpha=writer.Alpha,\n",
    "            Delta=writer.Delta,\n",
    "            psi=writer.psi,\n",
    "            phi=writer.phi,\n",
    "            h0=writer.h0,\n",
    "            cosi=writer.cosi,\n",
    "        )\n",
    "\n",
    "        meta_ = {\n",
    "            \"alpha\": [writer.Alpha],\n",
    "            \"daelta\": [writer.Delta],\n",
    "            \"cosi\": [writer.cosi],\n",
    "            \"psi\": [writer.psi],\n",
    "            \"phi\": [writer.phi],\n",
    "            \"h0\": [writer.h0],\n",
    "            \"f0\": [writer.F0],\n",
    "            \"f1\": [writer.F1],\n",
    "            \"snr\": [np.sqrt(squared_snr)],\n",
    "        }\n",
    "        print(meta_)\n",
    "        # Data can be read as a numpy array using PyFstat\n",
    "        frequency_l1, timestamps_l1, amplitudes_l1 = pyfstat.utils.get_sft_as_arrays(\n",
    "            writer.sftfilepath\n",
    "        )\n",
    "\n",
    "        sft_h1 = amplitudes_h1[\"H1\"][1:, :]\n",
    "        sft_l1 = amplitudes_l1[\"L1\"][1:, :]\n",
    "        timestamps = {\"H1\": timestamps_h1[\"H1\"], \"L1\": timestamps_l1[\"L1\"]}\n",
    "        save_hdf(Path(name), sft_h1, sft_l1, timestamps, frequency_l1, meta_)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_samples = 2000\n",
    "name = 'DATA_V12'\n",
    "save_pos_path =  Path(f'../data/custom_data/{name}/pos')\n",
    "os.makedirs(save_pos_path, exist_ok=True)\n",
    "Parallel(n_jobs=16)(\n",
    "    delayed(generate_data_v12)(get_random_name(),save_folder=save_pos_path, neg=False)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")\n",
    "\n",
    "save_neg_path =  Path(f'../data/custom_data/{name}/neg')\n",
    "os.makedirs(save_neg_path, exist_ok=True)\n",
    "Parallel(n_jobs=16)(\n",
    "    delayed(generate_data_v12)(get_random_name(),save_folder=save_neg_path, neg=True)\n",
    "    for i in tqdm(range(n_samples))\n",
    ")\n",
    "\n",
    "df_pos = pd.DataFrame({\"id\": list(save_pos_path.glob('*.h5')), \n",
    "                       \"target\": 1})\n",
    "df_neg = pd.DataFrame({\"id\": list(save_neg_path.glob('*.h5')), \n",
    "                       \"target\": 0})\n",
    "df_comb = pd.concat([df_pos, df_neg], ignore_index=True).sample(frac=1.)\n",
    "df_comb.to_csv(save_pos_path.parent/'train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "img = read_file(random.choice(list(save_neg_path.glob('*.h5'))))\n",
    "plt.imshow(img.mean(0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "generate_data('test_new', Path(''), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
