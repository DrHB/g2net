{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e383b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import copy\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from x_transformers import  Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import exists\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fastai.vision.all import BCEWithLogitsLossFlat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import os\n",
    "from timm import create_model\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import binned_statistic\n",
    "from copy import copy\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "OUT = 'init'\n",
    "DATA = 'data/gwaves_train_v5.pickle'\n",
    "with open(DATA, 'rb') as f: \n",
    "    clean_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab37361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 64\n",
    "    nw = 8\n",
    "    model_name = \"convnext_large_in22k\"\n",
    "    lr = 1e-3\n",
    "    wd = 1e-4\n",
    "    epoch = 100\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 1\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"CAT_V0\"\n",
    "    mixup=False\n",
    "    exp_name = f\"{folder}_{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fec8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iofass based\n",
    "class G2NetDatasetTrain(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise_fns, \n",
    "        signal_fns, \n",
    "        sz_f=360,\n",
    "        sz_t=128,\n",
    "        p=0.66,\n",
    "        p_ns=0.5,\n",
    "        depth0=15,\n",
    "        depth1=50,\n",
    "        tfms= True\n",
    "    ):\n",
    "        self.data = clean_data\n",
    "        self.fns =list(clean_data.keys())\n",
    "        self.tfrms = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "            ]\n",
    "        )\n",
    "        self.p, self.p_ns, self.sz_f, self.sz_t = p, p_ns, sz_f, sz_t\n",
    "        self.depth0, self.depth1 = depth0, depth1\n",
    "\n",
    "        # A_noise after multiplying by 1e22: very important parameter for model without norm\n",
    "        # 5e-2*np.sqrt(1800)/2 = 1.0606601717798214\n",
    "        self.A_noise = 1.065\n",
    "        Tsft = 1800\n",
    "        self.tosqrtSX = 2 / np.sqrt(Tsft)\n",
    "        self.noise_fns = noise_fns\n",
    "        self.signal_fns = signal_fns\n",
    "        self.tfms = tfms\n",
    "\n",
    "        with open(\"data/real_noise_std.pickle\", \"rb\") as handle:\n",
    "            self.std_est = pickle.load(handle)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_on_fly(self, idx):\n",
    "        data = self.data[self.fns[idx]]\n",
    "\n",
    "        n_stat = [data[\"H1_ts\"], data[\"L1_ts\"]]\n",
    "        noise = [[] for source in range(len(n_stat))]\n",
    "        if torch.rand(1).item() < 0.5:  # nonstationary noise\n",
    "            std_est = random.choice(self.std_est)\n",
    "            A_noise = [\n",
    "                np.where(\n",
    "                    std_est[\"H1_ts\"] > 5,\n",
    "                    std_est[\"H1_std\"],\n",
    "                    self.A_noise * np.ones_like(std_est[\"H1_std\"]),\n",
    "                ),\n",
    "                np.where(\n",
    "                    std_est[\"L1_ts\"] > 5,\n",
    "                    std_est[\"L1_std\"],\n",
    "                    self.A_noise * np.ones_like(std_est[\"L1_std\"]),\n",
    "                ),\n",
    "            ]\n",
    "        else:\n",
    "            A_noise = self.A_noise * np.ones((2, self.sz_t))\n",
    "        for source in range(len(n_stat)):\n",
    "            for n in n_stat[source]:\n",
    "                if n == 0:\n",
    "                    noise[source].append(torch.zeros(self.sz_f))\n",
    "                    continue\n",
    "                dist = torch.distributions.chi2.Chi2(2 * n)  # 2 because real+img\n",
    "                sample = dist.sample((self.sz_f,)) / n\n",
    "                sample *= A_noise[source][n] * A_noise[source][n]\n",
    "                noise[source].append(sample)\n",
    "        noise = torch.stack([torch.stack(noise[0], -1), torch.stack(noise[1], -1)], 0)\n",
    "\n",
    "        if torch.rand(1).item() < self.p:  # positive sample\n",
    "            target = 1\n",
    "            x0 = torch.from_numpy(\n",
    "                np.stack([data[\"H1\"], data[\"L1\"]], 0).astype(np.float32)\n",
    "            )\n",
    "            c, h, w = x0.shape\n",
    "            noise = noise.repeat(1, 2, 1)[:, :h, :]\n",
    "            x0 = torch.cat([x0, noise], 0)#[:, 20:-20]\n",
    "            x0 = self.tfrms(x0)  # transform noise and signal togather\n",
    "\n",
    "            depth = self.depth0 + (self.depth1 - self.depth0) * torch.rand(1)\n",
    "            # print(depth)\n",
    "            scale = (\n",
    "                1e2 * self.A_noise * self.tosqrtSX\n",
    "            )  # noise-free data is generated at h=1e-2\n",
    "            x = x0[c:] + x0[:c] * scale**2 / depth**2  # noise + signal\n",
    "\n",
    "            if target == 1:\n",
    "                raw = (\n",
    "                    x0[:c]\n",
    "                    / x0[:c].max()\n",
    "                    * (self.depth1 - depth)\n",
    "                    / (self.depth1 - self.depth0)\n",
    "                )\n",
    "            else:\n",
    "                raw = torch.zeros_like(x)\n",
    "        else:\n",
    "            target = 0\n",
    "            x = self.tfrms(noise)\n",
    "            raw = torch.zeros_like(x)\n",
    "\n",
    "        x[0] /= torch.max(x[0].mean(0, keepdim=True), 0.1 * torch.ones_like(x[0]))\n",
    "        x[1] /= torch.max(x[1].mean(0, keepdim=True), 0.1 * torch.ones_like(x[1]))\n",
    "\n",
    "        # x = torch.cat([x, 0.5 * (x[0] + x[1]).unsqueeze(0)], 0)\n",
    "        # raw = torch.cat([raw, 0.5 * (raw[0] + raw[1]).unsqueeze(0)], 0)\n",
    "\n",
    "        return x, target\n",
    "\n",
    "    def generate_random_file(self):\n",
    "        noise_fn = random.choice(self.noise_fns)\n",
    "        signal_fn = random.choice(self.signal_fns)\n",
    "        if np.random.rand() >= 0.66:\n",
    "            img = normalize(torch.load(noise_fn))\n",
    "            y = 0.0\n",
    "        else:\n",
    "            img = normalize(combine(torch.load(signal_fn), torch.load(noise_fn)))\n",
    "            y = 1.0\n",
    "\n",
    "        img = img.numpy()\n",
    "        if np.random.rand() <= 0.5:  # horizontal flip\n",
    "            img = np.flip(img, axis=1).copy()\n",
    "        if np.random.rand() <= 0.5:  # vertical flip\n",
    "            img = np.flip(img, axis=2).copy()\n",
    "        if np.random.rand() <= 0.5:  # vertical shift\n",
    "            img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "        if np.random.rand() <= 0.5:  # channel shuffle\n",
    "            img = img[np.random.permutation([0, 1]), ...]\n",
    "        return torch.tensor(img), y\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.get_on_fly(idx)\n",
    "        if self.tfms:\n",
    "            if np.random.rand() <= 0.3:\n",
    "                x = freq_mask(x)\n",
    "            if np.random.rand() <= 0.3:\n",
    "                x = time_mask(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def read_pkl(filename):  \n",
    "    data = dict()\n",
    "    with open(filename, 'rb') as file1: \n",
    "        k = pickle.load(file1)\n",
    "        data['L1_SFTs_amplitudes'] = np.array(k[\"L1\"]['spectrogram'])\n",
    "        data['L1_ts'] = np.array(k[\"L1\"]['timestamps'])\n",
    "        # Retrieve the Hanford decector data\n",
    "        data['H1_SFTs_amplitudes'] =  np.array(k[\"H1\"]['spectrogram'])\n",
    "        data['H1_ts'] = np.array(k[\"H1\"]['timestamps'])\n",
    "        data['freq'] = np.array(k['frequency'])\n",
    "    return data \n",
    "    \n",
    "def normalize_pickle(data, sz_t=128):     \n",
    "    time_ids = {\"H1\": data[\"H1_ts\"], \"L1\": data[\"L1_ts\"]}\n",
    "    mean_statH = binned_statistic(\n",
    "        time_ids[\"H1\"],\n",
    "        data[\"H1_SFTs_amplitudes\"],\n",
    "        statistic=\"mean\",\n",
    "        bins=sz_t,\n",
    "        range=(\n",
    "            max(time_ids[\"H1\"].min(), time_ids[\"L1\"].min()),\n",
    "            min(time_ids[\"H1\"].max(), time_ids[\"L1\"].max()),\n",
    "        ),\n",
    "    )\n",
    "    mean_statL = binned_statistic(\n",
    "        time_ids[\"L1\"],\n",
    "        data[\"L1_SFTs_amplitudes\"],\n",
    "        statistic=\"mean\",\n",
    "        bins=sz_t,\n",
    "        range=(\n",
    "            max(time_ids[\"H1\"].min(), time_ids[\"L1\"].min()),\n",
    "            min(time_ids[\"H1\"].max(), time_ids[\"L1\"].max()),\n",
    "        ),\n",
    "    )\n",
    "    mean_statH = np.nan_to_num(np.transpose(mean_statH.statistic, (0, 1)))\n",
    "    mean_statL = np.nan_to_num(np.transpose(mean_statL.statistic, (0, 1)))\n",
    "\n",
    "    x = torch.from_numpy(np.stack([mean_statH, mean_statL], 0).astype(np.float32))\n",
    "    c, h, w = x.shape\n",
    "    x[0] /= torch.max(x[0].mean(0, keepdim=True), 0.1 * torch.ones_like(x[0]))\n",
    "    x[1] /= torch.max(x[1].mean(0, keepdim=True), 0.1 * torch.ones_like(x[1]))\n",
    "    #x = torch.cat([x, 0.5 * (x[0] + x[1]).unsqueeze(0)], 0)\n",
    "    return x\n",
    "\n",
    "def read_data(path):\n",
    "    data = {}\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        ID_key =  path.stem\n",
    "        # Retrieve the frequency data\n",
    "        try:\n",
    "            data['freq'] = np.array(f['frequency_Hz'])\n",
    "        except:\n",
    "            data['freq'] = np.array(f[ID_key]['frequency_Hz'])\n",
    "        # Retrieve the Livingston decector data\n",
    "        data['L1_SFTs_amplitudes'] = np.array(f[ID_key]['L1']['SFTs'])\n",
    "        data['L1_ts'] = np.array(f[ID_key]['L1']['timestamps_GPS'])\n",
    "        # Retrieve the Hanford decector data\n",
    "        data['H1_SFTs_amplitudes'] = np.array(f[ID_key]['H1']['SFTs'])\n",
    "        data['H1_ts'] = np.array(f[ID_key]['H1']['timestamps_GPS'])\n",
    "    return data\n",
    "\n",
    "class ValLoaderPickle(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        try:\n",
    "            img = normalize_pickle(read_pkl(r.id))\n",
    "        except:\n",
    "            img = normalize(read_data(r.id))\n",
    "        return img.float(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a785480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "\n",
    "def generate_report(df, p, fn):\n",
    "    pred = torch.sigmoid(p).cpu().numpy().reshape(-1)\n",
    "    val_df_eval = df.copy()\n",
    "    val_df_eval[\"pred\"] = pred\n",
    "    val_df_eval = val_df_eval.dropna(subset=\"pred\")\n",
    "    val_df_eval.to_csv(f\"{fn}_oof.csv\")\n",
    "\n",
    "    roc_100 = roc_auc_score(val_df_eval[\"target\"], val_df_eval[\"pred\"])\n",
    "    tr_comp = val_df_eval.query('data_type==\"comp_train\"')\n",
    "    roc_comp_train = roc_auc_score(tr_comp[\"target\"], tr_comp[\"pred\"])\n",
    "    return {\"roc_all\": roc_100, \"roc_comp_train\": roc_comp_train}\n",
    "\n",
    "\n",
    "class SaveModel:\n",
    "    def __init__(self, folder, exp_name, best=np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score < self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelMetric:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelEpoch:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder)\n",
    "        self.exp_name = exp_name\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        self.best = score\n",
    "        print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "        torch.save(model.state_dict(), f\"{self.folder/self.exp_name}_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def custom_auc_score(p, gt):\n",
    "    p = torch.nan_to_num(p)\n",
    "    return roc_auc_score(gt.cpu().numpy(), torch.sigmoid(p).cpu().numpy().reshape(-1))\n",
    "\n",
    "\n",
    "def fit_mixup(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    loss_fn,\n",
    "    opt,\n",
    "    metric,\n",
    "    val_df,\n",
    "    folder=\"models\",\n",
    "    exp_name=\"exp_00\",\n",
    "    device=None,\n",
    "    sched=None,\n",
    "    mixup_=False,\n",
    "    save_md=SaveModelEpoch,\n",
    "):\n",
    "    if device is None:\n",
    "        device = (\n",
    "            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    loss_fn_trn = loss_fn\n",
    "    if mixup_:\n",
    "        mixup = Mixup(num_classes=2, mixup_alpha=0.4, prob=0.8)\n",
    "        loss_fn_trn = BinaryCrossEntropy()\n",
    "    mb = master_bar(range(epochs))\n",
    "\n",
    "    mb.write(\n",
    "        [\n",
    "            \"epoch\",\n",
    "            \"train_loss\",\n",
    "            \"valid_loss\",\n",
    "            \"val_metric\",\n",
    "            \"roc_all\",\n",
    "            \"roc_comp_train\",\n",
    "        ],\n",
    "        table=True,\n",
    "    )\n",
    "    model.to(device)  # we have to put our model on gpu\n",
    "    # scaler = torch.cuda.amp.GradScaler()  # this for half precision training\n",
    "    save_md = save_md(folder, exp_name)\n",
    "\n",
    "    for i in mb:  # iterating  epoch\n",
    "        trn_loss, val_loss = 0.0, 0.0\n",
    "        trn_n, val_n = len(train_dl.dataset), len(valid_dl.dataset)\n",
    "        model.train()  # set model for training\n",
    "        for (xb, yb) in progress_bar(train_dl, parent=mb):\n",
    "            xb, yb = xb.to(device), yb.to(device)  # putting batches to device\n",
    "            if mixup_:\n",
    "                xb, yb = mixup(xb, yb)\n",
    "\n",
    "            out = model(xb)  # forward pass\n",
    "            loss = loss_fn_trn(out, yb)  # calulation loss\n",
    "\n",
    "            trn_loss += loss.item()\n",
    "            # print(loss.item())\n",
    "            opt.zero_grad()  # zeroing optimizer\n",
    "            loss.backward()  # backward\n",
    "            opt.step()  # optimzers step\n",
    "            if sched is not None:\n",
    "                sched.step()  # scuedular step\n",
    "\n",
    "        trn_loss /= mb.child.total\n",
    "\n",
    "        # putting model in eval mode\n",
    "        model.eval()\n",
    "        gt = []\n",
    "        pred = []\n",
    "        # after epooch is done we can run a validation dataloder and see how are doing\n",
    "        with torch.no_grad():\n",
    "            for (xb, yb) in progress_bar(valid_dl, parent=mb):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(torch.nan_to_num(out), yb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                gt.append(yb.detach())\n",
    "                pred.append(out.detach())\n",
    "        # calculating metric\n",
    "        metric_ = metric(torch.cat(pred), torch.cat(gt))\n",
    "        # saving model if necessary\n",
    "        save_md(metric_, model, i)\n",
    "        val_loss /= mb.child.total\n",
    "        dict_res = generate_report(val_df, torch.cat(pred), f\"{folder}/{exp_name}_{i}\")\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"trn_loss\": [trn_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"metric\": [metric_],\n",
    "                \"roc_all\": [dict_res[\"roc_all\"]],\n",
    "                \"roc_comp_train\": [dict_res[\"roc_comp_train\"]],\n",
    "            }\n",
    "        ).to_csv(f\"{folder}/{exp_name}_{i}.csv\", index=False)\n",
    "        mb.write(\n",
    "            [\n",
    "                i,\n",
    "                f\"{trn_loss:.6f}\",\n",
    "                f\"{val_loss:.6f}\",\n",
    "                f\"{metric_:.6f}\",\n",
    "                f\"{dict_res['roc_all']:.6f}\",\n",
    "                f\"{dict_res['roc_comp_train']:.6f}\",\n",
    "            ],\n",
    "            table=True,\n",
    "        )\n",
    "    print(\"Training done\")\n",
    "    # loading the best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3eed83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mask(spec):\n",
    "    cloned = spec.clone().detach()\n",
    "    len_spectro = cloned.shape[2]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    T = np.random.randint(7, 12)\n",
    "    for i in range(0, num_masks):\n",
    "        t = random.randrange(0, T)\n",
    "        t_zero = random.randrange(0, len_spectro - t)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (t_zero == t_zero + t): return cloned\n",
    "\n",
    "        mask_end = random.randrange(t_zero, t_zero + t)\n",
    "        cloned[:, :,t_zero:mask_end] = 0\n",
    "    return cloned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def freq_mask(spec):\n",
    "    cloned = spec.clone().detach()\n",
    "    num_mel_channels = cloned.shape[1]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    F = np.random.randint(10, 30)\n",
    "    for i in range(0, num_masks):        \n",
    "        f = random.randrange(0, F)\n",
    "        f_zero = random.randrange(0, num_mel_channels - f)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "        mask_end = random.randrange(f_zero, f_zero + f) \n",
    "        cloned[:, f_zero:mask_end, :] = 0\n",
    "    \n",
    "    return cloned\n",
    "\n",
    "\n",
    "def normalize(data, sz_t=128):     \n",
    "    time_ids = {\"H1\": data[\"H1_ts\"], \"L1\": data[\"L1_ts\"]}\n",
    "    mean_statH = binned_statistic(\n",
    "        time_ids[\"H1\"],\n",
    "        np.abs(data[\"H1_SFTs_amplitudes\"] * 1e22) ** 2,\n",
    "        statistic=\"mean\",\n",
    "        bins=sz_t,\n",
    "        range=(\n",
    "            max(time_ids[\"H1\"].min(), time_ids[\"L1\"].min()),\n",
    "            min(time_ids[\"H1\"].max(), time_ids[\"L1\"].max()),\n",
    "        ),\n",
    "    )\n",
    "    mean_statL = binned_statistic(\n",
    "        time_ids[\"L1\"],\n",
    "        np.abs(data[\"L1_SFTs_amplitudes\"] * 1e22) ** 2,\n",
    "        statistic=\"mean\",\n",
    "        bins=sz_t,\n",
    "        range=(\n",
    "            max(time_ids[\"H1\"].min(), time_ids[\"L1\"].min()),\n",
    "            min(time_ids[\"H1\"].max(), time_ids[\"L1\"].max()),\n",
    "        ),\n",
    "    )\n",
    "    mean_statH = np.nan_to_num(np.transpose(mean_statH.statistic, (0, 1)))\n",
    "    mean_statL = np.nan_to_num(np.transpose(mean_statL.statistic, (0, 1)))\n",
    "\n",
    "    x = torch.from_numpy(np.stack([mean_statH, mean_statL], 0).astype(np.float32))\n",
    "    c, h, w = x.shape\n",
    "    x[0] /= torch.max(x[0].mean(0, keepdim=True), 0.1 * torch.ones_like(x[0]))\n",
    "    x[1] /= torch.max(x[1].mean(0, keepdim=True), 0.1 * torch.ones_like(x[1]))\n",
    "    #x = torch.cat([x, 0.5 * (x[0] + x[1]).unsqueeze(0)], 0)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "def combine(sig_, noise, w=1.):\n",
    "    sig = copy(sig_)\n",
    "    min_value_l= min(sig['L1_SFTs_amplitudes'].shape[1], noise['L1_SFTs_amplitudes'].shape[1])\n",
    "    min_value_h= min(sig['H1_SFTs_amplitudes'].shape[1], noise['H1_SFTs_amplitudes'].shape[1])\n",
    "    sig['L1_SFTs_amplitudes'] = w * sig['L1_SFTs_amplitudes'][:, :min_value_l] + noise['L1_SFTs_amplitudes'][:, :min_value_l]\n",
    "    sig['H1_SFTs_amplitudes'] = w * sig['H1_SFTs_amplitudes'][:, :min_value_h] + noise['H1_SFTs_amplitudes'][:, :min_value_h]\n",
    "    sig['H1_ts'] = sig['H1_ts'][:min_value_h]\n",
    "    sig['L1_ts'] = sig['L1_ts'][:min_value_l]\n",
    "    return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e7ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a18abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = list(Path(\"../data/custom_data/SIGNAL_V0/data\").glob(\"*.pth\")) + list(Path(\"../data/custom_data/SIGNAL_V1/data\").glob(\"*.pth\"))\n",
    "len(signal)\n",
    "noise = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5a5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_train = pd.read_csv(\"../data/train_labels.csv\")\n",
    "comp_train.columns = [\"fn\", \"target\"]\n",
    "comp_train = comp_train.query(\"target>=0\")\n",
    "comp_train[\"fn\"] = comp_train[\"fn\"].apply(lambda x: Path(\"../data/train\") / f\"{x}.hdf5\")\n",
    "comp_train.columns = [\"id\", \"target\"]\n",
    "comp_train[\"data_type\"] = \"comp_train\"\n",
    "\n",
    "df_eval = pd.read_csv('../../val/v21v.csv')\n",
    "df_eval.id = df_eval.id.apply(lambda x: Path(f\"../../val/v21_val/{x}.pickle\"))\n",
    "\n",
    "df_eval = pd.concat([df_eval, comp_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975a2564",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='29' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      29.00% [29/100 2:25:13&lt;5:55:33]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>roc_all</th>\n",
       "      <th>roc_comp_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.648979</td>\n",
       "      <td>0.643454</td>\n",
       "      <td>0.432039</td>\n",
       "      <td>0.431804</td>\n",
       "      <td>0.331912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639805</td>\n",
       "      <td>0.643413</td>\n",
       "      <td>0.487041</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.454550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.639623</td>\n",
       "      <td>0.641968</td>\n",
       "      <td>0.577860</td>\n",
       "      <td>0.577776</td>\n",
       "      <td>0.643331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.646103</td>\n",
       "      <td>0.645419</td>\n",
       "      <td>0.415347</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.324937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.641891</td>\n",
       "      <td>0.570926</td>\n",
       "      <td>0.570835</td>\n",
       "      <td>0.672444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.639670</td>\n",
       "      <td>0.645749</td>\n",
       "      <td>0.604045</td>\n",
       "      <td>0.603989</td>\n",
       "      <td>0.738350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.640141</td>\n",
       "      <td>0.642222</td>\n",
       "      <td>0.477221</td>\n",
       "      <td>0.477032</td>\n",
       "      <td>0.406806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.644841</td>\n",
       "      <td>0.642238</td>\n",
       "      <td>0.509820</td>\n",
       "      <td>0.509665</td>\n",
       "      <td>0.518169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.639285</td>\n",
       "      <td>0.642076</td>\n",
       "      <td>0.557189</td>\n",
       "      <td>0.557084</td>\n",
       "      <td>0.631081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.639697</td>\n",
       "      <td>0.641939</td>\n",
       "      <td>0.397522</td>\n",
       "      <td>0.397251</td>\n",
       "      <td>0.308925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.642062</td>\n",
       "      <td>0.641851</td>\n",
       "      <td>0.421910</td>\n",
       "      <td>0.421664</td>\n",
       "      <td>0.324438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.638951</td>\n",
       "      <td>0.642588</td>\n",
       "      <td>0.405903</td>\n",
       "      <td>0.405640</td>\n",
       "      <td>0.291938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.640026</td>\n",
       "      <td>0.642265</td>\n",
       "      <td>0.430365</td>\n",
       "      <td>0.430128</td>\n",
       "      <td>0.317719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.638180</td>\n",
       "      <td>0.641887</td>\n",
       "      <td>0.417067</td>\n",
       "      <td>0.416816</td>\n",
       "      <td>0.305188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.640266</td>\n",
       "      <td>0.642299</td>\n",
       "      <td>0.442221</td>\n",
       "      <td>0.441997</td>\n",
       "      <td>0.327894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.641958</td>\n",
       "      <td>0.641868</td>\n",
       "      <td>0.390639</td>\n",
       "      <td>0.390361</td>\n",
       "      <td>0.277737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.638975</td>\n",
       "      <td>0.641917</td>\n",
       "      <td>0.391947</td>\n",
       "      <td>0.391670</td>\n",
       "      <td>0.290594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.643284</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.473366</td>\n",
       "      <td>0.473173</td>\n",
       "      <td>0.379994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.639239</td>\n",
       "      <td>0.641829</td>\n",
       "      <td>0.415230</td>\n",
       "      <td>0.414977</td>\n",
       "      <td>0.307794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.640368</td>\n",
       "      <td>0.641829</td>\n",
       "      <td>0.452323</td>\n",
       "      <td>0.452108</td>\n",
       "      <td>0.348112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.637916</td>\n",
       "      <td>0.642327</td>\n",
       "      <td>0.622191</td>\n",
       "      <td>0.622153</td>\n",
       "      <td>0.745344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.641719</td>\n",
       "      <td>0.642021</td>\n",
       "      <td>0.384742</td>\n",
       "      <td>0.384458</td>\n",
       "      <td>0.279225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.639934</td>\n",
       "      <td>0.642281</td>\n",
       "      <td>0.591668</td>\n",
       "      <td>0.591598</td>\n",
       "      <td>0.676294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.640814</td>\n",
       "      <td>0.642431</td>\n",
       "      <td>0.630861</td>\n",
       "      <td>0.630832</td>\n",
       "      <td>0.707188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.642906</td>\n",
       "      <td>0.641922</td>\n",
       "      <td>0.448605</td>\n",
       "      <td>0.448387</td>\n",
       "      <td>0.368981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.637715</td>\n",
       "      <td>0.642009</td>\n",
       "      <td>0.428714</td>\n",
       "      <td>0.428475</td>\n",
       "      <td>0.343131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.643158</td>\n",
       "      <td>0.641826</td>\n",
       "      <td>0.624518</td>\n",
       "      <td>0.624482</td>\n",
       "      <td>0.747638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.647718</td>\n",
       "      <td>0.642266</td>\n",
       "      <td>0.624181</td>\n",
       "      <td>0.624145</td>\n",
       "      <td>0.755981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.639460</td>\n",
       "      <td>0.642144</td>\n",
       "      <td>0.457953</td>\n",
       "      <td>0.457744</td>\n",
       "      <td>0.404406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='22' class='' max='221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      9.95% [22/221 00:26&lt;03:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with value: 0.4320393994206779.\n",
      "Better model found at epoch 1 with value: 0.4870412404302893.\n",
      "Better model found at epoch 2 with value: 0.5778600958534994.\n",
      "Better model found at epoch 3 with value: 0.41534698402937775.\n",
      "Better model found at epoch 4 with value: 0.5709258481500424.\n",
      "Better model found at epoch 5 with value: 0.604045417459063.\n",
      "Better model found at epoch 6 with value: 0.47722090917439886.\n",
      "Better model found at epoch 7 with value: 0.509819968256953.\n",
      "Better model found at epoch 8 with value: 0.5571890911075305.\n",
      "Better model found at epoch 9 with value: 0.39752228420227415.\n",
      "Better model found at epoch 10 with value: 0.4219102165687961.\n",
      "Better model found at epoch 11 with value: 0.40590265917291657.\n",
      "Better model found at epoch 12 with value: 0.4303653995704755.\n",
      "Better model found at epoch 13 with value: 0.417066751995617.\n",
      "Better model found at epoch 14 with value: 0.44222145911778915.\n",
      "Better model found at epoch 15 with value: 0.390639158849182.\n",
      "Better model found at epoch 16 with value: 0.39194737677002817.\n",
      "Better model found at epoch 17 with value: 0.4733655277091004.\n",
      "Better model found at epoch 18 with value: 0.4152300681215906.\n",
      "Better model found at epoch 19 with value: 0.45232269105148326.\n",
      "Better model found at epoch 20 with value: 0.6221907360977155.\n",
      "Better model found at epoch 21 with value: 0.3847423923590176.\n",
      "Better model found at epoch 22 with value: 0.5916680914374964.\n",
      "Better model found at epoch 23 with value: 0.6308605724711043.\n",
      "Better model found at epoch 24 with value: 0.4486053096822585.\n",
      "Better model found at epoch 25 with value: 0.4287135729053721.\n",
      "Better model found at epoch 26 with value: 0.6245179827858642.\n",
      "Better model found at epoch 27 with value: 0.6241809987722166.\n",
      "Better model found at epoch 28 with value: 0.45795295582169826.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trn_dl) \u001b[38;5;241m*\u001b[39m CFG\u001b[38;5;241m.\u001b[39mepoch)\n\u001b[1;32m     36\u001b[0m sched \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(\n\u001b[1;32m     37\u001b[0m     opt, num_warmup_steps\u001b[38;5;241m=\u001b[39mwarmup_steps, num_training_steps\u001b[38;5;241m=\u001b[39mtotal_steps\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m \u001b[43mfit_mixup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrn_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvld_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_auc_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43msched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mfit_mixup\u001b[0;34m(epochs, model, train_dl, valid_dl, loss_fn, opt, metric, val_df, folder, exp_name, device, sched, mixup_, save_md)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# print(loss.item())\u001b[39;00m\n\u001b[1;32m    117\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# zeroing optimizer\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[1;32m    119\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# optimzers step\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sched \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:393\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/overrides.py:1524\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1519\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1520\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1524\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fastai/torch_core.py:376\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 376\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:1088\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1088\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:401\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    394\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    395\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    400\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 401\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:191\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train - val split\n",
    "fold =0\n",
    "trn_ds = G2NetDatasetTrain(noise, signal)\n",
    "vld_ds = ValLoaderPickle(df_eval)\n",
    "\n",
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=True,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "custom_model = create_model(\n",
    "                    CFG.model_name,\n",
    "                    pretrained=True,\n",
    "                    num_classes=1,\n",
    "                    in_chans=2,\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "opt = torch.optim.AdamW(custom_model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "loss_func = BCEWithLogitsLossFlat()\n",
    "warmup_steps = 1000\n",
    "total_steps = int(len(trn_dl) * CFG.epoch)\n",
    "sched = get_linear_schedule_with_warmup(\n",
    "    opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "fit_mixup(\n",
    "    epochs=CFG.epoch,\n",
    "    model=custom_model,\n",
    "    train_dl=trn_dl,\n",
    "    valid_dl=vld_dl,\n",
    "    loss_fn=loss_func,\n",
    "    opt=opt,\n",
    "    val_df=df_eval,\n",
    "    metric=custom_auc_score,\n",
    "    folder=CFG.folder,\n",
    "    exp_name=f\"{CFG.exp_name}_{fold}\",\n",
    "    device=\"cuda:0\",\n",
    "    sched=sched,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff0cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trn_ds = G2NetDatasetTrain(noise, signal)\n",
    "#for i in range(len(trn_ds)):\n",
    "#    x, y = trn_ds[i]\n",
    "#    print(y)\n",
    "#    plt.imshow(x.mean(0))\n",
    "#    plt.pause(0.1)\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805a62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
