{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c06bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, glob, os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import norm\n",
    "from timm import create_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from thop import profile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "##---------- Basic Layers ----------\n",
    "def conv3x3(in_chn, out_chn, bias=True):\n",
    "    layer = nn.Conv2d(in_chn, out_chn, kernel_size=3, stride=1, padding=1, bias=bias)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, bias=False, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        padding=(kernel_size // 2),\n",
    "        bias=bias,\n",
    "        stride=stride,\n",
    "    )\n",
    "\n",
    "\n",
    "def bili_resize(factor):\n",
    "    return nn.Upsample(scale_factor=factor, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "\n",
    "##---------- Basic Blocks ----------\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, downsample):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "        self.block = SK_RDB(in_channels=in_size, growth_rate=out_size, num_layers=3)\n",
    "        if downsample:\n",
    "            self.downsample = PS_down(out_size, out_size, downscale=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if self.downsample:\n",
    "            out_down = self.downsample(out)\n",
    "            return out_down, out\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        # self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2, bias=True)\n",
    "        self.up = PS_up(in_size, out_size, upscale=2)\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, False)\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        out = torch.cat([up, bridge], dim=1)\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "##---------- Resizing Modules (Pixel(Un)Shuffle) ----------\n",
    "class PS_down(nn.Module):\n",
    "    def __init__(self, in_size, out_size, downscale):\n",
    "        super(PS_down, self).__init__()\n",
    "        self.UnPS = nn.PixelUnshuffle(downscale)\n",
    "        self.conv1 = nn.Conv2d((downscale**2) * in_size, out_size, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.UnPS(x)  # h/2, w/2, 4*c\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PS_up(nn.Module):\n",
    "    def __init__(self, in_size, out_size, upscale):\n",
    "        super(PS_up, self).__init__()\n",
    "\n",
    "        self.PS = nn.PixelShuffle(upscale)\n",
    "        self.conv1 = nn.Conv2d(in_size // (upscale**2), out_size, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.PS(x)  # h/2, w/2, 4*c\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "##---------- Selective Kernel Feature Fusion (SKFF) ----------\n",
    "class SKFF(nn.Module):\n",
    "    def __init__(self, in_channels, height=3, reduction=8, bias=False):\n",
    "        super(SKFF, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        d = max(int(in_channels / reduction), 4)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_du = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, d, 1, padding=0, bias=bias), nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self.fcs = nn.ModuleList([])\n",
    "        for i in range(self.height):\n",
    "            self.fcs.append(\n",
    "                nn.Conv2d(d, in_channels, kernel_size=1, stride=1, bias=bias)\n",
    "            )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, inp_feats):\n",
    "        batch_size, n_feats, H, W = inp_feats[1].shape\n",
    "\n",
    "        inp_feats = torch.cat(inp_feats, dim=1)\n",
    "        inp_feats = inp_feats.view(\n",
    "            batch_size, self.height, n_feats, inp_feats.shape[2], inp_feats.shape[3]\n",
    "        )\n",
    "\n",
    "        feats_U = torch.sum(inp_feats, dim=1)\n",
    "        feats_S = self.avg_pool(feats_U)\n",
    "        feats_Z = self.conv_du(feats_S)\n",
    "\n",
    "        attention_vectors = [fc(feats_Z) for fc in self.fcs]\n",
    "        attention_vectors = torch.cat(attention_vectors, dim=1)\n",
    "        attention_vectors = attention_vectors.view(\n",
    "            batch_size, self.height, n_feats, 1, 1\n",
    "        )\n",
    "\n",
    "        attention_vectors = self.softmax(attention_vectors)\n",
    "        feats_V = torch.sum(inp_feats * attention_vectors, dim=1)\n",
    "\n",
    "        return feats_V\n",
    "\n",
    "\n",
    "##---------- Dense Block ----------\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, I):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=3 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sk = SKFF(out_channels, height=2, reduction=8, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.conv(x))\n",
    "        # output = torch.cat([x, x1], 1) # -> RDB\n",
    "        output = self.sk((x, x1))\n",
    "        return output\n",
    "\n",
    "\n",
    "##---------- Selective Kernel Residual Dense Block (SK-RDB) ----------\n",
    "class SK_RDB(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(SK_RDB, self).__init__()\n",
    "        self.identity = nn.Conv2d(in_channels, growth_rate, 1, 1, 0)\n",
    "        self.layers = nn.Sequential(\n",
    "            *[DenseLayer(in_channels, in_channels, I=i) for i in range(num_layers)]\n",
    "        )\n",
    "        self.lff = nn.Conv2d(in_channels, growth_rate, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.identity(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.lff(x)\n",
    "        return res + x\n",
    "\n",
    "\n",
    "##---------- testNet ----------\n",
    "class SRMNet(nn.Module):\n",
    "    def __init__(self, in_chn=3, wf=96, depth=4):\n",
    "        super(SRMNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.down_path = nn.ModuleList()\n",
    "        self.bili_down = bili_resize(0.5)\n",
    "        self.conv_01 = nn.Conv2d(in_chn, wf, 3, 1, 1)\n",
    "\n",
    "        # encoder of UNet\n",
    "        prev_channels = 0\n",
    "        for i in range(depth):  # 0,1,2,3\n",
    "            downsample = True if (i + 1) < depth else False\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels + wf, (2**i) * wf, downsample)\n",
    "            )\n",
    "            prev_channels = (2**i) * wf\n",
    "\n",
    "        # decoder of UNet\n",
    "        self.up_path = nn.ModuleList()\n",
    "        self.skip_conv = nn.ModuleList()\n",
    "        self.conv_up = nn.ModuleList()\n",
    "        self.bottom_conv = nn.Conv2d(prev_channels, wf, 3, 1, 1)\n",
    "        self.bottom_up = bili_resize(2 ** (depth - 1))\n",
    "\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, (2**i) * wf))\n",
    "            self.skip_conv.append(nn.Conv2d((2**i) * wf, (2**i) * wf, 3, 1, 1))\n",
    "            self.conv_up.append(\n",
    "                nn.Sequential(\n",
    "                    *[nn.Conv2d((2**i) * wf, wf, 3, 1, 1), bili_resize(2**i)]\n",
    "                )\n",
    "            )\n",
    "            prev_channels = (2**i) * wf\n",
    "\n",
    "        self.final_ff = SKFF(in_channels=wf, height=depth)\n",
    "        self.last = conv3x3(prev_channels, in_chn, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        img = x\n",
    "        scale_img = img\n",
    "\n",
    "        ##### shallow conv #####\n",
    "        x1 = self.conv_01(img)\n",
    "        encs = []\n",
    "        ######## UNet ########\n",
    "        # Down-path (Encoder)\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            if i == 0:\n",
    "                x1, x1_up = down(x1)\n",
    "                encs.append(x1_up)\n",
    "            elif (i + 1) < self.depth:\n",
    "                scale_img = self.bili_down(scale_img)\n",
    "                left_bar = self.conv_01(scale_img)\n",
    "                x1 = torch.cat([x1, left_bar], dim=1)\n",
    "                x1, x1_up = down(x1)\n",
    "                encs.append(x1_up)\n",
    "            else:\n",
    "                scale_img = self.bili_down(scale_img)\n",
    "                left_bar = self.conv_01(scale_img)\n",
    "                x1 = torch.cat([x1, left_bar], dim=1)\n",
    "                x1 = down(x1)\n",
    "\n",
    "        # Up-path (Decoder)\n",
    "        ms_result = [self.bottom_up(self.bottom_conv(x1))]\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x1 = up(x1, self.skip_conv[i](encs[-i - 1]))\n",
    "            ms_result.append(self.conv_up[i](x1))\n",
    "        # Multi-scale selective feature fusion\n",
    "        msff_result = self.final_ff(ms_result)\n",
    "\n",
    "        ##### Reconstruct #####\n",
    "        out_1 = self.last(msff_result) + img\n",
    "\n",
    "        return out_1\n",
    "    \n",
    "    \n",
    "\n",
    "def normalize(X):\n",
    "    X = (X[..., None].view(X.real.dtype) ** 2).sum(-1)\n",
    "    POS = int(X.size * 0.99903)\n",
    "    EXP = norm.ppf((POS + 0.4) / (X.size + 0.215))\n",
    "    scale = np.partition(X.flatten(), POS, -1)[POS]\n",
    "    X /= scale / EXP.astype(scale.dtype) ** 2\n",
    "    return X\n",
    "\n",
    "\n",
    "def dataload(filepath):\n",
    "    astime = np.full([2, 360, 5760], np.nan, dtype=np.float32)\n",
    "    with h5py.File(filepath, \"r\") as f:\n",
    "        fid, _ = os.path.splitext(os.path.split(filepath)[1])\n",
    "        HT = (\n",
    "            (np.asarray(f[fid][\"H1\"][\"timestamps_GPS\"]) / 1800).round().astype(np.int64)\n",
    "        )\n",
    "        LT = (\n",
    "            (np.asarray(f[fid][\"L1\"][\"timestamps_GPS\"]) / 1800).round().astype(np.int64)\n",
    "        )\n",
    "        MIN = min(HT.min(), LT.min())\n",
    "        HT -= MIN\n",
    "        LT -= MIN\n",
    "        H1 = normalize(np.asarray(f[fid][\"H1\"][\"SFTs\"], np.complex128))\n",
    "        valid = HT < 5760\n",
    "        astime[0][:, HT[valid]] = H1[:, valid]\n",
    "        L1 = normalize(np.asarray(f[fid][\"L1\"][\"SFTs\"], np.complex128))\n",
    "        valid = LT < 5760\n",
    "        astime[1][:, LT[valid]] = L1[:, valid]\n",
    "    gc.collect()\n",
    "    return fid, astime, H1.mean(), L1.mean()\n",
    "\n",
    "\n",
    "def normalize_custom(x, pmin=3, pmax=97, axis=None, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    \"\"\"Percentile-based image normalization.\"\"\"\n",
    "\n",
    "    mi = np.percentile(x,pmin,axis=axis,keepdims=True)\n",
    "    ma = np.percentile(x,pmax,axis=axis,keepdims=True)\n",
    "    return normalize_mi_ma(x, mi, ma, clip=clip, eps=eps, dtype=dtype)\n",
    "\n",
    "\n",
    "def normalize_mi_ma(x, mi, ma, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    if dtype is not None:\n",
    "        x   = x.astype(dtype,copy=False)\n",
    "        mi  = dtype(mi) if np.isscalar(mi) else mi.astype(dtype,copy=False)\n",
    "        ma  = dtype(ma) if np.isscalar(ma) else ma.astype(dtype,copy=False)\n",
    "        eps = dtype(eps)\n",
    "\n",
    "    try:\n",
    "        import numexpr\n",
    "        x = numexpr.evaluate(\"(x - mi) / ( ma - mi + eps )\")\n",
    "    except ImportError:\n",
    "        x =                   (x - mi) / ( ma - mi + eps )\n",
    "\n",
    "    if clip:\n",
    "        x = np.clip(x,0,1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(num, input, H1, L1):\n",
    "    input = torch.from_numpy(input).to(\"cuda\", non_blocking=True)\n",
    "    rescale = torch.tensor([[H1, L1]]).to(\"cuda\", non_blocking=True)\n",
    "    tta = (\n",
    "        torch.randn([num, *input.shape, 2], device=input.device, dtype=torch.float32)\n",
    "        .square_()\n",
    "        .sum(-1)\n",
    "    )\n",
    "    tta *= rescale[..., None, None] / 2\n",
    "    valid = ~torch.isnan(input)\n",
    "    tta[:, valid] = input[valid].float()\n",
    "    return tta\n",
    "\n",
    "\n",
    "class LargeKernel_debias(nn.Conv2d):\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        finput = input.flatten(0, 1)[:, None]\n",
    "        target = abs(self.weight)\n",
    "        target = target / target.sum((-1, -2), True)\n",
    "        joined_kernel = torch.cat([self.weight, target], 0)\n",
    "        reals = target.new_zeros(\n",
    "            [1, 1] + [s + p * 2 for p, s in zip(self.padding, input.shape[-2:])]\n",
    "        )\n",
    "        reals[\n",
    "            [slice(None)] * 2\n",
    "            + [slice(p, -p) if p != 0 else slice(None) for p in self.padding]\n",
    "        ].fill_(1)\n",
    "        output, power = torch.nn.functional.conv2d(\n",
    "            finput, joined_kernel, padding=self.padding\n",
    "        ).chunk(2, 1)\n",
    "        ratio = torch.div(*torch.nn.functional.conv2d(reals, joined_kernel).chunk(2, 1))\n",
    "        output = output.sub(power.mul(ratio))\n",
    "        return output.unflatten(0, input.shape[:2]).flatten(1, 2)\n",
    "    \n",
    "\n",
    "def get_model(path):\n",
    "    model = create_model(\n",
    "        \"tf_efficientnetv2_b0\",\n",
    "        in_chans=32,\n",
    "        num_classes=2,\n",
    "    )\n",
    "    state_dict = torch.load(path)\n",
    "    C, _, H, W = state_dict[\"conv_stem.2.weight\"].shape\n",
    "    print(C, _, H, W)\n",
    "    model.conv_stem = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        nn.Identity(),\n",
    "        LargeKernel_debias(1, C, [H, W], 1, [H // 2, W // 2], 1, 1, False),\n",
    "        model.conv_stem,\n",
    "    )\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model.conv_stem[:3]\n",
    "\n",
    "class LargeKernelModel(nn.Module):\n",
    "    def __init__(self, CFG):\n",
    "        super().__init__()\n",
    "        self.head = get_model('model_best.pth')\n",
    "        self.enc = create_model(\n",
    "                    CFG.model_name,\n",
    "                    pretrained=True,\n",
    "                    num_classes=CFG.num_classes,\n",
    "                    in_chans=32,\n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.head(x)\n",
    "        return self.enc(x)\n",
    "\n",
    "\n",
    "custom_model =  SRMNet(in_chn=2)\n",
    "custom_model.load_state_dict(torch.load('../EXP_40/EXP_40_01_NV_TEST_V5/EXP_40_01_NV_TEST_V5_SRG_REAL_NOISE_TO_VOID_TEST_V5_DATA_V31_9.pth'))\n",
    "custom_model.cuda();\n",
    "custom_model.eval();\n",
    "\n",
    "def custom_preprocess(x_in):\n",
    "    b, c, h, w = x_in.shape\n",
    "    x_in = x_in.reshape(b, c, 360, 288, 20).mean(-1)\n",
    "    dev = x_in.device\n",
    "    x_in = x_in.cpu().numpy()\n",
    "    for i in range(x_in.shape[0]):\n",
    "        x_in[i][0] = normalize_custom(x_in[i][0], clip = True)\n",
    "        x_in[i][1] = normalize_custom(x_in[i][1], clip = True)\n",
    "    return torch.tensor(x_in, device=dev)\n",
    "from pdb import set_trace\n",
    "@torch.no_grad()\n",
    "def inference(model, path):\n",
    "    file_path = glob.glob(os.path.join(path, \"*.hdf5\"))\n",
    "    FID, RES = [], []\n",
    "    with ProcessPoolExecutor(2) as pool:\n",
    "        for fid, input, H1, L1 in tqdm(pool.map(dataload, sorted(file_path))):\n",
    "            tta = preprocess(16, input, H1, L1)\n",
    "            tta = custom_preprocess(tta)\n",
    "            out = custom_model(tta)\n",
    "            tta = torch.concat([tta, out], -1)\n",
    "            FID += [fid]\n",
    "            RES += [model(tta).sigmoid().mean(0)]\n",
    "    return FID, torch.stack(RES, 0).cpu().float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07666fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bdfdb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 26\n",
    "    nw = 8\n",
    "    model_name = \"convnext_large_in22k\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 10\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 1\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_50_00_denoise_V5\"\n",
    "    mixup=False\n",
    "    split_voldf = Path(\"../data/SPLITS/V_20\")\n",
    "    exp_name = f\"{folder}_{model_name}_{split_voldf.stem}_{mixup}_POS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1b51ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 1 31 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7975it [2:55:40,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "model =  LargeKernelModel(CFG)\n",
    "model.load_state_dict(torch.load('../EXP_50/EXP_50_00_denoise_V5_PSD/EXP_50_00_denoise_V5_PSD_convnext_large_in22k_V_20_False_POS_0_4.pth'))\n",
    "model.eval();\n",
    "model.cuda();\n",
    "\n",
    "fid, infer = inference(model, \"../data/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27883f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict({\"id\": fid, \"target\": infer.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43254f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('TRUE_DEBIAS_DENOISE_V5_PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b852cc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result['target'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81050ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
