{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e383b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import copy\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from x_transformers import  Encoder, Decoder\n",
    "from x_transformers.autoregressive_wrapper import exists\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fastai.vision.all import BCEWithLogitsLossFlat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import os\n",
    "from timm import create_model\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab37361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 64\n",
    "    nw = 4\n",
    "    model_name = \"swin_large_patch4_window12_384\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 12\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 1\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_200_BASELINE_CASHE_V3\"\n",
    "    mixup=False\n",
    "    exp_name = f\"{folder}_{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a785480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "\n",
    "def generate_report(df):\n",
    "    val_df_eval = df.copy()\n",
    "\n",
    "    roc_100 = roc_auc_score(val_df_eval[\"target\"], val_df_eval[\"pred\"])\n",
    "\n",
    "    roc_25_50 = roc_auc_score(\n",
    "        get_snr(30, 50, val_df_eval)[\"target\"], get_snr(30, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"roc_all\": roc_100,\n",
    "        \"roc_30_50\": roc_25_50,\n",
    "\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3eed83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mask(spec, T=10):\n",
    "    cloned = spec.clone().detach()\n",
    "    len_spectro = cloned.shape[2]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):\n",
    "        t = random.randrange(0, T)\n",
    "        t_zero = random.randrange(0, len_spectro - t)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (t_zero == t_zero + t): return cloned\n",
    "\n",
    "        mask_end = random.randrange(t_zero, t_zero + t)\n",
    "        cloned[:, :,t_zero:mask_end] = 0\n",
    "    return cloned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def freq_mask(spec, F=30):\n",
    "    cloned = spec.clone().detach()\n",
    "    num_mel_channels = cloned.shape[1]\n",
    "    num_masks = np.random.randint(3, 8)\n",
    "    for i in range(0, num_masks):        \n",
    "        f = random.randrange(0, F)\n",
    "        f_zero = random.randrange(0, num_mel_channels - f)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "        mask_end = random.randrange(f_zero, f_zero + f) \n",
    "        cloned[:, f_zero:mask_end, :] = 0\n",
    "    \n",
    "    return cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e79a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pkl(filename):   \n",
    "    with open(filename, 'rb') as file1: \n",
    "        k = pickle.load(file1)\n",
    "        h1 = k[\"H1\"]['spectrogram']\n",
    "        l1 = k[\"L1\"]['spectrogram']\n",
    "        h1_timestamp = k[\"H1\"]['timestamps']\n",
    "        l1_timestamp = k[\"L1\"]['timestamps']\n",
    "        freq = k['frequency']\n",
    "        \n",
    "    data_dict = {\"sft\" : np.stack([h1[:, :4096], l1[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp}}\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1f50e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, target_size, with_conv=True):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        self.target_size = target_size\n",
    "        if self.with_conv:\n",
    "            self.conv = torch.nn.Conv2d(\n",
    "                in_channels, in_channels, kernel_size=3, stride=1, padding=1\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(x, size=self.target_size, mode=\"bilinear\")\n",
    "        if self.with_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomHybdridEmbed(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        decoder_proj_conv,\n",
    "        channel_in=2,\n",
    "        encoder_name=\"inception_v4\",\n",
    "        encoder_out_layer_num=[2],\n",
    "        transformer_original_input_size=(1, 3, 224, 224),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            encoder_name,\n",
    "            features_only=True,\n",
    "            out_indices=encoder_out_layer_num,\n",
    "            pretrained=True,\n",
    "            in_chans=channel_in,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.rand(1, channel_in, 360, 512)\n",
    "            enc_ch_num = self.encoder(x)[0].shape[1]\n",
    "            decoder_in_channels = decoder_proj_conv(\n",
    "                torch.rand(transformer_original_input_size)\n",
    "            ).shape\n",
    "\n",
    "        self.resize = Upsample(enc_ch_num, decoder_in_channels[2:])\n",
    "        self.proj = nn.Conv2d(\n",
    "            enc_ch_num, decoder_in_channels[1], kernel_size=1, stride=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[0]\n",
    "        x = self.resize(x)\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80e7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sft):\n",
    "    sft = sft * 1e22\n",
    "    sft = sft.real**2 + sft.imag**2\n",
    "    return sft\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data[0] = data[0] / data[0].mean()\n",
    "    data[1] = data[1] / data[1].mean()\n",
    "    data = data.reshape(2, 360, 128, 32).mean(-1)  # compress 4096 -> 128\n",
    "    data = data - data.mean()\n",
    "    data = data / data.std()\n",
    "    return torch.tensor(data)\n",
    "\n",
    "\n",
    "def read_h5(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        k = f[filename]\n",
    "        h1 = k[\"H1\"]\n",
    "        l1 = k[\"L1\"]\n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "        \n",
    "        data_dict = {\"sft\" : np.stack([h1_stft[:, :4096], l1_stft[:, :4096]]), \n",
    "                 \"timestamps\": {\"H1\": h1_timestamp, \n",
    "                                    \"L1\": l1_timestamp}}\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "\n",
    "    \n",
    "class ValLoader(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        img = normalize(preprocess(read_h5(r.id)['sft']))\n",
    "        return img, y\n",
    "    \n",
    "    \n",
    "class ValLoaderPickle(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        img = normalize(read_pkl(str(r.id))['sft'])\n",
    "        return img.float(), y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7faec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_rot90_cw(x):\n",
    "    return x.rot90(k=-1, dims=(2, 3))\n",
    "\n",
    "\n",
    "def torch_fliplr(x: Tensor):\n",
    "    \"\"\"\n",
    "    Flip 4D image tensor horizontally\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return x.flip(3)\n",
    "\n",
    "\n",
    "def torch_flipud(x: Tensor):\n",
    "    \"\"\"\n",
    "    Flip 4D image tensor vertically\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return x.flip(2)\n",
    "\n",
    "\n",
    "def tencrop_image2label(model: nn.Module, image: Tensor) -> Tensor:\n",
    "    \"\"\"Test-time augmentation for image classification that takes five crops out of input tensor (4 on corners and central)\n",
    "    and averages predictions from them and from their horisontally-flipped versions (10-Crop TTA).\n",
    "    :param model: Classification model\n",
    "    :param image: Input image tensor\n",
    "    :param crop_size: Crop size. Must be smaller than image size\n",
    "    :return: Averaged logits\n",
    "    \"\"\"\n",
    "\n",
    "    output = (\n",
    "        torch.sigmoid(model(image))\n",
    "        + torch.sigmoid(model(torch_flipud(image)))\n",
    "        # torch.sigmoid(model(torch_fliplr(image)))\n",
    "        # torch.sigmoid(model(torch_flipud(torch_fliplr(image))))\n",
    "    ) / 2\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7005f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tta(dl, model):\n",
    "    res = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(vld_dl):\n",
    "            out = tencrop_image2label(model, x.cuda()).detach().cpu()\n",
    "            #out = torch.sigmoid(model(x.to(\"cuda:1\"))).detach().cpu()\n",
    "            res.append(out)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b5a5a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [03:45<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V33/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "fake_noise_fns = sorted(\n",
    "    Path(\"../data/custom_data/DATA_V34/data/\").glob(\"*.pth\"),\n",
    "    key=lambda x: str(x).split(\"_\")[-2],\n",
    ")\n",
    "\n",
    "\n",
    "noise = (\n",
    "    list(Path(\"../data/custom_data/DATA_V31_V32_NOISE\").glob(\"*.pth\"))\n",
    "    + real_noise_fns[:1100]\n",
    "    + fake_noise_fns\n",
    ")\n",
    "cashe_fns = list(Path(\"cashe_dataset\").glob(\"*.pth\"))\n",
    "\n",
    "val_df = pd.read_csv(\"../data/SPLITS/V_22/val_df.csv\")\n",
    "comp_train = pd.read_csv(\"../data/train_labels.csv\")\n",
    "comp_train.columns = [\"fn\", \"target\"]\n",
    "comp_train = comp_train.query(\"target>=0\")\n",
    "comp_train[\"fn\"] = comp_train[\"fn\"].apply(lambda x: Path(\"../data/train\") / f\"{x}.hdf5\")\n",
    "comp_train.columns = [\"id\", \"target\"]\n",
    "comp_train[\"data_type\"] = \"comp_train\"\n",
    "real_noise_df = pd.DataFrame({\"id\": real_noise_fns[1100:], \"target\": 0.0, \"snr\": 0})\n",
    "real_noise_df[\"id\"] = real_noise_df[\"id\"].apply(\n",
    "    lambda x: Path(str(x).replace(\".pth\", \".h5\"))\n",
    ")\n",
    "\n",
    "val_df = pd.concat([val_df, comp_train, real_noise_df], ignore_index=True)\n",
    "val_df['id']= val_df['id'].apply(lambda x: Path(x))\n",
    "                             \n",
    "fns = [\"EXP_200_BASELINE_CASHE_V5_256/EXP_200_BASELINE_CASHE_V5_256_swin_large_patch4_window12_384_0_4.pth\"]\n",
    "\n",
    "\n",
    "custom_model = timm.create_model(\n",
    "    CFG.model_name, pretrained=True, num_classes=1\n",
    ")\n",
    "\n",
    "custom_model.patch_embed = CustomHybdridEmbed(\n",
    "    custom_model.patch_embed.proj, transformer_original_input_size=(1, 3, 384, 384)\n",
    ")\n",
    "\n",
    "\n",
    "custom_model.load_state_dict(torch.load(fns[0]))\n",
    "custom_model.cuda();\n",
    "custom_model.eval();\n",
    "sub_ds = ValLoader(val_df)\n",
    "vld_dl = DataLoader(\n",
    "    sub_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "res = predict_tta(vld_dl, custom_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3a459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "416929a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['pred'] = torch.cat(res).view(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b8ac135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9022722607133693"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_df['target'], val_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c82214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104999999999999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_df.query('data_type == \"comp_train\"')['target'], \n",
    "              val_df.query('data_type == \"comp_train\"')['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "042fbd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 125/125 [06:22<00:00,  3.06s/it]\n"
     ]
    }
   ],
   "source": [
    "fns = [\"EXP_200_BASELINE_CASHE_V5_256/EXP_200_BASELINE_CASHE_V5_256_swin_large_patch4_window12_384_0_4.pth\"]\n",
    "\n",
    "\n",
    "custom_model = timm.create_model(\n",
    "    CFG.model_name, pretrained=True, num_classes=1\n",
    ")\n",
    "\n",
    "custom_model.patch_embed = CustomHybdridEmbed(\n",
    "    custom_model.patch_embed.proj, transformer_original_input_size=(1, 3, 384, 384)\n",
    ")\n",
    "\n",
    "\n",
    "custom_model.load_state_dict(torch.load(fns[0]))\n",
    "custom_model.cuda();\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "sub['id'] = sub['id'].apply(lambda x: Path(f'../data/test/{x}.hdf5'))\n",
    "sub_ds = ValLoader(sub)\n",
    "vld_dl = DataLoader(\n",
    "    sub_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    sub_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "res = predict_tta(vld_dl, custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60af423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['target'] = torch.cat(res).view(-1).numpy()\n",
    "sub['id'] = sub['id'].apply(lambda x: x.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99c986c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('EXP_202_SWIN_128_SUB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b848b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub['target'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36732d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afe8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80698dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e9ff0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXP_200_BASELINE_CASHE_V5_256/EXP_200_BASELINE_CASHE_V5_256_swin_large_patch4_window12_384_0_4.pth']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = list(Path('EXP_200_BASELINE_CASHE_V5_256').glob(\"*.pth\"))\n",
    "fns = [\"EXP_200_BASELINE_CASHE_V5_256/EXP_200_BASELINE_CASHE_V5_256_swin_large_patch4_window12_384_0_4.pth\"]\n",
    "#\"EXP_200_BASELINE_CASHE_V5_256/EXP_200_BASELINE_CASHE_V5_256_swin_large_patch4_window12_384_0_6.pth\",\n",
    "#\"EXP_200_BASELINE_CASHE_V5_256/EXP_200_BASELINE_CASHE_V5_256_swin_large_patch4_window12_384_0_9.pth\" \n",
    "    # ]\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6832ec7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______\n",
      "EXP_200_BASELINE_CASHE_V5_256/EXP_200_BASELINE_CASHE_V5_256_swin_large_patch4_window12_384_0_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████                                                                        | 14/125 [00:23<02:46,  1.50s/it]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 13%|██████████▎                                                                      | 16/125 [00:26<02:42,  1.49s/it]/tmp/ipykernel_2654279/2093617167.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data[1] = data[1] / data[1].mean()\n",
      " 34%|███████████████████████████▊                                                     | 43/125 [01:07<02:02,  1.50s/it]/tmp/ipykernel_2654279/2093617167.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data[0] = data[0] / data[0].mean()\n",
      " 43%|██████████████████████████████████▉                                              | 54/125 [01:23<01:46,  1.50s/it]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 48%|██████████████████████████████████████▉                                          | 60/125 [01:32<01:37,  1.49s/it]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 62%|██████████████████████████████████████████████████▌                              | 78/125 [01:59<01:10,  1.49s/it]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:235: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      " 81%|████████████████████████████████████████████████████████████████▋               | 101/125 [02:34<00:35,  1.49s/it]/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:246: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 109/125 [02:45<00:23,  1.49s/it]/tmp/ipykernel_2654279/2093617167.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data[1] = data[1] / data[1].mean()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 125/125 [03:09<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "#predict train\n",
    "\n",
    "for mw in fns:\n",
    "    print('_______')\n",
    "    print(mw)\n",
    "    df_eval = pd.read_csv('../../val/v21v.csv')\n",
    "    df_eval.id = df_eval.id.apply(lambda x: Path(f\"../../val/v21_val/{x}.pickle\"))\n",
    "    df_eval.columns = ['id', 'nonstationary_H1', 'nonstationary_L1', 'artifact_H1',\n",
    "       'artifact_L1', 'freq', 'F1', 'F2', 'Alpha', 'Delta', 'h0', 'cosi', 'psi',\n",
    "       'phi', 'snr', 'target', 'path']\n",
    "    sub_ds = ValLoaderPickle(df_eval)\n",
    "    vld_dl = DataLoader(\n",
    "        sub_ds,\n",
    "        batch_size=CFG.bs,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.nw,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "\n",
    "    custom_model = timm.create_model(\n",
    "        CFG.model_name, pretrained=True, num_classes=1\n",
    "    )\n",
    "\n",
    "    custom_model.patch_embed = CustomHybdridEmbed(\n",
    "        custom_model.patch_embed.proj, transformer_original_input_size=(1, 3, 384, 384)\n",
    "    )\n",
    "\n",
    "\n",
    "    custom_model.load_state_dict(torch.load(mw))\n",
    "    custom_model.to(\"cuda:1\");\n",
    "    custom_model.eval();\n",
    "\n",
    "    res = predict_tta(vld_dl, custom_model)\n",
    "    df_eval['pred'] = torch.cat(res).view(-1).numpy()\n",
    "    break\n",
    "    df_eval['snr'] = df_eval['snr'].replace(np.nan, 0)\n",
    "    df_eval = df_eval.dropna(subset='pred')\n",
    "    dict_res = generate_report(df_eval)\n",
    "    #dict_res_400_500 = generate_report(df_eval.query('freq>400 and freq<500'))\n",
    "    #dict_res_300_400 = generate_report(df_eval.query('freq>300 and freq<400'))\n",
    "    #dict_res_200_300 = generate_report(df_eval.query('freq>200 and freq<300'))\n",
    "    #dict_res_50_200 = generate_report(df_eval.query('freq>50 and freq<200'))\n",
    "    print('___all___')\n",
    "    print(dict_res)\n",
    "    #print('freq_400_500:')\n",
    "    #print(dict_res_400_500)\n",
    "    #print('freq_300_400:')\n",
    "    #print(dict_res_300_400)\n",
    "    #print('freq_200_300:')\n",
    "    #print(dict_res_200_300)\n",
    "    #print('freq_50_200:')\n",
    "    #print(dict_res_50_200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c8cc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.id = df_eval.id.apply(lambda x: x.stem)\n",
    "df_eval.to_csv('EXP_202_SWIN_128.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.72503464674730\n",
    "# 0.7258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51276728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258627194002474"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df_eval.dropna(subset='pred')['target'], df_eval.dropna(subset='pred')['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc6aac4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval.pred.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e043a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
