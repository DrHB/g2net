{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd95f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from thop import profile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "torch.cuda.set_device(1)\n",
    "##---------- Basic Layers ----------\n",
    "def conv3x3(in_chn, out_chn, bias=True):\n",
    "    layer = nn.Conv2d(in_chn, out_chn, kernel_size=3, stride=1, padding=1, bias=bias)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, bias=False, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        padding=(kernel_size // 2),\n",
    "        bias=bias,\n",
    "        stride=stride,\n",
    "    )\n",
    "\n",
    "\n",
    "def bili_resize(factor):\n",
    "    return nn.Upsample(scale_factor=factor, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "\n",
    "##---------- Basic Blocks ----------\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, downsample):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "        self.block = SK_RDB(in_channels=in_size, growth_rate=out_size, num_layers=3)\n",
    "        if downsample:\n",
    "            self.downsample = PS_down(out_size, out_size, downscale=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if self.downsample:\n",
    "            out_down = self.downsample(out)\n",
    "            return out_down, out\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        # self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2, bias=True)\n",
    "        self.up = PS_up(in_size, out_size, upscale=2)\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, False)\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        out = torch.cat([up, bridge], dim=1)\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "##---------- Resizing Modules (Pixel(Un)Shuffle) ----------\n",
    "class PS_down(nn.Module):\n",
    "    def __init__(self, in_size, out_size, downscale):\n",
    "        super(PS_down, self).__init__()\n",
    "        self.UnPS = nn.PixelUnshuffle(downscale)\n",
    "        self.conv1 = nn.Conv2d((downscale**2) * in_size, out_size, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.UnPS(x)  # h/2, w/2, 4*c\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PS_up(nn.Module):\n",
    "    def __init__(self, in_size, out_size, upscale):\n",
    "        super(PS_up, self).__init__()\n",
    "\n",
    "        self.PS = nn.PixelShuffle(upscale)\n",
    "        self.conv1 = nn.Conv2d(in_size // (upscale**2), out_size, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.PS(x)  # h/2, w/2, 4*c\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "##---------- Selective Kernel Feature Fusion (SKFF) ----------\n",
    "class SKFF(nn.Module):\n",
    "    def __init__(self, in_channels, height=3, reduction=8, bias=False):\n",
    "        super(SKFF, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        d = max(int(in_channels / reduction), 4)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_du = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, d, 1, padding=0, bias=bias), nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self.fcs = nn.ModuleList([])\n",
    "        for i in range(self.height):\n",
    "            self.fcs.append(\n",
    "                nn.Conv2d(d, in_channels, kernel_size=1, stride=1, bias=bias)\n",
    "            )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, inp_feats):\n",
    "        batch_size, n_feats, H, W = inp_feats[1].shape\n",
    "\n",
    "        inp_feats = torch.cat(inp_feats, dim=1)\n",
    "        inp_feats = inp_feats.view(\n",
    "            batch_size, self.height, n_feats, inp_feats.shape[2], inp_feats.shape[3]\n",
    "        )\n",
    "\n",
    "        feats_U = torch.sum(inp_feats, dim=1)\n",
    "        feats_S = self.avg_pool(feats_U)\n",
    "        feats_Z = self.conv_du(feats_S)\n",
    "\n",
    "        attention_vectors = [fc(feats_Z) for fc in self.fcs]\n",
    "        attention_vectors = torch.cat(attention_vectors, dim=1)\n",
    "        attention_vectors = attention_vectors.view(\n",
    "            batch_size, self.height, n_feats, 1, 1\n",
    "        )\n",
    "\n",
    "        attention_vectors = self.softmax(attention_vectors)\n",
    "        feats_V = torch.sum(inp_feats * attention_vectors, dim=1)\n",
    "\n",
    "        return feats_V\n",
    "\n",
    "\n",
    "##---------- Dense Block ----------\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, I):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=3 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sk = SKFF(out_channels, height=2, reduction=8, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.conv(x))\n",
    "        # output = torch.cat([x, x1], 1) # -> RDB\n",
    "        output = self.sk((x, x1))\n",
    "        return output\n",
    "\n",
    "\n",
    "##---------- Selective Kernel Residual Dense Block (SK-RDB) ----------\n",
    "class SK_RDB(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(SK_RDB, self).__init__()\n",
    "        self.identity = nn.Conv2d(in_channels, growth_rate, 1, 1, 0)\n",
    "        self.layers = nn.Sequential(\n",
    "            *[DenseLayer(in_channels, in_channels, I=i) for i in range(num_layers)]\n",
    "        )\n",
    "        self.lff = nn.Conv2d(in_channels, growth_rate, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.identity(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.lff(x)\n",
    "        return res + x\n",
    "\n",
    "\n",
    "##---------- testNet ----------\n",
    "class SRMNet(nn.Module):\n",
    "    def __init__(self, in_chn=3, wf=96, depth=4):\n",
    "        super(SRMNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.down_path = nn.ModuleList()\n",
    "        self.bili_down = bili_resize(0.5)\n",
    "        self.conv_01 = nn.Conv2d(in_chn, wf, 3, 1, 1)\n",
    "\n",
    "        # encoder of UNet\n",
    "        prev_channels = 0\n",
    "        for i in range(depth):  # 0,1,2,3\n",
    "            downsample = True if (i + 1) < depth else False\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels + wf, (2**i) * wf, downsample)\n",
    "            )\n",
    "            prev_channels = (2**i) * wf\n",
    "\n",
    "        # decoder of UNet\n",
    "        self.up_path = nn.ModuleList()\n",
    "        self.skip_conv = nn.ModuleList()\n",
    "        self.conv_up = nn.ModuleList()\n",
    "        self.bottom_conv = nn.Conv2d(prev_channels, wf, 3, 1, 1)\n",
    "        self.bottom_up = bili_resize(2 ** (depth - 1))\n",
    "\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, (2**i) * wf))\n",
    "            self.skip_conv.append(nn.Conv2d((2**i) * wf, (2**i) * wf, 3, 1, 1))\n",
    "            self.conv_up.append(\n",
    "                nn.Sequential(\n",
    "                    *[nn.Conv2d((2**i) * wf, wf, 3, 1, 1), bili_resize(2**i)]\n",
    "                )\n",
    "            )\n",
    "            prev_channels = (2**i) * wf\n",
    "\n",
    "        self.final_ff = SKFF(in_channels=wf, height=depth)\n",
    "        self.last = conv3x3(prev_channels, in_chn, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        img = x\n",
    "        scale_img = img\n",
    "\n",
    "        ##### shallow conv #####\n",
    "        x1 = self.conv_01(img)\n",
    "        encs = []\n",
    "        ######## UNet ########\n",
    "        # Down-path (Encoder)\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            if i == 0:\n",
    "                x1, x1_up = down(x1)\n",
    "                encs.append(x1_up)\n",
    "            elif (i + 1) < self.depth:\n",
    "                scale_img = self.bili_down(scale_img)\n",
    "                left_bar = self.conv_01(scale_img)\n",
    "                x1 = torch.cat([x1, left_bar], dim=1)\n",
    "                x1, x1_up = down(x1)\n",
    "                encs.append(x1_up)\n",
    "            else:\n",
    "                scale_img = self.bili_down(scale_img)\n",
    "                left_bar = self.conv_01(scale_img)\n",
    "                x1 = torch.cat([x1, left_bar], dim=1)\n",
    "                x1 = down(x1)\n",
    "\n",
    "        # Up-path (Decoder)\n",
    "        ms_result = [self.bottom_up(self.bottom_conv(x1))]\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x1 = up(x1, self.skip_conv[i](encs[-i - 1]))\n",
    "            ms_result.append(self.conv_up[i](x1))\n",
    "        # Multi-scale selective feature fusion\n",
    "        msff_result = self.final_ff(ms_result)\n",
    "\n",
    "        ##### Reconstruct #####\n",
    "        out_1 = self.last(msff_result) + img\n",
    "\n",
    "        return out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca36d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "# https://arxiv.org/abs/1505.04597\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, nch_in, nch_out, nch_ker=64, norm=\"bnorm\"):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.nch_in = nch_in\n",
    "        self.nch_out = nch_out\n",
    "        self.nch_ker = nch_ker\n",
    "        self.norm = norm\n",
    "\n",
    "        if norm == \"bnorm\":\n",
    "            self.bias = False\n",
    "        else:\n",
    "            self.bias = True\n",
    "\n",
    "        \"\"\"\n",
    "        Encoder part\n",
    "        \"\"\"\n",
    "\n",
    "        self.enc1_1 = CNR2d(\n",
    "            1 * self.nch_in,\n",
    "            1 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.enc1_2 = CNR2d(\n",
    "            1 * self.nch_ker,\n",
    "            1 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.pool1 = Pooling2d(pool=2, type=\"avg\")\n",
    "\n",
    "        self.enc2_1 = CNR2d(\n",
    "            1 * self.nch_ker,\n",
    "            2 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.enc2_2 = CNR2d(\n",
    "            2 * self.nch_ker,\n",
    "            2 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.pool2 = Pooling2d(pool=2, type=\"avg\")\n",
    "\n",
    "        self.enc3_1 = CNR2d(\n",
    "            2 * self.nch_ker,\n",
    "            4 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.enc3_2 = CNR2d(\n",
    "            4 * self.nch_ker,\n",
    "            4 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.pool3 = Pooling2d(pool=2, type=\"avg\")\n",
    "\n",
    "        self.enc4_1 = CNR2d(\n",
    "            4 * self.nch_ker,\n",
    "            8 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.enc4_2 = CNR2d(\n",
    "            8 * self.nch_ker,\n",
    "            8 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.pool4 = Pooling2d(pool=2, type=\"avg\")\n",
    "\n",
    "        self.enc5_1 = CNR2d(\n",
    "            8 * self.nch_ker,\n",
    "            2 * 8 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        Decoder part\n",
    "        \"\"\"\n",
    "\n",
    "        self.dec5_1 = DECNR2d(\n",
    "            2 * 8 * self.nch_ker,\n",
    "            8 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.unpool4 = UnPooling2d(pool=2, type=\"nearest\")\n",
    "\n",
    "        self.dec4_2 = DECNR2d(\n",
    "            2 * 8 * self.nch_ker,\n",
    "            8 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.dec4_1 = DECNR2d(\n",
    "            8 * self.nch_ker,\n",
    "            4 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.unpool3 = UnPooling2d(pool=2, type=\"nearest\")\n",
    "\n",
    "        self.dec3_2 = DECNR2d(\n",
    "            2 * 4 * self.nch_ker,\n",
    "            4 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.dec3_1 = DECNR2d(\n",
    "            4 * self.nch_ker,\n",
    "            2 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.unpool2 = UnPooling2d(pool=2, type=\"nearest\")\n",
    "\n",
    "        self.dec2_2 = DECNR2d(\n",
    "            2 * 2 * self.nch_ker,\n",
    "            2 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.dec2_1 = DECNR2d(\n",
    "            2 * self.nch_ker,\n",
    "            1 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "\n",
    "        self.unpool1 = UnPooling2d(pool=2, type=\"nearest\")\n",
    "\n",
    "        self.dec1_2 = DECNR2d(\n",
    "            2 * 1 * self.nch_ker,\n",
    "            1 * self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=self.norm,\n",
    "            relu=0.0,\n",
    "            drop=[],\n",
    "        )\n",
    "        self.dec1_1 = DECNR2d(\n",
    "            1 * self.nch_ker,\n",
    "            1 * self.nch_out,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm=[],\n",
    "            relu=[],\n",
    "            drop=[],\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        Encoder part\n",
    "        \"\"\"\n",
    "\n",
    "        enc1 = self.enc1_2(self.enc1_1(x))\n",
    "        pool1 = self.pool1(enc1)\n",
    "\n",
    "        enc2 = self.enc2_2(self.enc2_1(pool1))\n",
    "        pool2 = self.pool2(enc2)\n",
    "\n",
    "        enc3 = self.enc3_2(self.enc3_1(pool2))\n",
    "        pool3 = self.pool3(enc3)\n",
    "\n",
    "        enc4 = self.enc4_2(self.enc4_1(pool3))\n",
    "        pool4 = self.pool4(enc4)\n",
    "\n",
    "        enc5 = self.enc5_1(pool4)\n",
    "\n",
    "        \"\"\"\n",
    "        Encoder part\n",
    "        \"\"\"\n",
    "        dec5 = self.dec5_1(enc5)\n",
    "\n",
    "        unpool4 = self.unpool4(dec5)\n",
    "        cat4 = torch.cat([enc4, unpool4], dim=1)\n",
    "        dec4 = self.dec4_1(self.dec4_2(cat4))\n",
    "\n",
    "        unpool3 = self.unpool3(dec4)\n",
    "        cat3 = torch.cat([enc3, unpool3], dim=1)\n",
    "        dec3 = self.dec3_1(self.dec3_2(cat3))\n",
    "\n",
    "        unpool2 = self.unpool2(dec3)\n",
    "        cat2 = torch.cat([enc2, unpool2], dim=1)\n",
    "        dec2 = self.dec2_1(self.dec2_2(cat2))\n",
    "\n",
    "        unpool1 = self.unpool1(dec2)\n",
    "        cat1 = torch.cat([enc1, unpool1], dim=1)\n",
    "        dec1 = self.dec1_1(self.dec1_2(cat1))\n",
    "\n",
    "        x = dec1\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNR2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nch_in,\n",
    "        nch_out,\n",
    "        kernel_size=4,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        norm=\"bnorm\",\n",
    "        relu=0.0,\n",
    "        drop=[],\n",
    "        bias=[],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bias == []:\n",
    "            if norm == \"bnorm\":\n",
    "                bias = False\n",
    "            else:\n",
    "                bias = True\n",
    "\n",
    "        layers = []\n",
    "        layers += [\n",
    "            Conv2d(\n",
    "                nch_in,\n",
    "                nch_out,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=bias,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if norm != []:\n",
    "            layers += [Norm2d(nch_out, norm)]\n",
    "\n",
    "        if relu != []:\n",
    "            layers += [ReLU(relu)]\n",
    "\n",
    "        if drop != []:\n",
    "            layers += [nn.Dropout2d(drop)]\n",
    "\n",
    "        self.cbr = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cbr(x)\n",
    "\n",
    "\n",
    "class DECNR2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nch_in,\n",
    "        nch_out,\n",
    "        kernel_size=4,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        output_padding=0,\n",
    "        norm=\"bnorm\",\n",
    "        relu=0.0,\n",
    "        drop=[],\n",
    "        bias=[],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bias == []:\n",
    "            if norm == \"bnorm\":\n",
    "                bias = False\n",
    "            else:\n",
    "                bias = True\n",
    "\n",
    "        layers = []\n",
    "        layers += [\n",
    "            Deconv2d(\n",
    "                nch_in,\n",
    "                nch_out,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                output_padding=output_padding,\n",
    "                bias=bias,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if norm != []:\n",
    "            layers += [Norm2d(nch_out, norm)]\n",
    "\n",
    "        if relu != []:\n",
    "            layers += [ReLU(relu)]\n",
    "\n",
    "        if drop != []:\n",
    "            layers += [nn.Dropout2d(drop)]\n",
    "\n",
    "        self.decbr = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decbr(x)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nch_in,\n",
    "        nch_out,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        padding_mode=\"reflection\",\n",
    "        norm=\"bnorm\",\n",
    "        relu=0.0,\n",
    "        drop=[],\n",
    "        bias=[],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if bias == []:\n",
    "            if norm == \"bnorm\":\n",
    "                bias = False\n",
    "            else:\n",
    "                bias = True\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # 1st conv\n",
    "        layers += [Padding(padding, padding_mode=padding_mode)]\n",
    "        layers += [\n",
    "            CNR2d(\n",
    "                nch_in,\n",
    "                nch_out,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=0,\n",
    "                norm=norm,\n",
    "                relu=relu,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if drop != []:\n",
    "            layers += [nn.Dropout2d(drop)]\n",
    "\n",
    "        # 2nd conv\n",
    "        layers += [Padding(padding, padding_mode=padding_mode)]\n",
    "        layers += [\n",
    "            CNR2d(\n",
    "                nch_in,\n",
    "                nch_out,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=0,\n",
    "                norm=norm,\n",
    "                relu=[],\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.resblk = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.resblk(x)\n",
    "\n",
    "\n",
    "class CNR1d(nn.Module):\n",
    "    def __init__(self, nch_in, nch_out, norm=\"bnorm\", relu=0.0, drop=[]):\n",
    "        super().__init__()\n",
    "\n",
    "        if norm == \"bnorm\":\n",
    "            bias = False\n",
    "        else:\n",
    "            bias = True\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(nch_in, nch_out, bias=bias)]\n",
    "\n",
    "        if norm != []:\n",
    "            layers += [Norm2d(nch_out, norm)]\n",
    "\n",
    "        if relu != []:\n",
    "            layers += [ReLU(relu)]\n",
    "\n",
    "        if drop != []:\n",
    "            layers += [nn.Dropout2d(drop)]\n",
    "\n",
    "        self.cbr = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cbr(x)\n",
    "\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, nch_in, nch_out, kernel_size=4, stride=1, padding=1, bias=True):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            nch_in,\n",
    "            nch_out,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Deconv2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nch_in,\n",
    "        nch_out,\n",
    "        kernel_size=4,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        output_padding=0,\n",
    "        bias=True,\n",
    "    ):\n",
    "        super(Deconv2d, self).__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(\n",
    "            nch_in,\n",
    "            nch_out,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            output_padding=output_padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        # layers = [nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "        #           nn.ReflectionPad2d(1),\n",
    "        #           nn.Conv2d(nch_in , nch_out, kernel_size=3, stride=1, padding=0)]\n",
    "        #\n",
    "        # self.deconv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.deconv(x)\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, nch_in, nch_out):\n",
    "        super(Linear, self).__init__()\n",
    "        self.linear = nn.Linear(nch_in, nch_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class Norm2d(nn.Module):\n",
    "    def __init__(self, nch, norm_mode):\n",
    "        super(Norm2d, self).__init__()\n",
    "        if norm_mode == \"bnorm\":\n",
    "            self.norm = nn.BatchNorm2d(nch)\n",
    "        elif norm_mode == \"inorm\":\n",
    "            self.norm = nn.InstanceNorm2d(nch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class ReLU(nn.Module):\n",
    "    def __init__(self, relu):\n",
    "        super(ReLU, self).__init__()\n",
    "        if relu > 0:\n",
    "            self.relu = nn.LeakyReLU(relu, True)\n",
    "        elif relu == 0:\n",
    "            self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class Padding(nn.Module):\n",
    "    def __init__(self, padding, padding_mode=\"zeros\", value=0):\n",
    "        super(Padding, self).__init__()\n",
    "        if padding_mode == \"reflection\":\n",
    "            self.padding = nn.ReflectionPad2d(padding)\n",
    "        elif padding_mode == \"replication\":\n",
    "            self.padding = nn.ReplicationPad2d(padding)\n",
    "        elif padding_mode == \"constant\":\n",
    "            self.padding = nn.ConstantPad2d(padding, value)\n",
    "        elif padding_mode == \"zeros\":\n",
    "            self.padding = nn.ZeroPad2d(padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.padding(x)\n",
    "\n",
    "\n",
    "class Pooling2d(nn.Module):\n",
    "    def __init__(self, nch=[], pool=2, type=\"avg\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if type == \"avg\":\n",
    "            self.pooling = nn.AvgPool2d(pool)\n",
    "        elif type == \"max\":\n",
    "            self.pooling = nn.MaxPool2d(pool)\n",
    "        elif type == \"conv\":\n",
    "            self.pooling = nn.Conv2d(nch, nch, kernel_size=pool, stride=pool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pooling(x)\n",
    "\n",
    "\n",
    "class UnPooling2d(nn.Module):\n",
    "    def __init__(self, nch=[], pool=2, type=\"nearest\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if type == \"nearest\":\n",
    "            self.unpooling = nn.Upsample(scale_factor=pool, mode=\"nearest\")\n",
    "        elif type == \"bilinear\":\n",
    "            self.unpooling = nn.Upsample(\n",
    "                scale_factor=pool, mode=\"bilinear\", align_corners=True\n",
    "            )\n",
    "        elif type == \"conv\":\n",
    "            self.unpooling = nn.ConvTranspose2d(nch, nch, kernel_size=pool, stride=pool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.unpooling(x)\n",
    "\n",
    "\n",
    "class Concat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        diffy = x2.size()[2] - x1.size()[2]\n",
    "        diffx = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffx // 2, diffx - diffx // 2, diffy // 2, diffy - diffy // 2])\n",
    "\n",
    "        return torch.cat([x2, x1], dim=1)\n",
    "\n",
    "\n",
    "class TV1dLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TV1dLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # loss = torch.mean(torch.abs(input[:, :, :, :-1] - input[:, :, :, 1:])) + \\\n",
    "        #        torch.mean(torch.abs(input[:, :, :-1, :] - input[:, :, 1:, :]))\n",
    "        loss = torch.mean(torch.abs(input[:, :-1] - input[:, 1:]))\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class TV2dLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TV2dLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        loss = torch.mean(\n",
    "            torch.abs(input[:, :, :, :-1] - input[:, :, :, 1:])\n",
    "        ) + torch.mean(torch.abs(input[:, :, :-1, :] - input[:, :, 1:, :]))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SSIM2dLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SSIM2dLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, targer):\n",
    "        loss = 0\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
    "# https://arxiv.org/abs/1609.04802\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, nch_in, nch_out, nch_ker=64, norm=\"bnorm\", nblk=16):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.nch_in = nch_in\n",
    "        self.nch_out = nch_out\n",
    "        self.nch_ker = nch_ker\n",
    "        self.norm = norm\n",
    "        self.nblk = nblk\n",
    "\n",
    "        if norm == \"bnorm\":\n",
    "            self.bias = False\n",
    "        else:\n",
    "            self.bias = True\n",
    "\n",
    "        self.enc1 = CNR2d(\n",
    "            self.nch_in,\n",
    "            self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            norm=[],\n",
    "            relu=0.0,\n",
    "        )\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.nblk):\n",
    "            res += [\n",
    "                ResBlock(\n",
    "                    self.nch_ker,\n",
    "                    self.nch_ker,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                    norm=self.norm,\n",
    "                    relu=0.0,\n",
    "                    padding_mode=\"reflection\",\n",
    "                )\n",
    "            ]\n",
    "        self.res = nn.Sequential(*res)\n",
    "\n",
    "        self.dec1 = CNR2d(\n",
    "            self.nch_ker,\n",
    "            self.nch_ker,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            norm=norm,\n",
    "            relu=[],\n",
    "        )\n",
    "\n",
    "        self.conv1 = Conv2d(\n",
    "            self.nch_ker, self.nch_out, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x0 = x\n",
    "\n",
    "        x = self.res(x)\n",
    "\n",
    "        x = self.dec1(x)\n",
    "        x = x + x0\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b905e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda, ToPILImage, CenterCrop, Resize\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from einops import repeat\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from fastai.vision.all import L, unsqueeze\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import (\n",
    "    LabelSmoothingCrossEntropy,\n",
    "    BinaryCrossEntropy,\n",
    "    SoftTargetCrossEntropy,\n",
    ")\n",
    "\n",
    "from einops import rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421402e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(x, pmin=3, pmax=97, axis=None, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    \"\"\"Percentile-based image normalization.\"\"\"\n",
    "\n",
    "    mi = np.percentile(x,pmin,axis=axis,keepdims=True)\n",
    "    ma = np.percentile(x,pmax,axis=axis,keepdims=True)\n",
    "    return normalize_mi_ma(x, mi, ma, clip=clip, eps=eps, dtype=dtype)\n",
    "\n",
    "\n",
    "def normalize_mi_ma(x, mi, ma, clip=False, eps=1e-20, dtype=np.float32):\n",
    "    if dtype is not None:\n",
    "        x   = x.astype(dtype,copy=False)\n",
    "        mi  = dtype(mi) if np.isscalar(mi) else mi.astype(dtype,copy=False)\n",
    "        ma  = dtype(ma) if np.isscalar(ma) else ma.astype(dtype,copy=False)\n",
    "        eps = dtype(eps)\n",
    "\n",
    "    try:\n",
    "        import numexpr\n",
    "        x = numexpr.evaluate(\"(x - mi) / ( ma - mi + eps )\")\n",
    "    except ImportError:\n",
    "        x =                   (x - mi) / ( ma - mi + eps )\n",
    "\n",
    "    if clip:\n",
    "        x = np.clip(x,0,1)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be61764",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class SaveModel:\n",
    "    def __init__(self, folder, exp_name, best=np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score < self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelMetric:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelEpoch:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder)\n",
    "        self.exp_name = exp_name\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        self.best = score\n",
    "        print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "        torch.save(model.state_dict(), f\"{self.folder/self.exp_name}_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def custom_auc_score(p, gt):\n",
    "    return roc_auc_score(gt.cpu().numpy(), F.softmax(p).cpu().numpy()[:, 1])\n",
    "\n",
    "\n",
    "def fit_mixup(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    loss_fn,\n",
    "    opt,\n",
    "    folder=\"models\",\n",
    "    exp_name=\"exp_00\",\n",
    "    device=None,\n",
    "    sched=None,\n",
    "    save_md=SaveModelEpoch,\n",
    "):\n",
    "    if device is None:\n",
    "        device = (\n",
    "            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    loss_fn_trn = loss_fn\n",
    "    mb = master_bar(range(epochs))\n",
    "    mb.write([\"epoch\", \n",
    "              \"train_loss\",\n",
    "              \"valid_loss\"], table=True)\n",
    "    model.to(device)  # we have to put our model on gpu\n",
    "    scaler = torch.cuda.amp.GradScaler()  # this for half precision training\n",
    "    save_md = save_md(folder, exp_name)\n",
    "\n",
    "    for i in mb:  # iterating  epoch\n",
    "        trn_loss, val_loss = 0.0, 0.0\n",
    "        trn_n, val_n = len(train_dl.dataset), len(valid_dl.dataset)\n",
    "        model.train()  # set model for training\n",
    "        for (xb, yb, msk) in progress_bar(train_dl, parent=mb):\n",
    "            #lbl, input, mask\n",
    "            xb, yb, msk, = xb.to(device), yb.to(device), msk.to(device)  # putting batches to device\n",
    "            with torch.cuda.amp.autocast():  # half precision\n",
    "                out = model(yb)  # forward pass\n",
    "                loss = loss_fn_trn(out, msk, xb)  # calulation loss\n",
    "            trn_loss += loss.item()\n",
    "\n",
    "            scaler.scale(loss).backward()  # backward\n",
    "            scaler.step(opt)  # optimzers step\n",
    "            scaler.update()  # for half precision\n",
    "            opt.zero_grad()  # zeroing optimizer\n",
    "            if sched is not None:\n",
    "                sched.step()  # scuedular step\n",
    "\n",
    "        trn_loss /= mb.child.total\n",
    "\n",
    "        # putting model in eval mode\n",
    "        model.eval()\n",
    "        # after epooch is done we can run a validation dataloder and see how are doing\n",
    "        with torch.no_grad():\n",
    "            for (xb, yb, msk) in progress_bar(valid_dl, parent=mb):\n",
    "                xb, yb, msk, = xb.to(device), yb.to(device), msk.to(device)\n",
    "                out = model(yb)\n",
    "                loss = loss_fn(out, msk, xb)\n",
    "                val_loss += loss.item()\n",
    "        # calculating metric\n",
    "        # saving model if necessary\n",
    "        val_loss /= mb.child.total\n",
    "        save_md(val_loss, model, i)\n",
    "\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"trn_loss\": [trn_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "            }\n",
    "        ).to_csv(f\"{folder}/{exp_name}_{i}.csv\", index=False)\n",
    "        mb.write(\n",
    "            [\n",
    "                i,\n",
    "                f\"{trn_loss:.6f}\",\n",
    "                f\"{val_loss:.6f}\",\n",
    "            ],\n",
    "            table=True,\n",
    "        )\n",
    "    print(\"Training done\")\n",
    "    # loading the best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89bdb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = dataset['train']\n",
    "#image = train[0]['image']\n",
    "#x_start = transform(image).unsqueeze(0)\n",
    "#noise_level = torch.randint(1, 80, (1,))\n",
    "#x_noisy = get_noisy_image(x_start, noise_level)\n",
    "#noise_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb6371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import h5py\n",
    "\n",
    "\n",
    "class CharbonnierLoss(nn.Module):\n",
    "    \"\"\"Charbonnier Loss (L1)\"\"\"\n",
    "\n",
    "    def __init__(self, eps=1e-3):\n",
    "        super(CharbonnierLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        diff = x - y\n",
    "        # loss = torch.sum(torch.sqrt(diff * diff + self.eps))\n",
    "        loss = torch.mean(torch.sqrt((diff * diff) + (self.eps * self.eps)))\n",
    "        return loss\n",
    "\n",
    "\n",
    "def get_mask(input):\n",
    "    ratio = 0.9\n",
    "    size_window = (5, 5)\n",
    "    size_data = (360, 128, 2)\n",
    "    num_sample = int(size_data[0] * size_data[1] * (1 - ratio))\n",
    "    mask = np.ones(size_data)\n",
    "    output = input\n",
    "    for ich in range(size_data[2]):\n",
    "        idy_msk = np.random.randint(0, size_data[0], num_sample)\n",
    "        idx_msk = np.random.randint(0, size_data[1], num_sample)\n",
    "\n",
    "        idy_neigh = np.random.randint(\n",
    "            -size_window[0] // 2 + size_window[0] % 2,\n",
    "            size_window[0] // 2 + size_window[0] % 2,\n",
    "            num_sample,\n",
    "        )\n",
    "        idx_neigh = np.random.randint(\n",
    "            -size_window[1] // 2 + size_window[1] % 2,\n",
    "            size_window[1] // 2 + size_window[1] % 2,\n",
    "            num_sample,\n",
    "        )\n",
    "\n",
    "        idy_msk_neigh = idy_msk + idy_neigh\n",
    "        idx_msk_neigh = idx_msk + idx_neigh\n",
    "\n",
    "        idy_msk_neigh = (\n",
    "            idy_msk_neigh\n",
    "            + (idy_msk_neigh < 0) * size_data[0]\n",
    "            - (idy_msk_neigh >= size_data[0]) * size_data[0]\n",
    "        )\n",
    "        idx_msk_neigh = (\n",
    "            idx_msk_neigh\n",
    "            + (idx_msk_neigh < 0) * size_data[1]\n",
    "            - (idx_msk_neigh >= size_data[1]) * size_data[1]\n",
    "        )\n",
    "\n",
    "        id_msk = (idy_msk, idx_msk, ich)\n",
    "        id_msk_neigh = (idy_msk_neigh, idx_msk_neigh, ich)\n",
    "\n",
    "        output[id_msk] = input[id_msk_neigh]\n",
    "        mask[id_msk] = 0.0\n",
    "\n",
    "    return output, mask\n",
    "\n",
    "\n",
    "class DataV0:\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        filename=r.id\n",
    "        file_id = Path(r.id).stem\n",
    "        img = np.empty((2, 360, 128), dtype=np.float32)\n",
    "\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            g = f[file_id]\n",
    "\n",
    "            for ch, s in enumerate(['H1', 'L1']):\n",
    "                a = g[s]['SFTs'][:, :4096] * 1e22  # Fourier coefficient complex64\n",
    "                p = a.real**2 + a.imag**2  # power\n",
    "                p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n",
    "                img[ch] = normalize(p, clip=True)\n",
    "\n",
    "        if self.tfms:\n",
    "            if np.random.rand() <= 0.5:  # horizontal flip\n",
    "                img = np.flip(img, axis=1).copy()\n",
    "            if np.random.rand() <= 0.5:  # vertical flip\n",
    "                img = np.flip(img, axis=2).copy()\n",
    "            if np.random.rand() <= 0.5:  # vertical shift\n",
    "                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "\n",
    "        label = rearrange(img, \"c h w -> h w c\")\n",
    "        input, mask = get_mask(copy.deepcopy(label))\n",
    "        return rearrange(label, \"h w c -> c h w\"), rearrange(input, \"h w c -> c h w\"),  rearrange(mask, \"h w c -> c h w\")\n",
    "\n",
    "\n",
    "def customplot(x, y, k=None):\n",
    "    if k:\n",
    "        plt.imshow(torch.concat([x.mean(0), y.mean(0), k.mean(0)], 1))\n",
    "    else:\n",
    "        plt.imshow(torch.concat([x.mean(0), y.mean(0)], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82291f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 32\n",
    "    nw = 4\n",
    "    model_name = \"SRG_REAL_NOISE_TO_VOID_TEST_V3\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 10\n",
    "    warmup_pct = 0.1\n",
    "    num_classes = 2\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_40_01_NV_TEST_V3\"\n",
    "    split_voldf = Path(\"../data/custom_data/DATA_V31/\")\n",
    "    exp_name = f\"{folder}_{model_name}_{split_voldf.stem}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97b1b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit.columns = ['fn', 'target']\n",
    "submit['fn'] = submit['fn'].apply(lambda x: Path('../data/test')/f'{x}.hdf5')\n",
    "submit.columns = ['id', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "409fab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dforig = pd.read_csv('../data/train_labels.csv')\n",
    "dforig.columns = ['fn', 'target']\n",
    "dforig = dforig.query('target>=0').reset_index(drop=True)\n",
    "dforig['fn'] = dforig['fn'].apply(lambda x: Path('../data/train')/f'{x}.hdf5')\n",
    "dforig.columns = ['id', 'target']\n",
    "trn_df = pd.read_csv(CFG.split_voldf/'train_meta.csv')\n",
    "trn_df_2 = pd.read_csv(Path(\"../data/custom_data/DATA_V32\")/'train_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.concat(\n",
    "    [trn_df.query(\"snr<70\"), trn_df_2.query(\"snr<70\"), dforig, submit],\n",
    "    ignore_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = DataV0(trn_df, True)\n",
    "vld_ds = DataV0(submit[:1000])\n",
    "len(trn_ds), len(vld_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e832bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = trn_ds[789]\n",
    "plt.imshow(img[1].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40faa03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, loss_func):\n",
    "        super().__init__()\n",
    "        self.loss_func = loss_func\n",
    "    \n",
    "    def forward(self, output, mask, label):\n",
    "        return self.loss_func(output * (1 - mask), label * (1 - mask))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579531f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    img, y, _= trn_ds[np.random.randint(0, len(trn_ds))]\n",
    "    customplot(torch.tensor(img), torch.tensor(y))\n",
    "    plt.pause(0.1)\n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    #plt.title('Spectrogram')\n",
    "    #plt.xlabel('time')\n",
    "    #plt.ylabel('frequency')\n",
    "    #plt.imshow(img.mean(0))\n",
    "    ##plt.imshow(np.concatenate([img[0], img[1]], 1))  # zooming in for dataset[10]\n",
    "    #plt.colorbar()\n",
    "    #plt.show()\n",
    "    #print(y)\n",
    "    #plt.pause(0.1)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a39a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb7fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=True,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "custom_model = SRMNet(in_chn=2)\n",
    "custom_model.load_state_dict(torch.load('EXP_40_01_NV_TEST_V2/EXP_40_01_NV_TEST_V2_SRG_REAL_NOISE_TO_VOID_TEST_V2_DATA_V31_29.pth'))\n",
    "opt = torch.optim.AdamW(custom_model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "loss_func = CustomLoss(nn.L1Loss())\n",
    "warmup_steps = int(len(trn_dl) * int(CFG.warmup_pct * CFG.epoch))\n",
    "total_steps = int(len(trn_dl) * CFG.epoch)\n",
    "sched = get_linear_schedule_with_warmup(\n",
    "    opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "fit_mixup(\n",
    "    epochs=CFG.epoch,\n",
    "    model=custom_model,\n",
    "    train_dl=trn_dl,\n",
    "    valid_dl=vld_dl,\n",
    "    loss_fn=loss_func,\n",
    "    opt=opt,\n",
    "    folder=CFG.folder,\n",
    "    exp_name=f\"{CFG.exp_name}\",\n",
    "    device=\"cuda:1\",\n",
    "    sched=sched,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cadcf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model =  SRMNet(in_chn=2)\n",
    "custom_model.load_state_dict(torch.load('EXP_40_01_NV_TEST_V3/EXP_40_01_NV_TEST_V3_SRG_REAL_NOISE_TO_VOID_TEST_V3_DATA_V31_9.pth'))\n",
    "custom_model.cuda();\n",
    "custom_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_model =  SRMNet(in_chn=2)\n",
    "#custom_model.load_state_dict(torch.load('EXP_40_01_NV_TEST/EXP_40_01_NV_TEST_SRG_REAL_NOISE_TO_VOID_TEST_V_19_15.pth'))\n",
    "#custom_model.cuda();\n",
    "#custom_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d057ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_df = pd.read_csv(CFG.split_voldf/'train_meta.csv')\n",
    "#trn_df = trn_df.query('snr>40 and snr < 50')\n",
    "mask = trn_df['id'].apply(lambda x: Path(x).parent.parent.stem) == 'DATA_V32'\n",
    "trn_ds = DataV0(trn_df.loc[mask], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57edba90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(30):\n",
    "    #idx = np.random.randint(0, len(trn_ds))\n",
    "    print(trn_ds.df.iloc[k].snr)\n",
    "    img = torch.tensor(trn_ds[k][0]).unsqueeze(0)\n",
    "    for i in range(1):\n",
    "        with torch.no_grad():\n",
    "            out = custom_model(img.cuda()).detach().cpu()\n",
    "            customplot(img[0], out[0])\n",
    "            plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model =  SRMNet(in_chn=2)\n",
    "custom_model.load_state_dict(torch.load('EXP_40_01_NV_TEST_V3/EXP_40_01_NV_TEST_V3_SRG_REAL_NOISE_TO_VOID_TEST_V3_DATA_V31_9.pth'))\n",
    "custom_model.cuda();\n",
    "custom_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 64\n",
    "    nw = 4\n",
    "    model_name = \"convnext_xlarge_384_in22ft1k\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 30\n",
    "    warmup_pct = 0.01\n",
    "    num_classes = 2\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_40_00_PSD\"\n",
    "    mixup=False\n",
    "    split_voldf = Path(\"../data/SPLITS/V_20\")\n",
    "    exp_name = f\"{folder}_{model_name}_{split_voldf.stem}_{mixup}_POS\"\n",
    "dforig = pd.read_csv('../data/train_labels.csv')\n",
    "dforig.columns = ['fn', 'target']\n",
    "dforig['fn'] = dforig['fn'].apply(lambda x: Path('../data/train')/f'{x}.hdf5')\n",
    "dforig.columns = ['id', 'target']\n",
    "dforig = dforig[dforig.target >= 0].reset_index(drop=True)\n",
    "\n",
    "\n",
    "trn_df = pd.read_csv(CFG.split_voldf/'trn_df.csv')\n",
    "trn_df['id'] = trn_df['id'].apply(lambda x: x.replace('.pth', '.h5'))\n",
    "\n",
    "val_df = pd.read_csv(CFG.split_voldf/'val_df.csv')\n",
    "val_df['id'] = val_df['id'].apply(lambda x: x.replace('.pth', '.h5'))\n",
    "\n",
    "\n",
    "\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit.columns = ['fn', 'target']\n",
    "submit['fn'] = submit['fn'].apply(lambda x: Path('../data/test')/f'{x}.hdf5')\n",
    "submit.columns = ['id', 'target']\n",
    "\n",
    "trn_df = pd.concat([dforig, trn_df, submit]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfaa625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DataV0:\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, tfms=False):\n",
    "        self.df = df\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        filename=r.id\n",
    "        file_id = Path(r.id).stem\n",
    "        img = np.empty((2, 360, 128), dtype=np.float32)\n",
    "\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            g = f[file_id]\n",
    "\n",
    "            for ch, s in enumerate(['H1', 'L1']):\n",
    "                a = g[s]['SFTs'][:, :4096] * 1e22  # Fourier coefficient complex64\n",
    "                p = a.real**2 + a.imag**2  # power\n",
    "                p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n",
    "                img[ch] = normalize(p, clip=True)\n",
    "\n",
    "        if self.tfms:\n",
    "            if np.random.rand() <= 0.5:  # horizontal flip\n",
    "                img = np.flip(img, axis=1).copy()\n",
    "            if np.random.rand() <= 0.5:  # vertical flip\n",
    "                img = np.flip(img, axis=2).copy()\n",
    "            if np.random.rand() <= 0.5:  # vertical shift\n",
    "                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "\n",
    "        label = rearrange(img, \"c h w -> h w c\")\n",
    "        input, mask = get_mask(copy.deepcopy(label))\n",
    "        return rearrange(label, \"h w c -> c h w\"), str(filename).replace('.h5', '_denoise.pth')\n",
    "    \n",
    "vld_ds = DataV0(val_df)\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "custom_model =  SRMNet(in_chn=2)\n",
    "custom_model.load_state_dict(torch.load('EXP_40_01_NV_TEST_V3/EXP_40_01_NV_TEST_V3_SRG_REAL_NOISE_TO_VOID_TEST_V3_DATA_V31_9.pth'))\n",
    "custom_model.cuda();\n",
    "custom_model.eval();\n",
    "with torch.no_grad():\n",
    "    for x, fns in tqdm(vld_dl):\n",
    "        out = custom_model(x.cuda()).cpu()\n",
    "        for den, fn in zip(out, fns):\n",
    "            torch.save({\"s_p_n\": den}, fn)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825238eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vld_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab8aa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#maybe = ['b7a339801']\n",
    "#submit = pd.read_csv('../data/sample_submission.csv')\n",
    "#submit = submit.set_index('id').loc[maybe].reset_index()\n",
    "#submit.columns = ['fn', 'target']\n",
    "#submit['fn'] = submit['fn'].apply(lambda x: Path('../data/test')/f'{x}.hdf5')\n",
    "#submit.columns = ['id', 'target']\n",
    "\n",
    "#df_test = pd.read_csv('../data/SUBS/submission_debias.csv')\n",
    "#pos = ['008b91c55',\n",
    "# '00bce5685',\n",
    "# '00f226552',\n",
    "# '012992291',\n",
    "# '015bf0213',\n",
    "# '017a7c7f1',\n",
    "# '0195324d2',\n",
    "# '01cb9865c']\n",
    "#df_test = df_test.set_index('id').drop(pos).reset_index()\n",
    "#df_test['id'] = df_test['id'].apply(lambda x: Path(\"../data/test/\")/f\"{x}.hdf5\")\n",
    "#\n",
    "#trn_ds = DataV0(df_test, False)\n",
    "#for k in range(10):\n",
    "#    #idx = np.random.randint(0, len(trn_ds))\n",
    "#    print(df_test.iloc[k].id, df_test.iloc[k].target)\n",
    "#    img = torch.tensor(trn_ds[k][0]).unsqueeze(0)\n",
    "#    for i in range(1):\n",
    "#        with torch.no_grad():\n",
    "#            out = custom_model(img.cuda()).detach().cpu()\n",
    "#            customplot(img[0], out[0])\n",
    "#            plt.pause(0.1)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[0].mean(0), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc84bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.tensor(vld_ds[0])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c5bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "class DataV0Valid():\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.freq_tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        filename=r.id\n",
    "        file_id = Path(r.id).stem\n",
    "        img = np.empty((2, 360, 128), dtype=np.float32)\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            g = f[file_id]\n",
    "\n",
    "            for ch, s in enumerate(['H1', 'L1']):\n",
    "                a = g[s]['SFTs'][:, :4096] * 1e22  # Fourier coefficient complex64\n",
    "                p = a.real**2 + a.imag**2  # power\n",
    "                p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n",
    "                img[ch] = normalize(p, clip=True)\n",
    "        if self.freq_tfms:\n",
    "            if np.random.rand() <= 0.5: # horizonta\n",
    "                img = np.flip(img, axis=1).copy()\n",
    "            if np.random.rand() <= 0.5: # vertical \n",
    "                img = np.flip(img, axis=2).copy()\n",
    "            if np.random.rand() <= 0.5: # vertical \n",
    "                img = np.roll(img, np.random.randint(low=0, high=img.shape[1]), axis=1)\n",
    "        img = torch.tensor(img)  \n",
    "        return img\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e639418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRMNet(nn.Module):\n",
    "    def __init__(self, in_chn=3, wf=96, depth=4):\n",
    "        super(SRMNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.down_path = nn.ModuleList()\n",
    "        self.bili_down = bili_resize(0.5)\n",
    "        self.conv_01 = nn.Conv2d(in_chn, wf, 3, 1, 1)\n",
    "\n",
    "        # encoder of UNet\n",
    "        prev_channels = 0\n",
    "        for i in range(depth):  # 0,1,2,3\n",
    "            downsample = True if (i + 1) < depth else False\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels + wf, (2**i) * wf, downsample)\n",
    "            )\n",
    "            prev_channels = (2**i) * wf\n",
    "\n",
    "        # decoder of UNet\n",
    "        self.up_path = nn.ModuleList()\n",
    "        self.skip_conv = nn.ModuleList()\n",
    "        self.conv_up = nn.ModuleList()\n",
    "        self.bottom_conv = nn.Conv2d(prev_channels, wf, 3, 1, 1)\n",
    "        self.bottom_up = bili_resize(2 ** (depth - 1))\n",
    "\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, (2**i) * wf))\n",
    "            self.skip_conv.append(nn.Conv2d((2**i) * wf, (2**i) * wf, 3, 1, 1))\n",
    "            self.conv_up.append(\n",
    "                nn.Sequential(\n",
    "                    *[nn.Conv2d((2**i) * wf, wf, 3, 1, 1), bili_resize(2**i)]\n",
    "                )\n",
    "            )\n",
    "            prev_channels = (2**i) * wf\n",
    "\n",
    "        self.final_ff = SKFF(in_channels=wf, height=depth)\n",
    "        self.last = conv3x3(prev_channels, in_chn, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        img = x\n",
    "        scale_img = img\n",
    "\n",
    "        ##### shallow conv #####\n",
    "        x1 = self.conv_01(img)\n",
    "        encs = []\n",
    "        ######## UNet ########\n",
    "        # Down-path (Encoder)\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            if i == 0:\n",
    "                x1, x1_up = down(x1)\n",
    "                encs.append(x1_up)\n",
    "            elif (i + 1) < self.depth:\n",
    "                scale_img = self.bili_down(scale_img)\n",
    "                left_bar = self.conv_01(scale_img)\n",
    "                x1 = torch.cat([x1, left_bar], dim=1)\n",
    "                x1, x1_up = down(x1)\n",
    "                encs.append(x1_up)\n",
    "            else:\n",
    "                scale_img = self.bili_down(scale_img)\n",
    "                left_bar = self.conv_01(scale_img)\n",
    "                x1 = torch.cat([x1, left_bar], dim=1)\n",
    "                x1 = down(x1)\n",
    "        from pdb import set_trace\n",
    "        set_trace()\n",
    "        # Up-path (Decoder)\n",
    "        ms_result = [self.bottom_up(self.bottom_conv(x1))]\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x1 = up(x1, self.skip_conv[i](encs[-i - 1]))\n",
    "            ms_result.append(self.conv_up[i](x1))\n",
    "        # Multi-scale selective feature fusion\n",
    "        msff_result = self.final_ff(ms_result)\n",
    "\n",
    "        ##### Reconstruct #####\n",
    "        out_1 = self.last(msff_result) + img\n",
    "\n",
    "        return out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53dd1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "#submit = submit.set_index('id').drop(pos + maybe + maybe_Extreme + no).reset_index()\n",
    "submit.columns = [\"fn\", \"target\"]\n",
    "submit[\"fn\"] = submit[\"fn\"].apply(lambda x: Path(\"../data/test\") / f\"{x}.hdf5\")\n",
    "submit.columns = [\"id\", \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d844e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model =  SRMNet(in_chn=2)\n",
    "custom_model.load_state_dict(torch.load('EXP_40_01_NV_TEST_V3/EXP_40_01_NV_TEST_V3_SRG_REAL_NOISE_TO_VOID_TEST_V3_DATA_V31_9.pth'))\n",
    "custom_model.cuda();\n",
    "custom_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5b73b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_ds = DataV0Valid(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1263e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7975"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tst_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e35c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_3340412/2602493982.py\u001b[0m(65)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m        \u001b[0;31m# Up-path (Decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m        \u001b[0mms_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m            \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> x1.shape\n",
      "torch.Size([1, 768, 45, 16])\n",
      "ipdb> len(encs)\n",
      "3\n",
      "ipdb> encs[0].shape\n",
      "torch.Size([1, 96, 360, 128])\n",
      "ipdb> encs[2].shape\n",
      "torch.Size([1, 384, 90, 32])\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_3340412/2602493982.py\u001b[0m(66)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     64 \u001b[0;31m        \u001b[0;31m# Up-path (Decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m        \u001b[0mms_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m            \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            \u001b[0mms_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_up\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> ms_result.shape\n",
      "*** AttributeError: 'list' object has no attribute 'shape'\n",
      "ipdb> len(ms_result)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for k in range(6000, 7000):\n",
    "    img = tst_ds[k].unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        #print(tst_ds.df.iloc[k].id.stem, tst_ds.df.iloc[k].target)\n",
    "        out = custom_model(img.cuda()).detach().cpu()\n",
    "        #customplot(img[0], out[0])\n",
    "        orig = torch.concat([img[0].mean(0), img[0][0], img[0][1]], axis=-1)\n",
    "        pred = torch.concat([out[0].mean(0), out[0][0], out[0][1]], axis=-1)\n",
    "        plt.imshow(orig, vmin=0, vmax=1)\n",
    "        plt.pause(0.1)\n",
    "        plt.imshow(pred, vmin=0, vmax=1)\n",
    "        plt.pause(0.1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f8e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38860b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
