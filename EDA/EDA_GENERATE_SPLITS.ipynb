{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b80b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "def scale_data(data):\n",
    "     return (data-np.min(data))/(np.max(data)-np.min(data))\n",
    "    \n",
    "df_test = pd.read_csv('../data/sample_submission.csv')\n",
    "df_test['id'] = df_test['id'].apply(lambda x: Path(\"../data/test/\")/f\"{x}.hdf5\")\n",
    "def read_file(filename):\n",
    "    file_id = Path(filename).stem\n",
    "    img = np.empty((2, 360, 128), dtype=np.float32)\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        g = f[file_id]\n",
    "\n",
    "        for ch, s in enumerate([\"H1\", \"L1\"]):\n",
    "            a = g[s][\"SFTs\"][:, :4096] * 1e22  # Fourier coefficient complex64\n",
    "            p = a.real**2 + a.imag**2  # power\n",
    "            p /= np.mean(p)  # normalize\n",
    "            p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n",
    "            img[ch] = p\n",
    "    return img\n",
    "\n",
    "\n",
    "class DatasetVisualizer():\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        filename=r.id\n",
    "        file_id = Path(r.id).stem\n",
    "        img = np.empty((2, 360, 128), dtype=np.float32)\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            g = f[file_id]\n",
    "\n",
    "            for ch, s in enumerate(['H1', 'L1']):\n",
    "                a = g[s]['SFTs'][:, :4096] * 1e22  # Fourier coefficient complex64\n",
    "\n",
    "                p = a.real**2 + a.imag**2  # power\n",
    "                p /= np.mean(p)  # normalize\n",
    "                p = np.mean(p.reshape(360, 128, 32), axis=2)  # compress 4096 -> 128\n",
    "\n",
    "                img[ch] = p\n",
    "\n",
    "        return img, y.astype('int')\n",
    "    \n",
    "def plot_sft(img):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(5, 5))\n",
    "    axes[0].imshow(img[0])\n",
    "    axes[0].set_title('Detector=H1')\n",
    "    axes[1].imshow(img[0])\n",
    "    axes[1].set_title('Detector=L1')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a16cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_dataset(version=\"DATA_V10\"):\n",
    "    df = (\n",
    "        pd.read_csv(f\"../data/custom_data/{version}/train.csv\")\n",
    "\n",
    "    )\n",
    "\n",
    "    fns = list(Path(f\"../data/custom_data/{version}/\").glob(\"*/*.csv\"))\n",
    "    meta = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(i)\n",
    "            for i in fns\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    meta['id_csv'] = fns\n",
    "    meta['uniq_id'] = meta['id_csv'].apply(lambda x: x.stem)\n",
    "    df['uniq_id'] = df['id'].apply(lambda x: Path(x).stem)\n",
    "    return pd.merge(df, meta, on='uniq_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9adfcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'V_10'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#df_10 = get_custom_dataset()\n",
    "#df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "#df_12 = get_custom_dataset(\"DATA_V12\")\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#    pd.concat([df_10, df_11, df_12], ignore_index=True)\n",
    "#    .sample(frac=1.0)\n",
    "#    .reset_index(drop=True)\n",
    "#)\n",
    "#\n",
    "#index_100 = list(df_comb.query(\"snr>60 & snr<100\").sample(n=500).index)\n",
    "#index_60 =  list(df_comb.query(\"snr>50 & snr<60\").sample(n=500).index)\n",
    "#index_50 =  list(df_comb.query(\"snr>40 & snr<50\").sample(n=500).index)\n",
    "#index_40 =  list(df_comb.query(\"snr>0 & snr<40\").sample(n=1500).index)\n",
    "#index_neg = list(df_comb.query(\"snr==0\").sample(n=4000).index)\n",
    "#\n",
    "#val_idx = index_100 + index_60 + index_50 + index_40 + index_neg\n",
    "#val_df = df_comb.iloc[val_idx].sample(frac=1.).reset_index(drop=True)\n",
    "#trn_df = df_comb.loc[~df_comb.index.isin(val_idx)].sample(frac=1.).reset_index(drop=True)\n",
    "#val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "#trn_df.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a80d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'V_11'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#df_10 = get_custom_dataset()\n",
    "#df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "#df_12 = get_custom_dataset(\"DATA_V12\")\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#    pd.concat([df_10, df_11, df_12], ignore_index=True)\n",
    "#    .sample(frac=1.0)\n",
    "#    .reset_index(drop=True)\n",
    "#)\n",
    "#\n",
    "#index_40 =  list(df_comb.query(\"snr>0 & snr<45\").sample(n=2200).index)\n",
    "#index_neg = list(df_comb.query(\"snr==0\").sample(n=5000).index)\n",
    "#val_idx = index_40 + index_neg\n",
    "#val_df = df_comb.iloc[val_idx].sample(frac=1.).reset_index(drop=True)\n",
    "#trn_df = df_comb.loc[~df_comb.index.isin(val_idx)].sample(frac=1.).reset_index(drop=True)\n",
    "#val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "#trn_df.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c36c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'V_12'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#df_10 = get_custom_dataset()\n",
    "#df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "#df_12 = get_custom_dataset(\"DATA_V12\")\n",
    "#df_13 = get_custom_dataset(\"DATA_V13\")\n",
    "#df_14 = get_custom_dataset(\"DATA_V14\")\n",
    "#df_15 = get_custom_dataset(\"DATA_V15\")\n",
    "#df_16 = get_custom_dataset(\"DATA_V16\")\n",
    "#\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#    pd.concat([df_10, df_11, df_12, df_13, df_14, df_15, df_16], ignore_index=True)\n",
    "#    .sample(frac=1.0)\n",
    "#    .reset_index(drop=True)\n",
    "#)\n",
    "#\n",
    "#index_100 = list(df_comb.query(\"snr>50 & snr<100\").sample(n=700).index)\n",
    "#index_50 =  list(df_comb.query(\"snr>30 & snr<50\").sample(n=1250).index)\n",
    "#index_30 =  list(df_comb.query(\"snr>0 & snr<30\").sample(n=1250).index)\n",
    "#index_neg = list(df_comb.query(\"snr==0\").sample(n=4000).index)\n",
    "#\n",
    "#val_idx = index_100 + index_50 + index_30 + index_neg\n",
    "#val_df = df_comb.iloc[val_idx].sample(frac=1.).reset_index(drop=True)\n",
    "#trn_df = df_comb.loc[~df_comb.index.isin(val_idx)].sample(frac=1.).reset_index(drop=True)\n",
    "#val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "#trn_df.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9d4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'V_14'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#\n",
    "#df_13 = get_custom_dataset(\"DATA_V13\")\n",
    "#df_14 = get_custom_dataset(\"DATA_V14\")\n",
    "#df_15 = get_custom_dataset(\"DATA_V15\")\n",
    "#df_16 = get_custom_dataset(\"DATA_V16\")\n",
    "#df_17 = get_custom_dataset(\"DATA_V17\")\n",
    "#df_18 = get_custom_dataset(\"DATA_V18\")\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#   pd.concat([df_13, df_14, df_15, df_16, df_17, df_18], ignore_index=True)\n",
    "#   .sample(frac=1.0)\n",
    "#   .reset_index(drop=True))\n",
    "#    \n",
    "#val_df = pd.read_csv('../data/SPLITS/V_10/val_df.csv')\n",
    "#trn_df = pd.concat([pd.read_csv('../data/SPLITS/V_10/trn_df.csv'), df_comb], ignore_index=True)\n",
    "#val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "#trn_df.to_csv(save_path/'trn_df.csv', index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1ac85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41118dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'V_15'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#\n",
    "#df_10 = get_custom_dataset(\"DATA_V10\")\n",
    "#df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "#df_12 = get_custom_dataset(\"DATA_V12\").query('snr==0').reset_index(drop=True)\n",
    "#df_13 = get_custom_dataset(\"DATA_V13\")\n",
    "#df_14 = get_custom_dataset(\"DATA_V14\")\n",
    "#df_16 = get_custom_dataset(\"DATA_V16\")\n",
    "#df_17 = get_custom_dataset(\"DATA_V17\")\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#    pd.concat(\n",
    "#        [df_10, df_11, df_12, df_13, df_14, df_16, df_17],\n",
    "#        ignore_index=True,\n",
    "#    )\n",
    "#    .sample(frac=1.0)\n",
    "#    .reset_index(drop=True)\n",
    "#)\n",
    "#\n",
    "#index_100 = list(df_comb.query(\"snr>50 & snr<100\").sample(n=1250).index)\n",
    "#index_50 =  list(df_comb.query(\"snr>30 & snr<50\").sample(n=1250).index)\n",
    "#index_30 =  list(df_comb.query(\"snr>0 & snr<30\").sample(n=1250).index)\n",
    "#index_neg = list(df_comb.query(\"snr==0\").sample(n=4000).index)\n",
    "#\n",
    "#\n",
    "#val_idx = index_100 + index_50 + index_30 + index_neg\n",
    "#val_df = df_comb.iloc[val_idx].sample(frac=1.).reset_index(drop=True)\n",
    "#trn_df = df_comb.loc[~df_comb.index.isin(val_idx)].sample(frac=1.).reset_index(drop=True)\n",
    "#val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "#trn_df.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027e698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'V_16'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#\n",
    "#df_10 = get_custom_dataset(\"DATA_V10\")\n",
    "#df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "#df_12 = get_custom_dataset(\"DATA_V12\").query('snr==0').reset_index(drop=True)\n",
    "#df_13 = get_custom_dataset(\"DATA_V13\")\n",
    "#df_14 = get_custom_dataset(\"DATA_V14\")\n",
    "#df_16 = get_custom_dataset(\"DATA_V16\")\n",
    "#df_17 = get_custom_dataset(\"DATA_V17\")\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#    pd.concat(\n",
    "#        [df_10, df_11, df_12, df_13, df_14, df_16, df_17],\n",
    "#        ignore_index=True,\n",
    "#    )\n",
    "#    .sample(frac=1.0)\n",
    "#    .reset_index(drop=True)\n",
    "#)\n",
    "#\n",
    "#index_100 = list(df_comb.query(\"snr>50 & snr<100\").sample(n=1500).index)\n",
    "#index_50 =  list(df_comb.query(\"snr>0 & snr<50\").sample(n=1500).index)\n",
    "#index_neg = list(df_comb.query(\"snr==0\").sample(n=4000).index)\n",
    "#\n",
    "#\n",
    "#val_idx = index_100 + index_50 + index_neg\n",
    "#val_df = df_comb.iloc[val_idx].sample(frac=1.).reset_index(drop=True)\n",
    "#trn_df = df_comb.loc[~df_comb.index.isin(val_idx)].sample(frac=1.).reset_index(drop=True)\n",
    "#val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "#trn_df.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff07c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'V_17'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#\n",
    "#df_10 = get_custom_dataset(\"DATA_V10\")\n",
    "#df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "#df_12 = get_custom_dataset(\"DATA_V12\").query('snr==0').reset_index(drop=True)\n",
    "#df_13 = get_custom_dataset(\"DATA_V13\")\n",
    "#df_14 = get_custom_dataset(\"DATA_V14\")\n",
    "#df_16 = get_custom_dataset(\"DATA_V16\")\n",
    "#df_17 = get_custom_dataset(\"DATA_V17\")\n",
    "#df_19 = get_custom_dataset(\"DATA_V19\")\n",
    "#df_20 = get_custom_dataset(\"DATA_V20\")\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#    pd.concat(\n",
    "#        [df_10, df_11, df_12, df_13, df_14, df_16, df_17, df_19, df_20],\n",
    "#        ignore_index=True,\n",
    "#    )\n",
    "#    .sample(frac=1.0)\n",
    "#    .reset_index(drop=True)\n",
    "#)\n",
    "#\n",
    "#index_100 = list(df_comb.query(\"snr>50 & snr<100\").sample(n=1500).index)\n",
    "#index_50 =  list(df_comb.query(\"snr>0 & snr<50\").sample(n=2000).index)\n",
    "#index_neg = list(df_comb.query(\"snr==0\").sample(n=4000).index)\n",
    "#\n",
    "#\n",
    "#val_idx = index_100 + index_50 + index_neg\n",
    "#val_df = df_comb.iloc[val_idx].sample(frac=1.).reset_index(drop=True)\n",
    "#trn_df = df_comb.loc[~df_comb.index.isin(val_idx)].sample(frac=1.).reset_index(drop=True)\n",
    "#val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "#trn_df.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e535f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#name = 'V_18'\n",
    "#save_path = Path(\"../data/SPLITS\")/name\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "#\n",
    "#\n",
    "#df_10 = get_custom_dataset(\"DATA_V10\")\n",
    "#df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "#df_12 = get_custom_dataset(\"DATA_V12\").query('snr==0').reset_index(drop=True)\n",
    "#df_13 = get_custom_dataset(\"DATA_V13\")\n",
    "#df_14 = get_custom_dataset(\"DATA_V14\")\n",
    "#df_16 = get_custom_dataset(\"DATA_V16\")\n",
    "#df_17 = get_custom_dataset(\"DATA_V17\")\n",
    "#df_19 = get_custom_dataset(\"DATA_V19\")\n",
    "#df_20 = get_custom_dataset(\"DATA_V20\")\n",
    "#\n",
    "#\n",
    "#df_comb = (\n",
    "#    pd.concat(\n",
    "#        [df_10, df_11, df_12, df_13, df_14, df_16, df_17, df_19, df_20],\n",
    "#        ignore_index=True,\n",
    "#    )\n",
    "#    .sample(frac=1.0)\n",
    "#    .reset_index(drop=True)\n",
    "#)\n",
    "#df_comb['t'] = df_comb['snr'].round().astype('int')\n",
    "#out = []\n",
    "#skf = StratifiedKFold(n_splits=5)\n",
    "#for k, (trn, val) in enumerate(skf.split(df_comb['id'], df_comb['t'])):\n",
    "#    temp = df_comb.iloc[val].copy().reset_index(drop=True)\n",
    "#    temp['fold']  = k\n",
    "#    out.append(temp)\n",
    "#df_comb = pd.concat(out, ignore_index=True)\n",
    "#df_comb.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3517f532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "name = 'V_19'\n",
    "save_path = Path(\"../data/SPLITS\")/name\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "df_10 = get_custom_dataset(\"DATA_V10\")\n",
    "df_11 = get_custom_dataset(\"DATA_V11\")\n",
    "df_13 = get_custom_dataset(\"DATA_V13\")\n",
    "df_14 = get_custom_dataset(\"DATA_V14\")\n",
    "df_16 = get_custom_dataset(\"DATA_V16\")\n",
    "df_20 = get_custom_dataset(\"DATA_V20\")\n",
    "\n",
    "\n",
    "df_comb = (\n",
    "    pd.concat(\n",
    "        [df_10, df_11, df_13, df_14, df_16, df_20],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    .sample(frac=1.0)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "index_100 = list(df_comb.query(\"snr>50 & snr<100\").sample(n=1500).index)\n",
    "index_50 =  list(df_comb.query(\"snr>0 & snr<50\").sample(n=2000).index)\n",
    "index_neg = list(df_comb.query(\"snr==0\").sample(n=4000).index)\n",
    "\n",
    "\n",
    "val_idx = index_100 + index_50 + index_neg\n",
    "val_df = df_comb.iloc[val_idx].sample(frac=1.).reset_index(drop=True)\n",
    "trn_df = df_comb.loc[~df_comb.index.isin(val_idx)].sample(frac=1.).reset_index(drop=True)\n",
    "val_df.to_csv(save_path/'val_df.csv', index=False)\n",
    "trn_df.to_csv(save_path/'trn_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_custom_dataset('DATA_V19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2449505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = DatasetVisualizer(val_df.query('snr>50').reset_index(drop=True)[:50])\n",
    "#for i in range(50):\n",
    "#    img, _ = ds[i]\n",
    "#    plot_sft(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
