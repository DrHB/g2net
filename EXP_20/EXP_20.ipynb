{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b186c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from timm import create_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from fastai.vision.all import L, unsqueeze\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import (\n",
    "    LabelSmoothingCrossEntropy,\n",
    "    BinaryCrossEntropy,\n",
    "    SoftTargetCrossEntropy,\n",
    ")\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1effff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollTimeFreq:\n",
    "    def __init__(self, shift_t_percent=0.3, shift_f_percent=0.3):\n",
    "        self.shift_t_percent = shift_t_percent\n",
    "        self.shift_f_percent = shift_f_percent\n",
    "\n",
    "    def __call__(self, x):\n",
    "        c, t, f = x.shape\n",
    "        roll_t = np.random.randint(0, int(self.shift_t_percent * t))\n",
    "        roll_f = np.random.randint(0, int(self.shift_f_percent * f))\n",
    "        if np.random.rand() > 0.5:\n",
    "            x = np.roll(x, roll_t, 1)\n",
    "        else:\n",
    "            x = np.roll(x, roll_f, 2)\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            k = [1, 0]\n",
    "            x = x[k, ...]\n",
    "        if np.random.rand() > 0.5:\n",
    "            x = np.flip(x, axis=1).copy()\n",
    "        if np.random.rand() > 0.5:  # vertical flip\n",
    "            x = np.flip(x, axis=2).copy()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr(left, right, df):\n",
    "    df_ = pd.concat([df.query(f\"snr>{left} & snr<{right}\"), df.query(\"snr==0\")])\n",
    "    return df_\n",
    "\n",
    "\n",
    "def generate_report(df, p, fn):\n",
    "    pred = F.softmax(p).cpu().numpy()[:, 1]\n",
    "    val_df_eval = df.copy()\n",
    "    val_df_eval[\"pred\"] = pred\n",
    "    val_df_eval.to_csv(f'{fn}_oof.csv')\n",
    "\n",
    "    roc_100 = roc_auc_score(val_df_eval[\"target\"], val_df_eval[\"pred\"])\n",
    "    roc_50_100 = roc_auc_score(\n",
    "        get_snr(50, 100, val_df_eval)[\"target\"], get_snr(50, 100, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_0_50 = roc_auc_score(\n",
    "        get_snr(0, 50, val_df_eval)[\"target\"], get_snr(0, 50, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_0_40 = roc_auc_score(\n",
    "        get_snr(0, 40, val_df_eval)[\"target\"], get_snr(0, 40, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    roc_0_30 = roc_auc_score(\n",
    "        get_snr(0, 30, val_df_eval)[\"target\"], get_snr(0, 30, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "\n",
    "    roc_0_20 = roc_auc_score(\n",
    "        get_snr(0, 20, val_df_eval)[\"target\"], get_snr(0, 20, val_df_eval)[\"pred\"]\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    return {\n",
    "        \"roc_all\": roc_100,\n",
    "        \"roc_50_100\": roc_50_100,\n",
    "        \"roc_0_50\": roc_0_50,\n",
    "        \"roc_0_40\": roc_0_40,\n",
    "        \"roc_0_30\": roc_0_30,\n",
    "        \"roc_0_20\": roc_0_20,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModel:\n",
    "    def __init__(self, folder, exp_name, best=np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score < self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelMetric:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder) / f\"{exp_name}.pth\"\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "            torch.save(model.state_dict(), self.folder)\n",
    "\n",
    "\n",
    "class SaveModelEpoch:\n",
    "    def __init__(self, folder, exp_name, best=-np.inf):\n",
    "        self.best = best\n",
    "        self.folder = Path(folder)\n",
    "        self.exp_name = exp_name\n",
    "\n",
    "    def __call__(self, score, model, epoch):\n",
    "        self.best = score\n",
    "        print(f\"Better model found at epoch {epoch} with value: {self.best}.\")\n",
    "        torch.save(model.state_dict(), f\"{self.folder/self.exp_name}_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def custom_auc_score(p, gt):\n",
    "    return roc_auc_score(gt.cpu().numpy(), F.softmax(p).cpu().numpy()[:, 1])\n",
    "\n",
    "\n",
    "def fit_mixup(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    loss_fn,\n",
    "    opt,\n",
    "    metric,\n",
    "    val_df,\n",
    "    folder=\"models\",\n",
    "    exp_name=\"exp_00\",\n",
    "    device=None,\n",
    "    sched=None,\n",
    "    mixup_=False,\n",
    "    save_md=SaveModelEpoch,\n",
    "):\n",
    "    if device is None:\n",
    "        device = (\n",
    "            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    loss_fn_trn = loss_fn\n",
    "    if mixup_:\n",
    "        mixup = Mixup(\n",
    "            num_classes=2, mixup_alpha=0.4, prob=0.8\n",
    "        )\n",
    "        loss_fn_trn = BinaryCrossEntropy()\n",
    "    mb = master_bar(range(epochs))\n",
    "    \n",
    "   \n",
    "    mb.write([\"epoch\", \n",
    "              \"train_loss\",\n",
    "              \"valid_loss\",\n",
    "              \"val_metric\",\n",
    "              \"roc_all\",\n",
    "              \"roc_50_100\", \n",
    "              \"roc_0_50\", \n",
    "              \"roc_0_40\", \n",
    "              \"roc_0_30\", \n",
    "              \"roc_0_20\"], table=True)\n",
    "    model.to(device)  # we have to put our model on gpu\n",
    "    scaler = torch.cuda.amp.GradScaler()  # this for half precision training\n",
    "    save_md = save_md(folder, exp_name)\n",
    "\n",
    "    for i in mb:  # iterating  epoch\n",
    "        trn_loss, val_loss = 0.0, 0.0\n",
    "        trn_n, val_n = len(train_dl.dataset), len(valid_dl.dataset)\n",
    "        model.train()  # set model for training\n",
    "        for (xb, yb) in progress_bar(train_dl, parent=mb):\n",
    "            xb, yb = xb.to(device), yb.to(device)  # putting batches to device\n",
    "            if mixup_:\n",
    "                xb, yb = mixup(xb, yb)\n",
    "            with torch.cuda.amp.autocast():  # half precision\n",
    "                out = model(xb)  # forward pass\n",
    "                loss = loss_fn_trn(out, yb)  # calulation loss\n",
    "\n",
    "            trn_loss += loss.item()\n",
    "\n",
    "            scaler.scale(loss).backward()  # backward\n",
    "            scaler.step(opt)  # optimzers step\n",
    "            scaler.update()  # for half precision\n",
    "            opt.zero_grad()  # zeroing optimizer\n",
    "            if sched is not None:\n",
    "                sched.step()  # scuedular step\n",
    "\n",
    "        trn_loss /= mb.child.total\n",
    "\n",
    "        # putting model in eval mode\n",
    "        model.eval()\n",
    "        gt = []\n",
    "        pred = []\n",
    "        # after epooch is done we can run a validation dataloder and see how are doing\n",
    "        with torch.no_grad():\n",
    "            for (xb, yb) in progress_bar(valid_dl, parent=mb):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(out, yb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                gt.append(yb.detach())\n",
    "                pred.append(out.detach())\n",
    "        # calculating metric\n",
    "        metric_ = metric(torch.cat(pred), torch.cat(gt))\n",
    "        # saving model if necessary\n",
    "        save_md(metric_, model, i)\n",
    "        val_loss /= mb.child.total\n",
    "        dict_res = generate_report(val_df, torch.cat(pred), f\"{folder}/{exp_name}_{i}\")\n",
    "            \n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"trn_loss\": [trn_loss],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"metric\": [metric_],\n",
    "                \"roc_all\": [dict_res[\"roc_all\"]],\n",
    "                \"roc_50_100\": [dict_res[\"roc_50_100\"]],\n",
    "                \"roc_0_50\": [dict_res[\"roc_0_50\"]],\n",
    "                \"roc_0_40\": [dict_res[\"roc_0_40\"]],\n",
    "                \"roc_0_30\": [dict_res[\"roc_0_30\"]],\n",
    "                \"roc_0_20\": [dict_res[\"roc_0_20\"]],\n",
    "            }\n",
    "        ).to_csv(f\"{folder}/{exp_name}_{i}.csv\", index=False)\n",
    "        mb.write(\n",
    "            [\n",
    "                i,\n",
    "                f\"{trn_loss:.6f}\",\n",
    "                f\"{val_loss:.6f}\",\n",
    "                f\"{metric_:.6f}\",\n",
    "                f\"{dict_res['roc_all']:.6f}\",\n",
    "                f\"{dict_res['roc_50_100']:.6f}\",\n",
    "                f\"{dict_res['roc_0_50']:.6f}\",\n",
    "                f\"{dict_res['roc_0_40']:.6f}\",\n",
    "                f\"{dict_res['roc_0_30']:.6f}\",\n",
    "                f\"{dict_res['roc_0_20']:.6f}\",\n",
    "            ],\n",
    "            table=True,\n",
    "        )\n",
    "    print(\"Training done\")\n",
    "    # loading the best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_data(data):\n",
    "     return (data-np.min(data))/(np.max(data)-np.min(data))\n",
    "\n",
    "class DataV0():\n",
    "    \"\"\"\n",
    "    dataset = Dataset(data_type, df)\n",
    "\n",
    "    img, y = dataset[i]\n",
    "      img (np.float32): 2 x 360 x 128\n",
    "      y (np.float32): label 0 or 1\n",
    "    \"\"\"\n",
    "    def __init__(self, df, freq_tfms=False):\n",
    "        self.df = df\n",
    "        self.freq_tfms = freq_tfms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        i (int): get ith data\n",
    "        \"\"\"\n",
    "        r = self.df.iloc[i]\n",
    "        y = np.float32(r.target)\n",
    "        filename=r.id\n",
    "        file_id = Path(r.id).stem\n",
    "        img = np.empty((2, 360, 256), dtype=np.float32)\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            g = f[file_id]\n",
    "\n",
    "            for ch, s in enumerate(['H1', 'L1']):\n",
    "                a = g[s]['SFTs'][:, :4096] * 1e22  # Fourier coefficient complex64\n",
    "\n",
    "                p = a.real**2 + a.imag**2  # power\n",
    "                p /= np.mean(p)  # normalize\n",
    "                p = np.mean(p.reshape(360, 256, 16), axis=2)  # compress 4096 -> 128\n",
    "                #print(p.min(), p.max())\n",
    "                #p = scale_data(p)\n",
    "                img[ch] = p\n",
    "        if self.freq_tfms:\n",
    "            if np.random.rand()>0.5:\n",
    "                img = self.freq_tfms(img)\n",
    "\n",
    "        return img, y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    bs = 64\n",
    "    nw = 4\n",
    "    model_name = \"convnext_xlarge_384_in22ft1k\"\n",
    "    lr = 1e-4\n",
    "    wd = 1e-4\n",
    "    epoch = 5\n",
    "    warmup_pct = 0.1\n",
    "    exp_name = \"EXP_20_DATA_V10_V11_V12_NEG_13_14_16_17_360_128_V_16\"\n",
    "    num_classes = 2\n",
    "    dropout_rate = 0.3\n",
    "    folder = \"EXP_20_00\"\n",
    "    split_voldf = Path(\"../data/SPLITS/V_16\")\n",
    "    mixup=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dforig = pd.read_csv('../data/train_labels.csv')\n",
    "dforig.columns = ['fn', 'target']\n",
    "dforig['fn'] = dforig['fn'].apply(lambda x: Path('../data/train')/f'{x}.hdf5')\n",
    "dforig.columns = ['id', 'target']\n",
    "#dforig = dforig[dforig.target >= 0].reset_index(drop=True)\n",
    "trn_df = pd.read_csv(CFG.split_voldf/'trn_df.csv')\n",
    "val_df = pd.read_csv(CFG.split_voldf/'val_df.csv')\n",
    "trn_df = pd.concat([dforig.query('target==0').reset_index(drop=True), trn_df]).sample(frac=1)\n",
    "trn_df.shape,  val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b7ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset =  DataV0(trn_df, RollTimeFreq())\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    img, y = dataset[np.random.randint(0, len(dataset))]\n",
    "    #img, y = dataset[i]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title('Spectrogram')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.imshow(np.concatenate([img[0], img[1]], 1))  # zooming in for dataset[10]\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print(y)\n",
    "    plt.pause(0.1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2eb96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt = []\n",
    "preds = []\n",
    "fold = 0\n",
    "\n",
    "# Train - val split\n",
    "trn_ds = DataV0(trn_df, RollTimeFreq())\n",
    "vld_ds = DataV0(val_df)\n",
    "\n",
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=True,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.bs,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "custom_model = create_model(\n",
    "    CFG.model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=CFG.num_classes,\n",
    "    in_chans=2,\n",
    ")\n",
    "opt = torch.optim.AdamW(custom_model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "warmup_steps = int(len(trn_dl) * int(CFG.warmup_pct * CFG.epoch))\n",
    "total_steps = int(len(trn_dl) * CFG.epoch)\n",
    "sched = get_linear_schedule_with_warmup(\n",
    "    opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "fit_mixup(\n",
    "    epochs=CFG.epoch,\n",
    "    model=custom_model,\n",
    "    train_dl=trn_dl,\n",
    "    valid_dl=vld_dl,\n",
    "    loss_fn=loss_func,\n",
    "    opt=opt,\n",
    "    val_df = val_df,\n",
    "    metric=custom_auc_score,\n",
    "    folder=CFG.folder,\n",
    "    exp_name=f\"{CFG.exp_name}_{fold}\",\n",
    "    device=\"cuda:0\",\n",
    "    sched=sched,\n",
    ")\n",
    "del custom_model\n",
    "del trn_dl\n",
    "del vld_dl\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch\ttrain_loss\tvalid_loss\tval_metric\troc_all\troc_50_100\troc_0_50\troc_0_40\troc_0_30\troc_0_20\n",
    "0\t0.531424\t0.487771\t0.795653\t0.795653\t0.963788\t0.627518\t0.609552\t0.611548\t0.652328\n",
    "1\t0.496563\t0.469109\t0.819678\t0.819678\t0.984185\t0.655171\t0.615622\t0.598838\t0.628265\n",
    "2\t0.484414\t0.448635\t0.826526\t0.826526\t0.986755\t0.666296\t0.628585\t0.610908\t0.626292\n",
    "3\t0.471053\t0.470826\t0.832730\t0.832730\t0.990788\t0.674672\t0.631519\t0.608003\t0.623880\n",
    "4\t0.457353\t0.433260\t0.835977\t0.835977\t0.991256\t0.680698\t0.639376\t0.615618\t0.631231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmFeatureExtractor(nn.Module):\n",
    "    def __init__(self, model_name, n_class, weights):\n",
    "        super().__init__()\n",
    "        self.md = create_model(\n",
    "            model_name,\n",
    "            pretrained=False,\n",
    "            num_classes=n_class,\n",
    "            in_chans=2,\n",
    "        )\n",
    "        print(f\"loading: {weights}\")\n",
    "        self.md.load_state_dict(torch.load(weights))\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            out = F.softmax(self.md(x))\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class AverageModel(nn.Module):\n",
    "    def __init__(self, model_list):\n",
    "        super().__init__()\n",
    "        self.model_list = model_list\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = []\n",
    "        for md in self.model_list:\n",
    "            res.append(md(x).detach().cpu())\n",
    "        return torch.stack(res).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c017d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 4\n",
    "md_wts = [f\"{CFG.folder}/{CFG.exp_name}_0_{epoch}.pth\"]\n",
    "md_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = AverageModel(\n",
    "    [\n",
    "        TimmFeatureExtractor(CFG.model_name, CFG.num_classes, md_wts[0]).cuda().eval(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit.columns = ['fn', 'target']\n",
    "submit['fn'] = submit['fn'].apply(lambda x: Path('../data/test')/f'{x}.hdf5')\n",
    "submit.columns = ['id', 'target']\n",
    "tst_ds = DataV0(submit)\n",
    "tst_dl = DataLoader(\n",
    "    tst_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.nw,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "res = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(tst_dl):\n",
    "        out = md(x.cuda())\n",
    "        res.append(out[:, 1].numpy())\n",
    "\n",
    "\n",
    "\n",
    "submit['target'] = np.concatenate(res)\n",
    "submit.columns = ['fn', 'target']\n",
    "submit['fn'] = submit['fn'].apply(lambda x: x.stem)\n",
    "submit.columns = ['id', 'target']\n",
    "os.makedirs('../data/SUBS', exist_ok=True)\n",
    "submit.to_csv(f'../data/SUBS/{CFG.model_name}_{CFG.exp_name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['target'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d276cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b198340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
