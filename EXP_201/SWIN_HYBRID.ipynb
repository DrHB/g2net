{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcdd160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.models.vision_transformer_hybrid import HybridEmbed\n",
    "import torch\n",
    "import numpy\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, target_size, with_conv=True):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        self.target_size = target_size\n",
    "        if self.with_conv:\n",
    "            self.conv = torch.nn.Conv2d(\n",
    "                in_channels, in_channels, kernel_size=3, stride=1, padding=1\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(x, size=self.target_size, mode=\"bilinear\")\n",
    "        if self.with_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomHybdridEmbed(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        decoder_proj_conv,\n",
    "        channel_in=2,\n",
    "        encoder_name=\"inception_v4\",\n",
    "        encoder_out_layer_num=[2],\n",
    "        transformer_original_input_size=(1, 3, 224, 224),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            encoder_name,\n",
    "            features_only=True,\n",
    "            out_indices=encoder_out_layer_num,\n",
    "            pretrained=True,\n",
    "            in_chans=channel_in,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.rand(1, channel_in, 360, 512)\n",
    "            enc_ch_num = self.encoder(x)[0].shape[1]\n",
    "            decoder_in_channels = decoder_proj_conv(\n",
    "                torch.rand(transformer_original_input_size)\n",
    "            ).shape\n",
    "\n",
    "        self.resize = Upsample(enc_ch_num, decoder_in_channels[2:])\n",
    "        self.proj = nn.Conv2d(\n",
    "            enc_ch_num, decoder_in_channels[1], kernel_size=1, stride=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[0]\n",
    "        x = self.resize(x)\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "backbone = timm.create_model(\n",
    "    \"swin_large_patch4_window12_384\", pretrained=True, num_classes=1\n",
    ")\n",
    "\n",
    "backbone.patch_embed = CustomHybdridEmbed(\n",
    "    backbone.patch_embed.proj, transformer_original_input_size=(1, 3, 384, 384)\n",
    ")\n",
    "\n",
    "backbone(torch.rand(1, 2, 512, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695fcc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64463efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3fccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4108f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
